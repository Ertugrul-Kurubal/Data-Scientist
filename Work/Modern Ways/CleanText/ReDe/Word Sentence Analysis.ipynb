{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Sentence Analysis Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('hepsiburada.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Review'].values\n",
    "y = df['Rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 15000\n",
    "tokenizer = Tokenizer(num_words=num_words, split='.') # Sentence only according to \".\"\n",
    "tokenizer.fit_on_texts(X)\n",
    "tokenizer.word_index\n",
    "tokenizer.word_index.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in tokenizer.word_index.keys():\n",
    "    a.append(' '.join(i.split()))\n",
    "a  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Corpus\n",
    "# text_corpus_3 = []                     \n",
    "# for i in text_corpus_2:\n",
    "#     text_corpus_3.append(i.strip(\"-\").strip(\"\\n\").strip(\"(\").strip(\")\").strip(\"...\").strip(\" \"))\n",
    "# text_corpus_3\n",
    "# Bu script kullanÄ±lacak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use For Equal Space \n",
    "# def space(sentence):\n",
    "#     words = word_tokenize(sentence)\n",
    "#     combine_words = \" \".join(words)\n",
    "#     return combine_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
