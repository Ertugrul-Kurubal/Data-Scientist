{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared Word File Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "#import multiprocessing as mp\n",
    "from multiprocessing import Process, Manager, Pool, Queue\n",
    "from itertools import islice\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 16\n"
     ]
    }
   ],
   "source": [
    "nprocs = multiprocessing.cpu_count()\n",
    "print(f\"Number of CPU cores: {nprocs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# language pair\n",
    "lang_folder = \"English\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "lang_pair = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "# adding native word to shared word\n",
    "word_start = 0  # 0  # native word start index\n",
    "word_end = 28  # 28  # native word end index\n",
    "\n",
    "# shared word frequency\n",
    "shared_word_frequency = True  # True, False\n",
    "\n",
    "# prefix suffix file\n",
    "prefix_suffix = False  # True, False  # always must be False in this part\n",
    "native_word = True # True for adding native word\n",
    "etymology_word = True  # True for adding etymology word\n",
    "\n",
    "# adding output file extention\n",
    "if (not prefix_suffix) & etymology_word & native_word:\n",
    "    file_ext = \"1\"\n",
    "elif (not prefix_suffix) & etymology_word & (not native_word):\n",
    "    file_ext = \"2\"\n",
    "elif prefix_suffix & etymology_word & native_word:\n",
    "    file_ext = \"3\"\n",
    "elif prefix_suffix & etymology_word & (not native_word):\n",
    "    file_ext = \"4\"\n",
    "elif prefix_suffix & (not etymology_word) & native_word:\n",
    "    file_ext = \"5\"\n",
    "elif (not prefix_suffix) & (not etymology_word) & native_word:\n",
    "    file_ext = \"6\"\n",
    "else:\n",
    "    file_ext = \"7\"              \n",
    "# 1 => for native word and etymology word without prefix suffix. \n",
    "# 2 => for only etymology word without prefix suffix. \n",
    "# 3 => for native word and etymology word with prefix suffix. prefix_suffix, native_word and etymology_word must be True. \n",
    "# 4 => for only etymology word with prefix suffix.\n",
    "# 5 => for only native word with prefix suffix.\n",
    "# 6 => for only native word without prefix suffix.\n",
    "print(f\"{file_ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/5-Shared Word File/{lang_folder.capitalize()} {lang_pair.capitalize()}\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twogram In Threegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you</td>\n",
       "      <td>102069964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i</td>\n",
       "      <td>94447074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>77481215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>58281119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>50852895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552149</th>\n",
       "      <td>fruitcocktail</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552150</th>\n",
       "      <td>andthesunlightshining</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552151</th>\n",
       "      <td>upravo</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552152</th>\n",
       "      <td>yagawa</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552153</th>\n",
       "      <td>foxtrotoscar</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>552154 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         word  frequency\n",
       "0                         you  102069964\n",
       "1                           i   94447074\n",
       "2                         the   77481215\n",
       "3                          to   58281119\n",
       "4                          is   50852895\n",
       "...                       ...        ...\n",
       "552149          fruitcocktail          6\n",
       "552150  andthesunlightshining          6\n",
       "552151                 upravo          6\n",
       "552152                 yagawa          6\n",
       "552153           foxtrotoscar          6\n",
       "\n",
       "[552154 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.lower().capitalize()}/Deployment/Data/Word/Word_Merge_Preprocess.xlsx\")\n",
    "df_word_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "      <th>twogram</th>\n",
       "      <th>freq_twogram</th>\n",
       "      <th>threegram</th>\n",
       "      <th>freq_threegram</th>\n",
       "      <th>fourgram</th>\n",
       "      <th>freq_fourgram</th>\n",
       "      <th>fivegram</th>\n",
       "      <th>freq_fivegram</th>\n",
       "      <th>sentence</th>\n",
       "      <th>freq_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you</td>\n",
       "      <td>102069964.0</td>\n",
       "      <td>i am</td>\n",
       "      <td>10494331.0</td>\n",
       "      <td>i do not</td>\n",
       "      <td>3520257</td>\n",
       "      <td>you do not have</td>\n",
       "      <td>160426.0</td>\n",
       "      <td>you do not have to</td>\n",
       "      <td>107450.0</td>\n",
       "      <td>of course</td>\n",
       "      <td>266277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i</td>\n",
       "      <td>94447074.0</td>\n",
       "      <td>do not</td>\n",
       "      <td>8972296.0</td>\n",
       "      <td>i am not</td>\n",
       "      <td>1262941</td>\n",
       "      <td>i do not have</td>\n",
       "      <td>158788.0</td>\n",
       "      <td>i do not have a</td>\n",
       "      <td>34568.0</td>\n",
       "      <td>what is it</td>\n",
       "      <td>251203.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>77481215.0</td>\n",
       "      <td>i do</td>\n",
       "      <td>4179914.0</td>\n",
       "      <td>what do you</td>\n",
       "      <td>1120086</td>\n",
       "      <td>do not have to</td>\n",
       "      <td>150328.0</td>\n",
       "      <td>do not have to do</td>\n",
       "      <td>21572.0</td>\n",
       "      <td>stop it</td>\n",
       "      <td>152280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>58281119.0</td>\n",
       "      <td>i will</td>\n",
       "      <td>3706224.0</td>\n",
       "      <td>you do not</td>\n",
       "      <td>1010676</td>\n",
       "      <td>no i do not</td>\n",
       "      <td>105374.0</td>\n",
       "      <td>i do not have to</td>\n",
       "      <td>21499.0</td>\n",
       "      <td>i am</td>\n",
       "      <td>136931.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>50852895.0</td>\n",
       "      <td>do you</td>\n",
       "      <td>3358227.0</td>\n",
       "      <td>do not you</td>\n",
       "      <td>644488</td>\n",
       "      <td>i do not like</td>\n",
       "      <td>99318.0</td>\n",
       "      <td>i do not like it</td>\n",
       "      <td>18564.0</td>\n",
       "      <td>i do</td>\n",
       "      <td>114801.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206638</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i control radiation</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206639</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the antibiotic i</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206640</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my radar screen</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206641</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cup will not</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206642</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stop on no</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206643 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word    frequency twogram  freq_twogram            threegram  \\\n",
       "0       you  102069964.0    i am    10494331.0             i do not   \n",
       "1         i   94447074.0  do not     8972296.0             i am not   \n",
       "2       the   77481215.0    i do     4179914.0          what do you   \n",
       "3        to   58281119.0  i will     3706224.0           you do not   \n",
       "4        is   50852895.0  do you     3358227.0           do not you   \n",
       "...     ...          ...     ...           ...                  ...   \n",
       "206638  NaN          NaN     NaN           NaN  i control radiation   \n",
       "206639  NaN          NaN     NaN           NaN     the antibiotic i   \n",
       "206640  NaN          NaN     NaN           NaN      my radar screen   \n",
       "206641  NaN          NaN     NaN           NaN         cup will not   \n",
       "206642  NaN          NaN     NaN           NaN           stop on no   \n",
       "\n",
       "        freq_threegram         fourgram  freq_fourgram            fivegram  \\\n",
       "0              3520257  you do not have       160426.0  you do not have to   \n",
       "1              1262941    i do not have       158788.0     i do not have a   \n",
       "2              1120086   do not have to       150328.0   do not have to do   \n",
       "3              1010676      no i do not       105374.0    i do not have to   \n",
       "4               644488    i do not like        99318.0    i do not like it   \n",
       "...                ...              ...            ...                 ...   \n",
       "206638               4              NaN            NaN                 NaN   \n",
       "206639               4              NaN            NaN                 NaN   \n",
       "206640               4              NaN            NaN                 NaN   \n",
       "206641               4              NaN            NaN                 NaN   \n",
       "206642               4              NaN            NaN                 NaN   \n",
       "\n",
       "        freq_fivegram    sentence  freq_sentence  \n",
       "0            107450.0   of course       266277.0  \n",
       "1             34568.0  what is it       251203.0  \n",
       "2             21572.0     stop it       152280.0  \n",
       "3             21499.0        i am       136931.0  \n",
       "4             18564.0        i do       114801.0  \n",
       "...               ...         ...            ...  \n",
       "206638            NaN         NaN            NaN  \n",
       "206639            NaN         NaN            NaN  \n",
       "206640            NaN         NaN            NaN  \n",
       "206641            NaN         NaN            NaN  \n",
       "206642            NaN         NaN            NaN  \n",
       "\n",
       "[206643 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shared_file = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/4-Shared Word/{lang_folder.capitalize()} {lang_pair.capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Result_With_Frequency{file_ext}.xlsx\")\n",
    "#df_shared_file = pd.read_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Result_With_Frequency.xlsx\")\n",
    "df_shared_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_result(df,column_list): # df is dataframe, column_list is list value\n",
    "    '''\n",
    "    word_count_bool(df, column_list): df columns word count for word frequency\\n\n",
    "    df is dataframe, column_list is list value\\n\n",
    "    word_count_bool(df, [\"word\",\"twogram\"]):\n",
    "    '''\n",
    "    list_all = []\n",
    "    for i in df.loc[:,[x for x in column_list]].columns:\n",
    "        var_list = df[f\"{i}\"].dropna().tolist()\n",
    "        for j in var_list:\n",
    "            list_all.append(j)\n",
    "    text = \" \".join(list_all)\n",
    "    word_list = re.findall(r\"\\w+\",text, re.UNICODE)\n",
    "    df_word_list = pd.DataFrame(word_list, columns=[\"word\"])\n",
    "    #df_word_list.rename(columns={0:\"word\"}, inplace=True)\n",
    "    df_word_count = pd.DataFrame(df_word_list.value_counts())\n",
    "    df_word_count.reset_index(inplace=True)\n",
    "    df_word_count.rename(columns={0:\"word_count\"}, inplace=True)\n",
    "    \n",
    "    return  df_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_in_wordgroup(df, list_column, target_column):\n",
    "\n",
    "    '''word_in_wordgroup(df, \"word\", \"twogram\"):\n",
    "       df is dataframe, list_column and target_column are \n",
    "       dataframe column string name. list_column convert list\n",
    "       values that are in target column.\n",
    "    '''\n",
    "    \n",
    "    df_select = df[[f\"{target_column}\"]].dropna()\n",
    "    df_word_result = pd.DataFrame()\n",
    "    for i in df[f\"{list_column}\"].dropna():\n",
    "        try:\n",
    "            #word_in_twogram = df_select[df_select[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)].head(10)  # Option\n",
    "            word_in_word_cluster = df_select[df_select[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)].head(100) \n",
    "        except:\n",
    "            pass        \n",
    "        word_in_word_cluster.insert(0,f\"{list_column}\",i)\n",
    "        df_word_result = pd.concat([df_word_result,word_in_word_cluster], axis=0)\n",
    "    df_word_result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_word_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_shared_count = word_count_result(df_shared_file,[\"threegram\"])\n",
    "#df_shared_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78359"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shared_file[\"twogram\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram</th>\n",
       "      <th>threegram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i am</td>\n",
       "      <td>i am not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i am</td>\n",
       "      <td>i am a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i am</td>\n",
       "      <td>no i am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am</td>\n",
       "      <td>what i am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am</td>\n",
       "      <td>i am the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334913</th>\n",
       "      <td>champion puzzle</td>\n",
       "      <td>a champion puzzle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334914</th>\n",
       "      <td>quality material</td>\n",
       "      <td>was quality material</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334915</th>\n",
       "      <td>quality mask</td>\n",
       "      <td>a quality mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334916</th>\n",
       "      <td>quality index</td>\n",
       "      <td>quality index is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334917</th>\n",
       "      <td>classical department</td>\n",
       "      <td>the classical department</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>334918 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     twogram                 threegram\n",
       "0                       i am                  i am not\n",
       "1                       i am                    i am a\n",
       "2                       i am                   no i am\n",
       "3                       i am                 what i am\n",
       "4                       i am                  i am the\n",
       "...                      ...                       ...\n",
       "334913       champion puzzle         a champion puzzle\n",
       "334914      quality material      was quality material\n",
       "334915          quality mask            a quality mask\n",
       "334916         quality index          quality index is\n",
       "334917  classical department  the classical department\n",
       "\n",
       "[334918 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_two_in_three = word_in_wordgroup(df_shared_file, \"twogram\", \"threegram\")\n",
    "df_two_in_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60870"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_two_in_three[\"twogram\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram</th>\n",
       "      <th>freq_twogram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i am</td>\n",
       "      <td>10494331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>do not</td>\n",
       "      <td>8972296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i do</td>\n",
       "      <td>4179914.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i will</td>\n",
       "      <td>3706224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>do you</td>\n",
       "      <td>3358227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206638</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206639</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206640</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206641</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206642</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206643 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       twogram  freq_twogram\n",
       "0         i am    10494331.0\n",
       "1       do not     8972296.0\n",
       "2         i do     4179914.0\n",
       "3       i will     3706224.0\n",
       "4       do you     3358227.0\n",
       "...        ...           ...\n",
       "206638     NaN           NaN\n",
       "206639     NaN           NaN\n",
       "206640     NaN           NaN\n",
       "206641     NaN           NaN\n",
       "206642     NaN           NaN\n",
       "\n",
       "[206643 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shared_select_twogram = df_shared_file.loc[:,[\"twogram\",\"freq_twogram\"]]\n",
    "df_shared_select_twogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_shared_twogram = set(df_shared_select_twogram[\"twogram\"])\n",
    "set_two_three = set(df_two_in_three[\"twogram\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>your screen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hologram is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>action august</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>realism do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>corner depressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60865</th>\n",
       "      <td>social plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60866</th>\n",
       "      <td>bouquet the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60867</th>\n",
       "      <td>cafe we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60868</th>\n",
       "      <td>training baby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60869</th>\n",
       "      <td>unit hit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60870 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                twogram\n",
       "0           your screen\n",
       "1           hologram is\n",
       "2         action august\n",
       "3            realism do\n",
       "4      corner depressed\n",
       "...                 ...\n",
       "60865       social plan\n",
       "60866       bouquet the\n",
       "60867           cafe we\n",
       "60868     training baby\n",
       "60869          unit hit\n",
       "\n",
       "[60870 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twogram_in_threegram = pd.DataFrame(set_two_three, columns=[\"twogram\"])  # columns=[\"twogram_in_threegram\"]\n",
    "df_twogram_in_threegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram_in_threegram</th>\n",
       "      <th>freq_two_in_three</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i am</td>\n",
       "      <td>10494331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>do not</td>\n",
       "      <td>8972296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i do</td>\n",
       "      <td>4179914.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i will</td>\n",
       "      <td>3706224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>do you</td>\n",
       "      <td>3358227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60865</th>\n",
       "      <td>lift music</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60866</th>\n",
       "      <td>counter no</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60867</th>\n",
       "      <td>system design</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60868</th>\n",
       "      <td>have champion</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60869</th>\n",
       "      <td>frequency active</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60870 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      twogram_in_threegram  freq_two_in_three\n",
       "0                     i am         10494331.0\n",
       "1                   do not          8972296.0\n",
       "2                     i do          4179914.0\n",
       "3                   i will          3706224.0\n",
       "4                   do you          3358227.0\n",
       "...                    ...                ...\n",
       "60865           lift music                4.0\n",
       "60866           counter no                4.0\n",
       "60867        system design                4.0\n",
       "60868        have champion                4.0\n",
       "60869     frequency active                4.0\n",
       "\n",
       "[60870 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twogram_in_threegram_freq = pd.merge(df_twogram_in_threegram, df_shared_select_twogram, how=\"left\", on=\"twogram\")\n",
    "df_twogram_in_threegram_freq.sort_values(by=\"freq_twogram\", ascending=False, inplace=True)\n",
    "df_twogram_in_threegram_freq.rename(columns={\"twogram\":\"twogram_in_threegram\",\"freq_twogram\":\"freq_two_in_three\"}, inplace=True)\n",
    "df_twogram_in_threegram_freq.reset_index(drop=True, inplace=True)\n",
    "df_twogram_in_threegram_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anonymous sponsor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>diet chips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>complete protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>university hall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17485</th>\n",
       "      <td>subsidy to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17486</th>\n",
       "      <td>shot type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17487</th>\n",
       "      <td>captain post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17488</th>\n",
       "      <td>it initiative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17489</th>\n",
       "      <td>miniature control</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17490 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 twogram\n",
       "0                    NaN\n",
       "1      anonymous sponsor\n",
       "2             diet chips\n",
       "3       complete protein\n",
       "4        university hall\n",
       "...                  ...\n",
       "17485         subsidy to\n",
       "17486          shot type\n",
       "17487       captain post\n",
       "17488      it initiative\n",
       "17489  miniature control\n",
       "\n",
       "[17490 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twogram_diff = pd.DataFrame(set_shared_twogram.difference(set_two_three), columns=[\"twogram\"])\n",
    "df_twogram_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram</th>\n",
       "      <th>freq_twogram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>media group</td>\n",
       "      <td>4604.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hello sheriff</td>\n",
       "      <td>501.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hello mark</td>\n",
       "      <td>457.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hello princess</td>\n",
       "      <td>433.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hello general</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145768</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145769</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145770</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145771</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145772</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145773 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               twogram  freq_twogram\n",
       "0          media group        4604.0\n",
       "1        hello sheriff         501.0\n",
       "2           hello mark         457.0\n",
       "3       hello princess         433.0\n",
       "4        hello general         398.0\n",
       "...                ...           ...\n",
       "145768             NaN           NaN\n",
       "145769             NaN           NaN\n",
       "145770             NaN           NaN\n",
       "145771             NaN           NaN\n",
       "145772             NaN           NaN\n",
       "\n",
       "[145773 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twogram_diff_freq = pd.merge(df_twogram_diff, df_shared_select_twogram, how=\"left\", on=\"twogram\")\n",
    "df_twogram_diff_freq.sort_values(by=\"freq_twogram\", ascending=False, inplace=True)\n",
    "df_twogram_diff_freq.reset_index(drop=True, inplace=True)\n",
    "df_twogram_diff_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shared_file[\"twogram\"] = df_twogram_diff_freq[\"twogram\"]\n",
    "df_shared_file[\"freq_twogram\"] = df_twogram_diff_freq[\"freq_twogram\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "      <th>twogram</th>\n",
       "      <th>freq_twogram</th>\n",
       "      <th>threegram</th>\n",
       "      <th>freq_threegram</th>\n",
       "      <th>fourgram</th>\n",
       "      <th>freq_fourgram</th>\n",
       "      <th>fivegram</th>\n",
       "      <th>freq_fivegram</th>\n",
       "      <th>sentence</th>\n",
       "      <th>freq_sentence</th>\n",
       "      <th>twogram_in_threegram</th>\n",
       "      <th>freq_two_in_three</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you</td>\n",
       "      <td>102069964.0</td>\n",
       "      <td>media group</td>\n",
       "      <td>4604.0</td>\n",
       "      <td>i do not</td>\n",
       "      <td>3520257</td>\n",
       "      <td>you do not have</td>\n",
       "      <td>160426.0</td>\n",
       "      <td>you do not have to</td>\n",
       "      <td>107450.0</td>\n",
       "      <td>of course</td>\n",
       "      <td>266277.0</td>\n",
       "      <td>i am</td>\n",
       "      <td>10494331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i</td>\n",
       "      <td>94447074.0</td>\n",
       "      <td>hello sheriff</td>\n",
       "      <td>501.0</td>\n",
       "      <td>i am not</td>\n",
       "      <td>1262941</td>\n",
       "      <td>i do not have</td>\n",
       "      <td>158788.0</td>\n",
       "      <td>i do not have a</td>\n",
       "      <td>34568.0</td>\n",
       "      <td>what is it</td>\n",
       "      <td>251203.0</td>\n",
       "      <td>do not</td>\n",
       "      <td>8972296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>77481215.0</td>\n",
       "      <td>hello mark</td>\n",
       "      <td>457.0</td>\n",
       "      <td>what do you</td>\n",
       "      <td>1120086</td>\n",
       "      <td>do not have to</td>\n",
       "      <td>150328.0</td>\n",
       "      <td>do not have to do</td>\n",
       "      <td>21572.0</td>\n",
       "      <td>stop it</td>\n",
       "      <td>152280.0</td>\n",
       "      <td>i do</td>\n",
       "      <td>4179914.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>58281119.0</td>\n",
       "      <td>hello princess</td>\n",
       "      <td>433.0</td>\n",
       "      <td>you do not</td>\n",
       "      <td>1010676</td>\n",
       "      <td>no i do not</td>\n",
       "      <td>105374.0</td>\n",
       "      <td>i do not have to</td>\n",
       "      <td>21499.0</td>\n",
       "      <td>i am</td>\n",
       "      <td>136931.0</td>\n",
       "      <td>i will</td>\n",
       "      <td>3706224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>50852895.0</td>\n",
       "      <td>hello general</td>\n",
       "      <td>398.0</td>\n",
       "      <td>do not you</td>\n",
       "      <td>644488</td>\n",
       "      <td>i do not like</td>\n",
       "      <td>99318.0</td>\n",
       "      <td>i do not like it</td>\n",
       "      <td>18564.0</td>\n",
       "      <td>i do</td>\n",
       "      <td>114801.0</td>\n",
       "      <td>do you</td>\n",
       "      <td>3358227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206638</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i control radiation</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206639</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the antibiotic i</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206640</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my radar screen</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206641</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cup will not</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206642</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stop on no</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206643 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word    frequency         twogram  freq_twogram            threegram  \\\n",
       "0       you  102069964.0     media group        4604.0             i do not   \n",
       "1         i   94447074.0   hello sheriff         501.0             i am not   \n",
       "2       the   77481215.0      hello mark         457.0          what do you   \n",
       "3        to   58281119.0  hello princess         433.0           you do not   \n",
       "4        is   50852895.0   hello general         398.0           do not you   \n",
       "...     ...          ...             ...           ...                  ...   \n",
       "206638  NaN          NaN             NaN           NaN  i control radiation   \n",
       "206639  NaN          NaN             NaN           NaN     the antibiotic i   \n",
       "206640  NaN          NaN             NaN           NaN      my radar screen   \n",
       "206641  NaN          NaN             NaN           NaN         cup will not   \n",
       "206642  NaN          NaN             NaN           NaN           stop on no   \n",
       "\n",
       "        freq_threegram         fourgram  freq_fourgram            fivegram  \\\n",
       "0              3520257  you do not have       160426.0  you do not have to   \n",
       "1              1262941    i do not have       158788.0     i do not have a   \n",
       "2              1120086   do not have to       150328.0   do not have to do   \n",
       "3              1010676      no i do not       105374.0    i do not have to   \n",
       "4               644488    i do not like        99318.0    i do not like it   \n",
       "...                ...              ...            ...                 ...   \n",
       "206638               4              NaN            NaN                 NaN   \n",
       "206639               4              NaN            NaN                 NaN   \n",
       "206640               4              NaN            NaN                 NaN   \n",
       "206641               4              NaN            NaN                 NaN   \n",
       "206642               4              NaN            NaN                 NaN   \n",
       "\n",
       "        freq_fivegram    sentence  freq_sentence twogram_in_threegram  \\\n",
       "0            107450.0   of course       266277.0                 i am   \n",
       "1             34568.0  what is it       251203.0               do not   \n",
       "2             21572.0     stop it       152280.0                 i do   \n",
       "3             21499.0        i am       136931.0               i will   \n",
       "4             18564.0        i do       114801.0               do you   \n",
       "...               ...         ...            ...                  ...   \n",
       "206638            NaN         NaN            NaN                  NaN   \n",
       "206639            NaN         NaN            NaN                  NaN   \n",
       "206640            NaN         NaN            NaN                  NaN   \n",
       "206641            NaN         NaN            NaN                  NaN   \n",
       "206642            NaN         NaN            NaN                  NaN   \n",
       "\n",
       "        freq_two_in_three  \n",
       "0              10494331.0  \n",
       "1               8972296.0  \n",
       "2               4179914.0  \n",
       "3               3706224.0  \n",
       "4               3358227.0  \n",
       "...                   ...  \n",
       "206638                NaN  \n",
       "206639                NaN  \n",
       "206640                NaN  \n",
       "206641                NaN  \n",
       "206642                NaN  \n",
       "\n",
       "[206643 rows x 14 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shared_twogram_process = pd.concat([df_shared_file,df_twogram_in_threegram_freq], axis=1)\n",
    "df_shared_twogram_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shared_twogram_process.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Result_With_Frequency{file_ext}2.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concat Result With Comma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_twogram = word_in_wordgroup(df_shared_twogram_process, \"word\", \"twogram\")\n",
    "df_word_order_threegram = word_in_wordgroup(df_shared_twogram_process, \"word\", \"threegram\") \n",
    "df_word_order_fourgram = word_in_wordgroup(df_shared_twogram_process, \"word\", \"fourgram\") \n",
    "df_word_order_fivegram = word_in_wordgroup(df_shared_twogram_process, \"word\", \"fivegram\")\n",
    "df_word_order_sentence = word_in_wordgroup(df_shared_twogram_process, \"word\", \"sentence\")\n",
    "df_word_order_twogram_threegram = word_in_wordgroup(df_shared_twogram_process, \"word\", \"twogram_in_threegram\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_join_twogram = df_word_order_twogram.groupby([\"word\"])[\"twogram\"].apply(\", \".join).reset_index()   # df_word_order_11.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].transform(lambda x: ','.join(x))\n",
    "df_word_order_join_threegram = df_word_order_threegram.groupby([\"word\"])[\"threegram\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_fourgram = df_word_order_fourgram.groupby([\"word\"])[\"fourgram\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_fivegram = df_word_order_fivegram.groupby([\"word\"])[\"fivegram\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_sentence = df_word_order_sentence.groupby([\"word\"])[\"sentence\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_twogram_threegram = df_word_order_twogram_threegram.groupby([\"word\"])[\"twogram_in_threegram\"].apply(\", \".join).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df_word_order_join_twogram,df_word_order_join_threegram,df_word_order_join_fourgram,df_word_order_join_fivegram,df_word_order_join_sentence,df_word_order_join_twogram_threegram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>twogram</th>\n",
       "      <th>threegram</th>\n",
       "      <th>fourgram</th>\n",
       "      <th>fivegram</th>\n",
       "      <th>sentence</th>\n",
       "      <th>twogram_in_threegram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>agent a, a terrorism, solo a, a tribune, mummy...</td>\n",
       "      <td>i am a, i have a, this is a, you have a, it wa...</td>\n",
       "      <td>i am not a, do not have a, do you have a, this...</td>\n",
       "      <td>i do not have a, you do not have a, we do not ...</td>\n",
       "      <td>a what, not a chance, what a surprise, i am a ...</td>\n",
       "      <td>have a, is a, was a, for a, in a, not a, like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abacus</td>\n",
       "      <td>your abacus, abacus and, abacus of, my abacus</td>\n",
       "      <td>like the abacus, abacus to the, and the abacus...</td>\n",
       "      <td>i like the abacus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>and the abacus, my abacus</td>\n",
       "      <td>the abacus, abacus to, abacus is, abacus you, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abnormal</td>\n",
       "      <td>on abnormal, this abnormal, for abnormal, you ...</td>\n",
       "      <td>i am abnormal, in the abnormal, am i abnormal,...</td>\n",
       "      <td>contact in the abnormal, and you have abnormal...</td>\n",
       "      <td>we have on the abnormal, the reaction to the a...</td>\n",
       "      <td>abnormal psychology, i am abnormal, am i abnor...</td>\n",
       "      <td>the abnormal, no abnormal, abnormal psychology...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>absorb</td>\n",
       "      <td>i absorb, absorb shock</td>\n",
       "      <td>to absorb the, will absorb the, and absorb it,...</td>\n",
       "      <td>it and absorb it, will absorb the radiation, t...</td>\n",
       "      <td>that will absorb the radiation, the ocean will...</td>\n",
       "      <td>absorb it, to absorb, i absorb, absorb this in...</td>\n",
       "      <td>to absorb, absorb the, absorb it, will absorb,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>absurd</td>\n",
       "      <td>absurd it, absurd you, what absurd, you absurd...</td>\n",
       "      <td>this is absurd, that is absurd, it is absurd, ...</td>\n",
       "      <td>absurd is not it, absurd your position is, you...</td>\n",
       "      <td>is it not absurd to, absurd name for a cricket...</td>\n",
       "      <td>this is absurd, that is absurd, it is absurd, ...</td>\n",
       "      <td>is absurd, absurd to, the absurd, this absurd,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>provoke</td>\n",
       "      <td>NaN</td>\n",
       "      <td>do not provoke, not provoke me, to provoke me,...</td>\n",
       "      <td>do not provoke me, i do not provoke, do not yo...</td>\n",
       "      <td>you do do not provoke, do not you provoke me, ...</td>\n",
       "      <td>do not provoke me, i do not provoke, do not pr...</td>\n",
       "      <td>to provoke, not provoke, provoke me, you provo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>quadrillion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a quadrillion electron</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a quadrillion</td>\n",
       "      <td>a quadrillion, quadrillion electron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>retouch</td>\n",
       "      <td>NaN</td>\n",
       "      <td>do not retouch, will retouch it, to retouch it...</td>\n",
       "      <td>we do not retouch, we will retouch it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>retouch it, not retouch, will retouch, to retouch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>sympathizer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>me a sympathizer, a communist sympathizer, is ...</td>\n",
       "      <td>am a communist sympathizer, brother was a symp...</td>\n",
       "      <td>i am a communist sympathizer, your brother was...</td>\n",
       "      <td>communist sympathizer, a sympathizer, i am a c...</td>\n",
       "      <td>a sympathizer, communist sympathizer, sympathi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>unisex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a unisex toilet, you have unisex, it was unise...</td>\n",
       "      <td>me it was unisex, this is a unisex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a unisex, a unisex toilet</td>\n",
       "      <td>a unisex, unisex toilet, have unisex, was unis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1700 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word                                            twogram  \\\n",
       "0               a  agent a, a terrorism, solo a, a tribune, mummy...   \n",
       "1          abacus      your abacus, abacus and, abacus of, my abacus   \n",
       "2        abnormal  on abnormal, this abnormal, for abnormal, you ...   \n",
       "3          absorb                             i absorb, absorb shock   \n",
       "4          absurd  absurd it, absurd you, what absurd, you absurd...   \n",
       "...           ...                                                ...   \n",
       "1695      provoke                                                NaN   \n",
       "1696  quadrillion                                                NaN   \n",
       "1697      retouch                                                NaN   \n",
       "1698  sympathizer                                                NaN   \n",
       "1699       unisex                                                NaN   \n",
       "\n",
       "                                              threegram  \\\n",
       "0     i am a, i have a, this is a, you have a, it wa...   \n",
       "1     like the abacus, abacus to the, and the abacus...   \n",
       "2     i am abnormal, in the abnormal, am i abnormal,...   \n",
       "3     to absorb the, will absorb the, and absorb it,...   \n",
       "4     this is absurd, that is absurd, it is absurd, ...   \n",
       "...                                                 ...   \n",
       "1695  do not provoke, not provoke me, to provoke me,...   \n",
       "1696                             a quadrillion electron   \n",
       "1697  do not retouch, will retouch it, to retouch it...   \n",
       "1698  me a sympathizer, a communist sympathizer, is ...   \n",
       "1699  a unisex toilet, you have unisex, it was unise...   \n",
       "\n",
       "                                               fourgram  \\\n",
       "0     i am not a, do not have a, do you have a, this...   \n",
       "1                                     i like the abacus   \n",
       "2     contact in the abnormal, and you have abnormal...   \n",
       "3     it and absorb it, will absorb the radiation, t...   \n",
       "4     absurd is not it, absurd your position is, you...   \n",
       "...                                                 ...   \n",
       "1695  do not provoke me, i do not provoke, do not yo...   \n",
       "1696                                                NaN   \n",
       "1697              we do not retouch, we will retouch it   \n",
       "1698  am a communist sympathizer, brother was a symp...   \n",
       "1699                 me it was unisex, this is a unisex   \n",
       "\n",
       "                                               fivegram  \\\n",
       "0     i do not have a, you do not have a, we do not ...   \n",
       "1                                                   NaN   \n",
       "2     we have on the abnormal, the reaction to the a...   \n",
       "3     that will absorb the radiation, the ocean will...   \n",
       "4     is it not absurd to, absurd name for a cricket...   \n",
       "...                                                 ...   \n",
       "1695  you do do not provoke, do not you provoke me, ...   \n",
       "1696                                                NaN   \n",
       "1697                                                NaN   \n",
       "1698  i am a communist sympathizer, your brother was...   \n",
       "1699                                                NaN   \n",
       "\n",
       "                                               sentence  \\\n",
       "0     a what, not a chance, what a surprise, i am a ...   \n",
       "1                             and the abacus, my abacus   \n",
       "2     abnormal psychology, i am abnormal, am i abnor...   \n",
       "3     absorb it, to absorb, i absorb, absorb this in...   \n",
       "4     this is absurd, that is absurd, it is absurd, ...   \n",
       "...                                                 ...   \n",
       "1695  do not provoke me, i do not provoke, do not pr...   \n",
       "1696                                      a quadrillion   \n",
       "1697                                                NaN   \n",
       "1698  communist sympathizer, a sympathizer, i am a c...   \n",
       "1699                          a unisex, a unisex toilet   \n",
       "\n",
       "                                   twogram_in_threegram  \n",
       "0     have a, is a, was a, for a, in a, not a, like ...  \n",
       "1     the abacus, abacus to, abacus is, abacus you, ...  \n",
       "2     the abnormal, no abnormal, abnormal psychology...  \n",
       "3     to absorb, absorb the, absorb it, will absorb,...  \n",
       "4     is absurd, absurd to, the absurd, this absurd,...  \n",
       "...                                                 ...  \n",
       "1695  to provoke, not provoke, provoke me, you provo...  \n",
       "1696                a quadrillion, quadrillion electron  \n",
       "1697  retouch it, not retouch, will retouch, to retouch  \n",
       "1698  a sympathizer, communist sympathizer, sympathi...  \n",
       "1699  a unisex, unisex toilet, have unisex, was unis...  \n",
       "\n",
       "[1700 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_order_join_all = reduce(lambda  left,right: pd.merge(left,right, on=['word'], how='outer'), dfs)  # left,right make left to right merge\n",
    "#df_word_order_join_all = reduce(lambda  right,left: pd.merge(left,right, on=['word'], how='outer'), dfs)  # right,left make right to left merge\n",
    "df_word_order_join_all  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "      <th>twogram</th>\n",
       "      <th>threegram</th>\n",
       "      <th>fourgram</th>\n",
       "      <th>fivegram</th>\n",
       "      <th>sentence</th>\n",
       "      <th>twogram_in_threegram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you</td>\n",
       "      <td>102069964</td>\n",
       "      <td>you korean, specific you, cypher you, you comm...</td>\n",
       "      <td>what do you, you do not, do not you, you have ...</td>\n",
       "      <td>you do not have, do you have a, no you do not,...</td>\n",
       "      <td>you do not have to, you do not have a, you do ...</td>\n",
       "      <td>and you, do you, you do, no you do not, you do...</td>\n",
       "      <td>do you, you have, you do, not you, you will, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i</td>\n",
       "      <td>94447074</td>\n",
       "      <td>anonymous i, i absorb, i contract, i wow, dies...</td>\n",
       "      <td>i do not, i am not, i am a, i have to, i will ...</td>\n",
       "      <td>i do not have, no i do not, i do not like, i a...</td>\n",
       "      <td>i do not have a, i do not have to, i do not li...</td>\n",
       "      <td>i am, i do, i will, i do not, i am not, no i d...</td>\n",
       "      <td>i am, i do, i will, i have, i was, and i, what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>77481215</td>\n",
       "      <td>the idealist, fantastic the, sophisticated the...</td>\n",
       "      <td>this is the, i am the, out of the, it was the,...</td>\n",
       "      <td>i am in the, i am not the, this is not the, do...</td>\n",
       "      <td>i do not have the, i do not like the, i am not...</td>\n",
       "      <td>what the, the what, the police, the baby, the ...</td>\n",
       "      <td>in the, to the, on the, of the, what the, for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>58281119</td>\n",
       "      <td>to booster, to princess, to formula, to capaci...</td>\n",
       "      <td>i have to, you have to, we have to, not have t...</td>\n",
       "      <td>do not have to, you will have to, do i have to...</td>\n",
       "      <td>you do not have to, do not have to do, i do no...</td>\n",
       "      <td>i have to, you do not have to, you have to, to...</td>\n",
       "      <td>have to, to the, to me, to do, to you, you to,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>50852895</td>\n",
       "      <td>is simultaneous, is feminine, is bourgeois, tu...</td>\n",
       "      <td>what is it, this is not, this is a, this is th...</td>\n",
       "      <td>this is not a, is that what you, this is not t...</td>\n",
       "      <td>you have to do is, is not that what you, is th...</td>\n",
       "      <td>what is it, what is this, what is that, it is,...</td>\n",
       "      <td>this is, is not, is it, what is, is that, it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2299</th>\n",
       "      <td>camp</td>\n",
       "      <td>6</td>\n",
       "      <td>captain camp, camp zombie, camp doctor, camp e...</td>\n",
       "      <td>in the camp, to the camp, we will camp, in thi...</td>\n",
       "      <td>this is base camp, me to the camp, the camp wa...</td>\n",
       "      <td>this for a band camp, this is a training camp,...</td>\n",
       "      <td>the camp, base camp, what camp, a camp, in the...</td>\n",
       "      <td>the camp, to camp, base camp, this camp, camp ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>session</td>\n",
       "      <td>6</td>\n",
       "      <td>practice session, detector session, session a,...</td>\n",
       "      <td>is in session, the session is, have a session,...</td>\n",
       "      <td>a group therapy session, congress is in sessio...</td>\n",
       "      <td>the meeting is in session, in a group therapy ...</td>\n",
       "      <td>i am in session, school is in session, this is...</td>\n",
       "      <td>in session, a session, the session, this sessi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2301</th>\n",
       "      <td>captain</td>\n",
       "      <td>6</td>\n",
       "      <td>captain axis, captain camp, control captain, c...</td>\n",
       "      <td>this is captain, i am captain, is the captain,...</td>\n",
       "      <td>this is the captain, i am the captain, this is...</td>\n",
       "      <td>i am the captain of, captain of the football t...</td>\n",
       "      <td>this is the captain, the captain, no captain, ...</td>\n",
       "      <td>the captain, you captain, captain i, is captai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2302</th>\n",
       "      <td>have</td>\n",
       "      <td>6</td>\n",
       "      <td>have name, have depressed, have tank, caps hav...</td>\n",
       "      <td>do not have, i have to, you have to, i have a,...</td>\n",
       "      <td>you do not have, i do not have, do not have to...</td>\n",
       "      <td>you do not have to, i do not have a, do not ha...</td>\n",
       "      <td>i have, have you, i have to, you do not have t...</td>\n",
       "      <td>i have, you have, have to, we have, have a, no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2303</th>\n",
       "      <td>point</td>\n",
       "      <td>6</td>\n",
       "      <td>point bar, million point, out point, point cap...</td>\n",
       "      <td>not the point, the point is, to the point, the...</td>\n",
       "      <td>what is the point, you have a point, is not th...</td>\n",
       "      <td>that is not the point, what is the point of, i...</td>\n",
       "      <td>the point is, no point, your point, what is th...</td>\n",
       "      <td>the point, a point, your point, point is, poin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2304 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  frequency                                            twogram  \\\n",
       "0         you  102069964  you korean, specific you, cypher you, you comm...   \n",
       "1           i   94447074  anonymous i, i absorb, i contract, i wow, dies...   \n",
       "2         the   77481215  the idealist, fantastic the, sophisticated the...   \n",
       "3          to   58281119  to booster, to princess, to formula, to capaci...   \n",
       "4          is   50852895  is simultaneous, is feminine, is bourgeois, tu...   \n",
       "...       ...        ...                                                ...   \n",
       "2299     camp          6  captain camp, camp zombie, camp doctor, camp e...   \n",
       "2300  session          6  practice session, detector session, session a,...   \n",
       "2301  captain          6  captain axis, captain camp, control captain, c...   \n",
       "2302     have          6  have name, have depressed, have tank, caps hav...   \n",
       "2303    point          6  point bar, million point, out point, point cap...   \n",
       "\n",
       "                                              threegram  \\\n",
       "0     what do you, you do not, do not you, you have ...   \n",
       "1     i do not, i am not, i am a, i have to, i will ...   \n",
       "2     this is the, i am the, out of the, it was the,...   \n",
       "3     i have to, you have to, we have to, not have t...   \n",
       "4     what is it, this is not, this is a, this is th...   \n",
       "...                                                 ...   \n",
       "2299  in the camp, to the camp, we will camp, in thi...   \n",
       "2300  is in session, the session is, have a session,...   \n",
       "2301  this is captain, i am captain, is the captain,...   \n",
       "2302  do not have, i have to, you have to, i have a,...   \n",
       "2303  not the point, the point is, to the point, the...   \n",
       "\n",
       "                                               fourgram  \\\n",
       "0     you do not have, do you have a, no you do not,...   \n",
       "1     i do not have, no i do not, i do not like, i a...   \n",
       "2     i am in the, i am not the, this is not the, do...   \n",
       "3     do not have to, you will have to, do i have to...   \n",
       "4     this is not a, is that what you, this is not t...   \n",
       "...                                                 ...   \n",
       "2299  this is base camp, me to the camp, the camp wa...   \n",
       "2300  a group therapy session, congress is in sessio...   \n",
       "2301  this is the captain, i am the captain, this is...   \n",
       "2302  you do not have, i do not have, do not have to...   \n",
       "2303  what is the point, you have a point, is not th...   \n",
       "\n",
       "                                               fivegram  \\\n",
       "0     you do not have to, you do not have a, you do ...   \n",
       "1     i do not have a, i do not have to, i do not li...   \n",
       "2     i do not have the, i do not like the, i am not...   \n",
       "3     you do not have to, do not have to do, i do no...   \n",
       "4     you have to do is, is not that what you, is th...   \n",
       "...                                                 ...   \n",
       "2299  this for a band camp, this is a training camp,...   \n",
       "2300  the meeting is in session, in a group therapy ...   \n",
       "2301  i am the captain of, captain of the football t...   \n",
       "2302  you do not have to, i do not have a, do not ha...   \n",
       "2303  that is not the point, what is the point of, i...   \n",
       "\n",
       "                                               sentence  \\\n",
       "0     and you, do you, you do, no you do not, you do...   \n",
       "1     i am, i do, i will, i do not, i am not, no i d...   \n",
       "2     what the, the what, the police, the baby, the ...   \n",
       "3     i have to, you do not have to, you have to, to...   \n",
       "4     what is it, what is this, what is that, it is,...   \n",
       "...                                                 ...   \n",
       "2299  the camp, base camp, what camp, a camp, in the...   \n",
       "2300  i am in session, school is in session, this is...   \n",
       "2301  this is the captain, the captain, no captain, ...   \n",
       "2302  i have, have you, i have to, you do not have t...   \n",
       "2303  the point is, no point, your point, what is th...   \n",
       "\n",
       "                                   twogram_in_threegram  \n",
       "0     do you, you have, you do, not you, you will, f...  \n",
       "1     i am, i do, i will, i have, i was, and i, what...  \n",
       "2     in the, to the, on the, of the, what the, for ...  \n",
       "3     have to, to the, to me, to do, to you, you to,...  \n",
       "4     this is, is not, is it, what is, is that, it i...  \n",
       "...                                                 ...  \n",
       "2299  the camp, to camp, base camp, this camp, camp ...  \n",
       "2300  in session, a session, the session, this sessi...  \n",
       "2301  the captain, you captain, captain i, is captai...  \n",
       "2302  i have, you have, have to, we have, have a, no...  \n",
       "2303  the point, a point, your point, point is, poin...  \n",
       "\n",
       "[2304 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option For Word Frequency\n",
    "if shared_word_frequency:\n",
    "    df_word_order_join_all = pd.merge(df_word_order_join_all,df_word_all, how=\"inner\", on=\"word\")\n",
    "    df_word_order_join_all.drop_duplicates(inplace=True)\n",
    "    df_word_order_join_all = df_word_order_join_all.loc[:,[\"word\",\"frequency\",\"twogram\",\"threegram\",\"fourgram\",\"fivegram\",\"sentence\",\"twogram_in_threegram\"]]\n",
    "    df_word_order_join_all.sort_values(by=\"frequency\", inplace=True, ascending=False)\n",
    "    df_word_order_join_all.reset_index(drop=True, inplace=True)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "df_word_order_join_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_join_all.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Join_Result_Without_Frequency{file_ext}2.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Move And Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['English_Turkish_Shared_Result_With_Frequency12.xlsx',\n",
       " 'English_Turkish_Shared_Join_Result_Without_Frequency12.xlsx']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file = glob.glob(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared*{file_ext}2.xlsx\")\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in output_file:\n",
    "    source = k # source directory\n",
    "    destination = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/5-Shared Word File/{lang_folder.capitalize()} {lang_pair.capitalize()}\"\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in output_file:\n",
    "    try:\n",
    "        os.remove(i)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prefix Suffix Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "lang_pair = \"Italian\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "# adding native word to shared word\n",
    "word_start = 0  # 0  # native word start index\n",
    "word_end = 28  # 28  # native word end index\n",
    "\n",
    "# word sample\n",
    "word_sample = True  # True, False\n",
    "word_sample_num = 20\n",
    "\n",
    "# shared word frequency\n",
    "shared_word_frequency = True  # True, False\n",
    "\n",
    "# prefix suffix file\n",
    "prefix_suffix = True  # True, False  # always must be True in this part\n",
    "native_word = False # True for adding native word\n",
    "etymology_word = True  # True for adding etymology word\n",
    "\n",
    "# adding output file extention\n",
    "if (not prefix_suffix) & etymology_word & native_word:\n",
    "    file_ext = \"1\"\n",
    "elif (not prefix_suffix) & etymology_word & (not native_word):\n",
    "    file_ext = \"2\"\n",
    "elif prefix_suffix & etymology_word & native_word:\n",
    "    file_ext = \"3\"\n",
    "elif prefix_suffix & etymology_word & (not native_word):\n",
    "    file_ext = \"4\"\n",
    "elif prefix_suffix & (not etymology_word) & native_word:\n",
    "    file_ext = \"5\"\n",
    "elif (not prefix_suffix) & (not etymology_word) & native_word:\n",
    "    file_ext = \"6\"\n",
    "else:\n",
    "    file_ext = \"7\"              \n",
    "# 1 => for native word and etymology word without prefix suffix. \n",
    "# 2 => for only etymology word without prefix suffix. \n",
    "# 3 => for native word and etymology word with prefix suffix. prefix_suffix, native_word and etymology_word must be True. \n",
    "# 4 => for only etymology word with prefix suffix.\n",
    "# 5 => for only native word with prefix suffix.\n",
    "# 6 => for only native word without prefix suffix.\n",
    "print(f\"{file_ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_in_wordgroup(df, source_column, target_column):\n",
    "\n",
    "    '''word_in_wordgroup(df, \"word\", \"twogram\"):\n",
    "       df is dataframe, source_column and target_column are \n",
    "       dataframe column string name. source_column convert list\n",
    "       values that are in target column.\n",
    "    '''\n",
    "    \n",
    "    df_select = df[[f\"{target_column}\"]].dropna()\n",
    "    df_word_result = pd.DataFrame()\n",
    "    for i in df[f\"{source_column}\"].dropna():\n",
    "        try:\n",
    "            if word_sample:\n",
    "                word_in_word_cluster = df_select[df_select[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)].head(word_sample_num)  # Option\n",
    "            else:\n",
    "                word_in_word_cluster = df_select[df_select[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)] \n",
    "        except:\n",
    "            pass        \n",
    "        word_in_word_cluster.insert(0,f\"{source_column}\",i)\n",
    "        df_word_result = pd.concat([df_word_result,word_in_word_cluster], axis=0)\n",
    "    df_word_result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_word_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.lower().capitalize()}/Deployment/Data/Word/Word_Merge_Preprocess.xlsx\")\n",
    "df_word_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_prefix_suffix = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_{word_end}_Word_Prefix_Suffix_Custom_Result_Manuel.xlsx\")\n",
    "df_word_prefix_suffix = df_word_prefix_suffix[[\"search_word\",\"word\"]]\n",
    "df_word_prefix_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ety_prefix_suffix = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Word_Prefix_Suffix_Custom_Result.xlsx\")\n",
    "df_ety_prefix_suffix = df_ety_prefix_suffix[[\"search_word\",\"word\"]]\n",
    "df_ety_prefix_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file_ext == \"3\":\n",
    "    df_all_word = pd.concat([df_word_prefix_suffix,df_ety_prefix_suffix],axis=0)\n",
    "    df_all_word.drop_duplicates(inplace=True)\n",
    "    df_all_word.reset_index(drop=True, inplace=True)\n",
    "elif file_ext == \"4\":\n",
    "    df_all_word = df_ety_prefix_suffix\n",
    "    df_all_word.drop_duplicates(inplace=True)\n",
    "    df_all_word.reset_index(drop=True, inplace=True)\n",
    "elif file_ext == \"5\":\n",
    "    df_all_word = df_word_prefix_suffix\n",
    "    df_all_word.drop_duplicates(inplace=True)\n",
    "    df_all_word.reset_index(drop=True, inplace=True)\n",
    "else:\n",
    "    pass\n",
    "    \n",
    "df_all_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_word.search_word.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_word.word.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shared_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/4-Shared Word/{lang_folder.capitalize()} {lang_pair.capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Result_With_Frequency{file_ext}.xlsx\")\n",
    "#df_shared_all = pd.read_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Result_With_Frequency.xlsx\")\n",
    "df_shared_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_twogram = word_in_wordgroup(df_shared_all, \"word\", \"twogram\")\n",
    "df_word_order_threegram = word_in_wordgroup(df_shared_all, \"word\", \"threegram\") \n",
    "df_word_order_fourgram = word_in_wordgroup(df_shared_all, \"word\", \"fourgram\") \n",
    "df_word_order_fivegram = word_in_wordgroup(df_shared_all, \"word\", \"fivegram\")\n",
    "df_word_order_sentence = word_in_wordgroup(df_shared_all, \"word\", \"sentence\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_twogram = pd.merge(df_word_order_twogram,df_all_word, how=\"inner\", on=\"word\")\n",
    "df_word_order_threegram = pd.merge(df_word_order_threegram,df_all_word, how=\"inner\", on=\"word\")\n",
    "df_word_order_fourgram = pd.merge(df_word_order_fourgram,df_all_word, how=\"inner\", on=\"word\")\n",
    "df_word_order_fivegram = pd.merge(df_word_order_fivegram,df_all_word, how=\"inner\", on=\"word\")\n",
    "df_word_order_sentence = pd.merge(df_word_order_sentence,df_all_word, how=\"inner\", on=\"word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_join_twogram = df_word_order_twogram.groupby([\"search_word\"])[\"twogram\"].apply(\", \".join).reset_index()   # df_word_order_11.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].transform(lambda x: ','.join(x))\n",
    "df_word_order_join_threegram = df_word_order_threegram.groupby([\"search_word\"])[\"threegram\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_fourgram = df_word_order_fourgram.groupby([\"search_word\"])[\"fourgram\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_fivegram = df_word_order_fivegram.groupby([\"search_word\"])[\"fivegram\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_sentence = df_word_order_sentence.groupby([\"search_word\"])[\"sentence\"].apply(\", \".join).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df_word_order_join_twogram,df_word_order_join_threegram,df_word_order_join_fourgram,df_word_order_join_fivegram,df_word_order_join_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_join_all = reduce(lambda  left,right: pd.merge(left,right, on=['search_word'], how='outer'), dfs)  # left,right make left to right merge\n",
    "#df_word_order_join_all = reduce(lambda  right,left: pd.merge(left,right, on=['word'], how='outer'), dfs)  # right,left make right to left merge\n",
    "df_word_order_join_all.rename(columns={\"search_word\":\"word\"}, inplace=True)\n",
    "df_word_order_join_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option For Word Frequency\n",
    "if shared_word_frequency:\n",
    "    df_word_order_join_all = pd.merge(df_word_order_join_all,df_word_all, how=\"left\", on=\"word\")\n",
    "    df_word_order_join_all.drop_duplicates(inplace=True)\n",
    "    df_word_order_join_all = df_word_order_join_all.loc[:,[\"word\",\"frequency\",\"twogram\",\"threegram\",\"fourgram\",\"fivegram\",\"sentence\"]]\n",
    "    df_word_order_join_all.sort_values(by=\"frequency\", inplace=True, ascending=False)\n",
    "    df_word_order_join_all.reset_index(drop=True, inplace=True)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "df_word_order_join_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_join_all.word.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_join_all.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Join_Result_Without_Frequency{file_ext}3.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Move And Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file2 = glob.glob(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared*{file_ext}3.xlsx\")\n",
    "output_file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in output_file2:\n",
    "    source = l # source directory\n",
    "    destination = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/5-Shared Word File/{lang_folder.capitalize()} {lang_pair.capitalize()}\"\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in output_file2:\n",
    "    try:\n",
    "        os.remove(j)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prefix Suffix Shared File Word Result Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## language pair (same previous part parameter)\n",
    "#lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "#lang_pair = \"French\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "# word sample\n",
    "word_sample_num = 20\n",
    "\n",
    "print(f\"{file_ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_strip_func(x):\n",
    "    try:\n",
    "        var_low = x.lower()\n",
    "        var_out = var_low.strip()\n",
    "    except:\n",
    "        var_out = x\n",
    "    return var_out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shared_process_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/5-Shared Word File/{lang_folder.capitalize()} {lang_pair.capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Join_Result_Without_Frequency{file_ext}3.xlsx\")\n",
    "df_shared_process_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.lower().capitalize()}/Deployment/Data/Word/Word_Merge_Preprocess.xlsx\")\n",
    "df_word_all = df_word_all.loc[:,[\"word\",\"frequency\"]]\n",
    "df_word_all[\"word\"] = df_word_all[\"word\"].apply(lambda x: lower_strip_func(x))\n",
    "df_word_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twogram_all = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Twogram_Merge.csv\")\n",
    "df_twogram_all = df_twogram_all.loc[:,[\"twogram\",\"frequency\"]]\n",
    "df_twogram_all[\"twogram\"] = df_twogram_all[\"twogram\"].apply(lambda x: lower_strip_func(x))\n",
    "df_twogram_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_threegram_all = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Threegram_Merge.csv\")\n",
    "df_threegram_all = df_threegram_all.loc[:,[\"threegram\",\"frequency\"]]\n",
    "df_threegram_all[\"threegram\"] = df_threegram_all[\"threegram\"].apply(lambda x: lower_strip_func(x))\n",
    "df_threegram_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fourgram_all = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Fourgram_Merge.csv\")\n",
    "df_fourgram_all = df_fourgram_all.loc[:,[\"fourgram\",\"frequency\"]]\n",
    "df_fourgram_all[\"fourgram\"] = df_fourgram_all[\"fourgram\"].apply(lambda x: lower_strip_func(x))\n",
    "df_fourgram_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fivegram_all = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Fivegram_Merge.csv\")\n",
    "df_fivegram_all = df_fivegram_all.loc[:,[\"fivegram\",\"frequency\"]]\n",
    "df_fivegram_all[\"fivegram\"] = df_fivegram_all[\"fivegram\"].apply(lambda x: lower_strip_func(x))\n",
    "df_fivegram_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentence_all = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/Sentence/Merge/Sentence_Merge.csv\")\n",
    "df_sentence_all = df_sentence_all.loc[:,[\"sentence\",\"frequency\"]]\n",
    "df_sentence_all[\"sentence\"] = df_sentence_all[\"sentence\"].apply(lambda x: lower_strip_func(x))\n",
    "df_sentence_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_shared_process_all)):\n",
    "    # column result\n",
    "    try:\n",
    "        # column result\n",
    "        df_two_var = pd.DataFrame(df_shared_process_all.loc[i,\"twogram\"].split(\", \"), columns=[\"twogram\"])\n",
    "        # merge with all\n",
    "        df_two_var_merge = pd.merge(df_two_var, df_twogram_all, how=\"left\", on=\"twogram\")\n",
    "        df_two_var_merge.sort_values(by=\"frequency\", ascending=False, inplace=True)\n",
    "        df_two_var_merge_select = df_two_var_merge.head(word_sample_num)\n",
    "        # to list value\n",
    "        df_two_var_list = df_two_var_merge_select[\"twogram\"].to_list()\n",
    "        # list join\n",
    "        df_two_var_list_join = \", \".join(df_two_var_list)\n",
    "        # change value\n",
    "        df_shared_process_all.loc[i,\"twogram\"] = df_two_var_list_join\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        # column result\n",
    "        df_three_var = pd.DataFrame(df_shared_process_all.loc[i,\"threegram\"].split(\", \"), columns=[\"threegram\"])\n",
    "        # merge with all\n",
    "        df_three_var_merge = pd.merge(df_three_var, df_threegram_all, how=\"left\", on=\"threegram\")\n",
    "        df_three_var_merge.sort_values(by=\"frequency\", ascending=False, inplace=True)\n",
    "        df_three_var_merge_select = df_three_var_merge.head(word_sample_num)\n",
    "        # to list value\n",
    "        df_three_var_list = df_three_var_merge_select[\"threegram\"].to_list()\n",
    "        # list join\n",
    "        df_three_var_list_join = \", \".join(df_three_var_list)\n",
    "        # change value\n",
    "        df_shared_process_all.loc[i,\"threegram\"] = df_three_var_list_join\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        # column result\n",
    "        df_four_var = pd.DataFrame(df_shared_process_all.loc[i,\"fourgram\"].split(\", \"), columns=[\"fourgram\"])\n",
    "        # merge with all\n",
    "        df_four_var_merge = pd.merge(df_four_var, df_fourgram_all, how=\"left\", on=\"fourgram\")\n",
    "        df_four_var_merge.sort_values(by=\"frequency\", ascending=False, inplace=True)\n",
    "        df_four_var_merge_select = df_four_var_merge.head(word_sample_num)\n",
    "        # to list value\n",
    "        df_four_var_list = df_four_var_merge_select[\"fourgram\"].to_list()\n",
    "        # list join\n",
    "        df_four_var_list_join = \", \".join(df_four_var_list)\n",
    "        # change value\n",
    "        df_shared_process_all.loc[i,\"fourgram\"] = df_four_var_list_join\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        # column result\n",
    "        df_five_var = pd.DataFrame(df_shared_process_all.loc[i,\"fivegram\"].split(\", \"), columns=[\"fivegram\"])\n",
    "        # merge with all\n",
    "        df_five_var_merge = pd.merge(df_five_var, df_fivegram_all, how=\"left\", on=\"fivegram\")\n",
    "        df_five_var_merge.sort_values(by=\"frequency\", ascending=False, inplace=True)\n",
    "        df_five_var_merge_select = df_five_var_merge.head(word_sample_num)\n",
    "        # to list value\n",
    "        df_five_var_list = df_five_var_merge_select[\"fivegram\"].to_list()\n",
    "        # list join\n",
    "        df_five_var_list_join = \", \".join(df_five_var_list)\n",
    "        # change value\n",
    "        df_shared_process_all.loc[i,\"fivegram\"] = df_five_var_list_join\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        # column result\n",
    "        df_sentence_var = pd.DataFrame(df_shared_process_all.loc[i,\"sentence\"].split(\", \"), columns=[\"sentence\"])\n",
    "        # merge with all\n",
    "        df_sentence_var_merge = pd.merge(df_sentence_var, df_sentence_all, how=\"left\", on=\"sentence\")\n",
    "        df_sentence_var_merge.sort_values(by=\"frequency\", ascending=False, inplace=True)\n",
    "        df_sentence_var_merge_select = df_sentence_var_merge.head(word_sample_num)\n",
    "        # to list value\n",
    "        df_sentence_var_list = df_sentence_var_merge_select[\"sentence\"].to_list()\n",
    "        # list join\n",
    "        df_sentence_var_list_join = \", \".join(df_sentence_var_list)\n",
    "        # change value\n",
    "        df_shared_process_all.loc[i,\"sentence\"] = df_sentence_var_list_join\n",
    "    except:\n",
    "        pass      \n",
    "\n",
    "df_shared_process_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_shared_process_all.sort_values(by=\"frequency\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shared_process_all.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Join_Select_Result_Without_Frequency{file_ext}4.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Move And Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file3 = glob.glob(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared*_Select_*{file_ext}4.xlsx\")\n",
    "output_file3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in output_file3:\n",
    "    source = l # source directory\n",
    "    destination = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/5-Shared Word File/{lang_folder.capitalize()} {lang_pair.capitalize()}\"\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in output_file3:\n",
    "    try:\n",
    "        os.remove(j)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Count Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "lang_pair = \"English\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/5-Shared Word File/{lang_folder.capitalize()} {lang_pair.capitalize()}\").mkdir(parents=True, exist_ok=True)\n",
    "Path(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/Deploy Result Manuel\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_result(df,column_list): # df is dataframe, column_list is list value\n",
    "    '''\n",
    "    word_count_bool(df, column_list): df columns word count for word frequency\\n\n",
    "    df is dataframe, column_list is list value\\n\n",
    "    word_count_bool(df, [\"word\",\"twogram\"]):\n",
    "    '''\n",
    "    list_all = []\n",
    "    for i in df.loc[:,[x for x in column_list]].columns:\n",
    "        var_list = df[f\"{i}\"].dropna().tolist()\n",
    "        for j in var_list:\n",
    "            list_all.append(j)\n",
    "    text = \" \".join(list_all)\n",
    "    word_list = re.findall(r\"\\w+\",text, re.UNICODE)\n",
    "    df_word_list = pd.DataFrame(word_list, columns=[\"word\"])\n",
    "    #df_word_list.rename(columns={0:\"word\"}, inplace=True)\n",
    "    df_word_count = pd.DataFrame(df_word_list.value_counts())\n",
    "    df_word_count.reset_index(inplace=True)\n",
    "    df_word_count.rename(columns={0:\"word_count\"}, inplace=True)\n",
    "    \n",
    "    return  df_word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hybrid Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybrid = pd.read_excel(\"Turkish English manual selected 2 gram hybrids 3.xlsx\", sheet_name=\"2 gram hybrid\")\n",
    "df_hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybrid_count = word_count_result(df_hybrid, [\"twogram_pair1\",\"twogram_pair2\",\"twogram_pair3\",\"twogram_pair4\"])\n",
    "df_hybrid_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybrid_count_merge = pd.merge(df_hybrid,df_hybrid_count,how=\"left\",on=\"word\")\n",
    "df_hybrid_count_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybrid_count_merge2 = pd.merge(df_hybrid,df_hybrid_count,how=\"outer\",on=\"word\")\n",
    "df_hybrid_count_merge2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(f\"{lang_folder}_{lang_pair}_Hybrid_Word_Count.xlsx\", engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybrid_count_merge.to_excel(writer, sheet_name='28_Hybrid_Word_Count', index=False)\n",
    "df_hybrid_count_merge2.to_excel(writer, sheet_name='All_Hybrid_Word_Count', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = pd.read_excel(\"Turkish English manual selected 2 gram hybrids 3.xlsx\", sheet_name=\"2 gram target\")\n",
    "df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_count = word_count_result(df_target, [\"twogram_1\",\"twogram_2\",\"twogram_3\",\"twogram_4\"])\n",
    "df_target_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_count_merge = pd.merge(df_target,df_target_count,how=\"left\",on=\"word\")\n",
    "df_target_count_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_count_merge2 = pd.merge(df_target,df_target_count,how=\"outer\",on=\"word\")\n",
    "df_target_count_merge2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer2 = pd.ExcelWriter(f\"{lang_folder}_{lang_pair}_Target_Word_Count.xlsx\", engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_count_merge.to_excel(writer2, sheet_name='28_Target_Word_Count', index=False)\n",
    "df_target_count_merge2.to_excel(writer2, sheet_name='All_Target_Word_Count', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer2.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All Target Hybrid Word Count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybrid_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_word = pd.concat([df_target_count, df_hybrid_count], axis=0)\n",
    "df_all_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_word.groupby(\"word\")[[\"word_count\"]].sum().reset_index(inplace=True)\n",
    "df_all_word.sort_values(by=\"word_count\", ascending=False, inplace=True)\n",
    "df_all_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_word.to_excel(f\"{lang_folder}_{lang_pair}_Target_Hybrid_Word_Count.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Move And Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file4 = glob.glob(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_*_Word_Count.xlsx\")\n",
    "output_file4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in output_file4:\n",
    "    source = o # source directory\n",
    "    destination = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/5-Shared Word File/{lang_folder.capitalize()} {lang_pair.capitalize()}\"\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in output_file4:\n",
    "    try:\n",
    "        os.remove(p)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Prefix Suffix Control ????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>twogram_pair1</th>\n",
       "      <th>twogram_pair2</th>\n",
       "      <th>twogram_pair3</th>\n",
       "      <th>twogram_pair4</th>\n",
       "      <th>twogram_pair5</th>\n",
       "      <th>twogram_pair6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kontrol</td>\n",
       "      <td>trafik kontrol</td>\n",
       "      <td>kontrol paneli</td>\n",
       "      <td>sistem kontrolü</td>\n",
       "      <td>trafik kontrolü</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doktor</td>\n",
       "      <td>doktor raporu</td>\n",
       "      <td>doktorun numarası</td>\n",
       "      <td>doktorun telefonu</td>\n",
       "      <td>doktorun ofisine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>polis</td>\n",
       "      <td>polis şefi</td>\n",
       "      <td>trafik polisi</td>\n",
       "      <td>sivil polis</td>\n",
       "      <td>polis raporu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dolar</td>\n",
       "      <td>milyon dolar</td>\n",
       "      <td>milyon dolarlık</td>\n",
       "      <td>milyonlarca dolar</td>\n",
       "      <td>amerikan doları</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>komik</td>\n",
       "      <td>komik film</td>\n",
       "      <td>komik videoları</td>\n",
       "      <td>komik tipler</td>\n",
       "      <td>komik karakter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>alarm</td>\n",
       "      <td>genel alarm</td>\n",
       "      <td>alarm sistemi</td>\n",
       "      <td>alarm şifresi</td>\n",
       "      <td>kriz alarmı</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>motor</td>\n",
       "      <td>jet motoru</td>\n",
       "      <td>motorlar stop</td>\n",
       "      <td>motor kontrol</td>\n",
       "      <td>turbo motor</td>\n",
       "      <td>elektrik motorları</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>otobüs</td>\n",
       "      <td>okul otobüsü</td>\n",
       "      <td>takım otobüse</td>\n",
       "      <td>otobüs terminali</td>\n",
       "      <td>turist otobüsü</td>\n",
       "      <td>tur otobüsü</td>\n",
       "      <td>otobüs turu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>manyak</td>\n",
       "      <td>psikopat manyak</td>\n",
       "      <td>manyak film</td>\n",
       "      <td>manyak numara</td>\n",
       "      <td>manyak parti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>makine</td>\n",
       "      <td>fotoğraf makinesi</td>\n",
       "      <td>kahve makinesi</td>\n",
       "      <td>tost makinesi</td>\n",
       "      <td>fotokopi makinesi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word      twogram_pair1        twogram_pair2       twogram_pair3  \\\n",
       "0   kontrol     trafik kontrol       kontrol paneli     sistem kontrolü   \n",
       "1    doktor      doktor raporu    doktorun numarası   doktorun telefonu   \n",
       "2     polis         polis şefi        trafik polisi         sivil polis   \n",
       "3     dolar       milyon dolar      milyon dolarlık   milyonlarca dolar   \n",
       "4     komik         komik film      komik videoları        komik tipler   \n",
       "..      ...                ...                  ...                 ...   \n",
       "71    alarm        genel alarm        alarm sistemi       alarm şifresi   \n",
       "72    motor         jet motoru        motorlar stop       motor kontrol   \n",
       "73   otobüs       okul otobüsü        takım otobüse    otobüs terminali   \n",
       "74   manyak    psikopat manyak          manyak film       manyak numara   \n",
       "75   makine  fotoğraf makinesi       kahve makinesi       tost makinesi   \n",
       "\n",
       "         twogram_pair4        twogram_pair5 twogram_pair6  \n",
       "0      trafik kontrolü                  NaN           NaN  \n",
       "1     doktorun ofisine                  NaN           NaN  \n",
       "2         polis raporu                  NaN           NaN  \n",
       "3      amerikan doları                  NaN           NaN  \n",
       "4       komik karakter                  NaN           NaN  \n",
       "..                 ...                  ...           ...  \n",
       "71         kriz alarmı                  NaN           NaN  \n",
       "72         turbo motor   elektrik motorları           NaN  \n",
       "73      turist otobüsü          tur otobüsü   otobüs turu  \n",
       "74        manyak parti                  NaN           NaN  \n",
       "75   fotokopi makinesi                  NaN           NaN  \n",
       "\n",
       "[76 rows x 7 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shared_word_manuel = pd.read_excel(\"Turkish English Manual Selected 2 Gram Hybrids2.xlsx\", sheet_name=\"2 gram SV\")\n",
    "df_shared_word_manuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['twogram_pair1', 'twogram_pair2', 'twogram_pair3', 'twogram_pair4',\n",
       "       'twogram_pair5', 'twogram_pair6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shared_word_manuel.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>numarası</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kahve</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>futbol</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>okul</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>raporu</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>ligi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>limiti</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>limuzin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>listesi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>şoku</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>313 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  word_count\n",
       "0    numarası           9\n",
       "1       kahve           8\n",
       "2      futbol           8\n",
       "3        okul           8\n",
       "4      raporu           7\n",
       "..        ...         ...\n",
       "308      ligi           1\n",
       "309    limiti           1\n",
       "310   limuzin           1\n",
       "311   listesi           1\n",
       "312      şoku           1\n",
       "\n",
       "[313 rows x 2 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shared_word_manuel_count = word_count_result(df_shared_word_manuel, df_shared_word_manuel.columns[1:])\n",
    "df_shared_word_manuel_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_word</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ama</td>\n",
       "      <td>ama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bana</td>\n",
       "      <td>bana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ben</td>\n",
       "      <td>ben</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ben</td>\n",
       "      <td>bence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ben</td>\n",
       "      <td>bende</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6355</th>\n",
       "      <td>şut</td>\n",
       "      <td>şutu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6356</th>\n",
       "      <td>şut</td>\n",
       "      <td>şutunu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6357</th>\n",
       "      <td>şırınga</td>\n",
       "      <td>şırınga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6358</th>\n",
       "      <td>şırınga</td>\n",
       "      <td>şırıngayla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6359</th>\n",
       "      <td>şırınga</td>\n",
       "      <td>şırıngayı</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6360 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     search_word        word\n",
       "0            ama         ama\n",
       "1           bana        bana\n",
       "2            ben         ben\n",
       "3            ben       bence\n",
       "4            ben       bende\n",
       "...          ...         ...\n",
       "6355         şut        şutu\n",
       "6356         şut      şutunu\n",
       "6357     şırınga     şırınga\n",
       "6358     şırınga  şırıngayla\n",
       "6359     şırınga   şırıngayı\n",
       "\n",
       "[6360 rows x 2 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_prefix = pd.read_excel(\"Turkish_English_Native_And_Shared_Word_Prefix_Suffix_Custom_Concat.xlsx\")\n",
    "df_word_prefix.drop_duplicates(inplace=True)\n",
    "df_word_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>word_count</th>\n",
       "      <th>search_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>numarası</td>\n",
       "      <td>9</td>\n",
       "      <td>numara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kahve</td>\n",
       "      <td>8</td>\n",
       "      <td>kahve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>futbol</td>\n",
       "      <td>8</td>\n",
       "      <td>futbol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>okul</td>\n",
       "      <td>8</td>\n",
       "      <td>okul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>raporu</td>\n",
       "      <td>7</td>\n",
       "      <td>rapor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>ligi</td>\n",
       "      <td>1</td>\n",
       "      <td>lig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>limiti</td>\n",
       "      <td>1</td>\n",
       "      <td>limit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>limuzin</td>\n",
       "      <td>1</td>\n",
       "      <td>limuzin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>listesi</td>\n",
       "      <td>1</td>\n",
       "      <td>liste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>şoku</td>\n",
       "      <td>1</td>\n",
       "      <td>şok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>337 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  word_count search_word\n",
       "0    numarası           9      numara\n",
       "1       kahve           8       kahve\n",
       "2      futbol           8      futbol\n",
       "3        okul           8        okul\n",
       "4      raporu           7       rapor\n",
       "..        ...         ...         ...\n",
       "332      ligi           1         lig\n",
       "333    limiti           1       limit\n",
       "334   limuzin           1     limuzin\n",
       "335   listesi           1       liste\n",
       "336      şoku           1         şok\n",
       "\n",
       "[337 rows x 3 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge_test = pd.merge(df_shared_word_manuel_count,df_word_prefix,how=\"left\",on=\"word\")\n",
    "df_merge_test.drop_duplicates(inplace=True)\n",
    "df_merge_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_word</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>telefon</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>numara</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>film</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doktor</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>okul</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>ekspres</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>ekipman</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>orijin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>orijinal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>pijama</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    search_word  word_count\n",
       "0       telefon          11\n",
       "1        numara          11\n",
       "2          film          10\n",
       "3        doktor          10\n",
       "4          okul           9\n",
       "..          ...         ...\n",
       "238     ekspres           1\n",
       "239     ekipman           1\n",
       "240      orijin           1\n",
       "241    orijinal           1\n",
       "242      pijama           1\n",
       "\n",
       "[243 rows x 2 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_count_result = pd.DataFrame(df_merge_test.groupby(\"search_word\")[\"word_count\"].sum())\n",
    "df_count_result.sort_values(by=\"word_count\", ascending=False, inplace=True)\n",
    "df_count_result.reset_index(inplace=True)\n",
    "df_count_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_result.to_excel(\"Turkish_English_2 gram hybrid_SV_Word_Count.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Youtube Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "lang_pair = \"English\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "# parameter\n",
    "sheets = \"2 gram hybrid\"  # 2 gram target, 2 gram hybrid\n",
    "time_shift = 0.6\n",
    "sample_num = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sentence</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:02:51.948</td>\n",
       "      <td>00:02:58.829</td>\n",
       "      <td>özgür bunlar normalde kamyon daha büyük araçla...</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:03:00.956</td>\n",
       "      <td>00:03:04.236</td>\n",
       "      <td>burcu arka tarafı bağlamak kolay olmayacak</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:03:13.434</td>\n",
       "      <td>00:03:16.327</td>\n",
       "      <td>özgür arabaya yarım tur attıracağım</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:03:17.235</td>\n",
       "      <td>00:03:21.338</td>\n",
       "      <td>burcu biraz daha devam et devam et tamam oldu</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:03:27.806</td>\n",
       "      <td>00:03:33.383</td>\n",
       "      <td>burcu şimdilik iki tekere takacağız ama kar ka...</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036932</th>\n",
       "      <td>00:07:51.970</td>\n",
       "      <td>00:07:52.470</td>\n",
       "      <td>umarız ki bu büyük ve güçlü teknoloji yanlış e...</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036933</th>\n",
       "      <td>00:07:52.470</td>\n",
       "      <td>00:08:02.304</td>\n",
       "      <td>daha faydalı ve özgün kurumlarda herkesin eşit...</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036934</th>\n",
       "      <td>00:08:02.498</td>\n",
       "      <td>00:08:04.178</td>\n",
       "      <td>i zlediğiniz için teşekkürler</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036935</th>\n",
       "      <td>00:08:04.178</td>\n",
       "      <td>00:08:08.089</td>\n",
       "      <td>yararlandığım kaynakları açıklamada link olara...</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036936</th>\n",
       "      <td>00:08:08.089</td>\n",
       "      <td>00:08:11.770</td>\n",
       "      <td>i leri düzey okuma ve araştırma yapmak isteyen...</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3036937 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           start_time      end_time  \\\n",
       "0        00:02:51.948  00:02:58.829   \n",
       "1        00:03:00.956  00:03:04.236   \n",
       "2        00:03:13.434  00:03:16.327   \n",
       "3        00:03:17.235  00:03:21.338   \n",
       "4        00:03:27.806  00:03:33.383   \n",
       "...               ...           ...   \n",
       "3036932  00:07:51.970  00:07:52.470   \n",
       "3036933  00:07:52.470  00:08:02.304   \n",
       "3036934  00:08:02.498  00:08:04.178   \n",
       "3036935  00:08:04.178  00:08:08.089   \n",
       "3036936  00:08:08.089  00:08:11.770   \n",
       "\n",
       "                                                  sentence     video_id  \n",
       "0        özgür bunlar normalde kamyon daha büyük araçla...  8V9tq1pe8eI  \n",
       "1               burcu arka tarafı bağlamak kolay olmayacak  8V9tq1pe8eI  \n",
       "2                      özgür arabaya yarım tur attıracağım  8V9tq1pe8eI  \n",
       "3            burcu biraz daha devam et devam et tamam oldu  8V9tq1pe8eI  \n",
       "4        burcu şimdilik iki tekere takacağız ama kar ka...  8V9tq1pe8eI  \n",
       "...                                                    ...          ...  \n",
       "3036932  umarız ki bu büyük ve güçlü teknoloji yanlış e...  YFFJ5FyZj4Q  \n",
       "3036933  daha faydalı ve özgün kurumlarda herkesin eşit...  YFFJ5FyZj4Q  \n",
       "3036934                      i zlediğiniz için teşekkürler  YFFJ5FyZj4Q  \n",
       "3036935  yararlandığım kaynakları açıklamada link olara...  YFFJ5FyZj4Q  \n",
       "3036936  i leri düzey okuma ve araştırma yapmak isteyen...  YFFJ5FyZj4Q  \n",
       "\n",
       "[3036937 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_youtube_sentence = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Youtube/Result/{lang_folder.capitalize()}/Sentence Clean Merge/Clean_Youtube_Sentence_Merge_Result.csv\")\n",
    "df_youtube_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_youtube_sentence['start_time'] = pd.to_timedelta(df_youtube_sentence['start_time']) # data type converted timedelta for second \n",
    "df_youtube_sentence['end_time'] = pd.to_timedelta(df_youtube_sentence['end_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sentence</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171.948</td>\n",
       "      <td>178.829</td>\n",
       "      <td>özgür bunlar normalde kamyon daha büyük araçla...</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180.956</td>\n",
       "      <td>184.236</td>\n",
       "      <td>burcu arka tarafı bağlamak kolay olmayacak</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>193.434</td>\n",
       "      <td>196.327</td>\n",
       "      <td>özgür arabaya yarım tur attıracağım</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>197.235</td>\n",
       "      <td>201.338</td>\n",
       "      <td>burcu biraz daha devam et devam et tamam oldu</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>207.806</td>\n",
       "      <td>213.383</td>\n",
       "      <td>burcu şimdilik iki tekere takacağız ama kar ka...</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036932</th>\n",
       "      <td>471.970</td>\n",
       "      <td>472.470</td>\n",
       "      <td>umarız ki bu büyük ve güçlü teknoloji yanlış e...</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036933</th>\n",
       "      <td>472.470</td>\n",
       "      <td>482.304</td>\n",
       "      <td>daha faydalı ve özgün kurumlarda herkesin eşit...</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036934</th>\n",
       "      <td>482.498</td>\n",
       "      <td>484.178</td>\n",
       "      <td>i zlediğiniz için teşekkürler</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036935</th>\n",
       "      <td>484.178</td>\n",
       "      <td>488.089</td>\n",
       "      <td>yararlandığım kaynakları açıklamada link olara...</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036936</th>\n",
       "      <td>488.089</td>\n",
       "      <td>491.770</td>\n",
       "      <td>i leri düzey okuma ve araştırma yapmak isteyen...</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3036937 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         start_time  end_time  \\\n",
       "0           171.948   178.829   \n",
       "1           180.956   184.236   \n",
       "2           193.434   196.327   \n",
       "3           197.235   201.338   \n",
       "4           207.806   213.383   \n",
       "...             ...       ...   \n",
       "3036932     471.970   472.470   \n",
       "3036933     472.470   482.304   \n",
       "3036934     482.498   484.178   \n",
       "3036935     484.178   488.089   \n",
       "3036936     488.089   491.770   \n",
       "\n",
       "                                                  sentence     video_id  \n",
       "0        özgür bunlar normalde kamyon daha büyük araçla...  8V9tq1pe8eI  \n",
       "1               burcu arka tarafı bağlamak kolay olmayacak  8V9tq1pe8eI  \n",
       "2                      özgür arabaya yarım tur attıracağım  8V9tq1pe8eI  \n",
       "3            burcu biraz daha devam et devam et tamam oldu  8V9tq1pe8eI  \n",
       "4        burcu şimdilik iki tekere takacağız ama kar ka...  8V9tq1pe8eI  \n",
       "...                                                    ...          ...  \n",
       "3036932  umarız ki bu büyük ve güçlü teknoloji yanlış e...  YFFJ5FyZj4Q  \n",
       "3036933  daha faydalı ve özgün kurumlarda herkesin eşit...  YFFJ5FyZj4Q  \n",
       "3036934                      i zlediğiniz için teşekkürler  YFFJ5FyZj4Q  \n",
       "3036935  yararlandığım kaynakları açıklamada link olara...  YFFJ5FyZj4Q  \n",
       "3036936  i leri düzey okuma ve araştırma yapmak isteyen...  YFFJ5FyZj4Q  \n",
       "\n",
       "[3036937 rows x 4 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_youtube_sentence['start_time'] = df_youtube_sentence['start_time'].apply(lambda x: x.total_seconds()) # convert seconds\n",
    "df_youtube_sentence['end_time'] = df_youtube_sentence['end_time'].apply(lambda x: x.total_seconds())\n",
    "df_youtube_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_group_select = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/Deploy Result Manuel/\\\n",
    "{lang_folder.capitalize()} {lang_pair.capitalize()}/{lang_folder.capitalize()} {lang_pair.capitalize()} Manual Selected 2 Gram Hybrids.xlsx\", sheet_name= f\"{sheets}\")\n",
    "df_word_group_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>twogram_pair1</th>\n",
       "      <th>twogram_pair2</th>\n",
       "      <th>twogram_pair3</th>\n",
       "      <th>twogram_pair4</th>\n",
       "      <th>twogram_pair5</th>\n",
       "      <th>twogram_pair6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kontrol</td>\n",
       "      <td>trafik kontrol</td>\n",
       "      <td>kontrol paneli</td>\n",
       "      <td>sistem kontrolü</td>\n",
       "      <td>trafik kontrolü</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doktor</td>\n",
       "      <td>doktor raporu</td>\n",
       "      <td>doktorun numarası</td>\n",
       "      <td>doktorun telefonu</td>\n",
       "      <td>doktorun ofisine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>polis</td>\n",
       "      <td>polis şefi</td>\n",
       "      <td>trafik polisi</td>\n",
       "      <td>sivil polis</td>\n",
       "      <td>polis raporu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dolar</td>\n",
       "      <td>milyon dolar</td>\n",
       "      <td>milyon dolarlık</td>\n",
       "      <td>milyonlarca dolar</td>\n",
       "      <td>amerikan doları</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>komik</td>\n",
       "      <td>komik film</td>\n",
       "      <td>komik videoları</td>\n",
       "      <td>komik tipler</td>\n",
       "      <td>komik karakter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>alarm</td>\n",
       "      <td>genel alarm</td>\n",
       "      <td>alarm sistemi</td>\n",
       "      <td>alarm şifresi</td>\n",
       "      <td>kriz alarmı</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>motor</td>\n",
       "      <td>jet motoru</td>\n",
       "      <td>motorlar stop</td>\n",
       "      <td>motor kontrol</td>\n",
       "      <td>turbo motor</td>\n",
       "      <td>elektrik motorları</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>otobüs</td>\n",
       "      <td>okul otobüsü</td>\n",
       "      <td>takım otobüse</td>\n",
       "      <td>otobüs terminali</td>\n",
       "      <td>turist otobüsü</td>\n",
       "      <td>tur otobüsü</td>\n",
       "      <td>otobüs turu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>manyak</td>\n",
       "      <td>psikopat manyak</td>\n",
       "      <td>manyak film</td>\n",
       "      <td>manyak numara</td>\n",
       "      <td>manyak parti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>makine</td>\n",
       "      <td>fotoğraf makinesi</td>\n",
       "      <td>kahve makinesi</td>\n",
       "      <td>tost makinesi</td>\n",
       "      <td>fotokopi makinesi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word      twogram_pair1        twogram_pair2       twogram_pair3  \\\n",
       "0   kontrol     trafik kontrol       kontrol paneli     sistem kontrolü   \n",
       "1    doktor      doktor raporu    doktorun numarası   doktorun telefonu   \n",
       "2     polis         polis şefi        trafik polisi         sivil polis   \n",
       "3     dolar       milyon dolar      milyon dolarlık   milyonlarca dolar   \n",
       "4     komik         komik film      komik videoları        komik tipler   \n",
       "..      ...                ...                  ...                 ...   \n",
       "71    alarm        genel alarm        alarm sistemi       alarm şifresi   \n",
       "72    motor         jet motoru        motorlar stop       motor kontrol   \n",
       "73   otobüs       okul otobüsü        takım otobüse    otobüs terminali   \n",
       "74   manyak    psikopat manyak          manyak film       manyak numara   \n",
       "75   makine  fotoğraf makinesi       kahve makinesi       tost makinesi   \n",
       "\n",
       "         twogram_pair4        twogram_pair5 twogram_pair6  \n",
       "0      trafik kontrolü                  NaN           NaN  \n",
       "1     doktorun ofisine                  NaN           NaN  \n",
       "2         polis raporu                  NaN           NaN  \n",
       "3      amerikan doları                  NaN           NaN  \n",
       "4       komik karakter                  NaN           NaN  \n",
       "..                 ...                  ...           ...  \n",
       "71         kriz alarmı                  NaN           NaN  \n",
       "72         turbo motor   elektrik motorları           NaN  \n",
       "73      turist otobüsü          tur otobüsü   otobüs turu  \n",
       "74        manyak parti                  NaN           NaN  \n",
       "75   fotokopi makinesi                  NaN           NaN  \n",
       "\n",
       "[76 rows x 7 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## temp\n",
    "#df_word_group_select = pd.read_excel(\"Turkish English Manual Selected 2 Gram Hybrids2.xlsx\", sheet_name=\"2 gram SV\")\n",
    "#df_word_group_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_list = []\n",
    "for i in range(len(df_word_group_select)):\n",
    "    for j in df_word_group_select.columns[1:]:\n",
    "        string = df_word_group_select.loc[i,j]\n",
    "        \n",
    "        if pd.isnull(string) == False and string != 'nan':\n",
    "            search_list.append(string.strip())\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        #search_list.append(string.strip())\n",
    "        #search_list = [x for x in search_list if np.isnan(x) == False]\n",
    "#search_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_group_youtube(df, search_list, target_column, sample_num):\n",
    "    '''\n",
    "    word_group_youtube(df_youtube_sentence, search_list, \"sentence\", 6)\n",
    "    ''' \n",
    "    df_search_result = pd.DataFrame()\n",
    "    for j in search_list:\n",
    "        try:\n",
    "            df_select = df[df[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){j}(?:\\s|$)\", na=True)].sample(sample_num)\n",
    "        except:\n",
    "            df_select = df[df[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){j}(?:\\s|$)\", na=True)].head(sample_num)\n",
    "        #df_result = df[df[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){j}(?:\\s|$)\", na=True)]  # sentence length part\n",
    "        #df_result.sort_values(f\"{target_column}\",key=lambda x:x.str.len(), inplace=True)\n",
    "        #df_select = df_result.head(sample_num)\n",
    "        df_select.insert(0,\"search_string\",j)\n",
    "        df_search_result = pd.concat([df_search_result,df_select], axis=0)\n",
    "    df_search_result.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return df_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_search_result = pd.DataFrame()\n",
    "#for i in range(len(df_english_select)):\n",
    "#    for j in df_english_select.columns[1:]:\n",
    "#        string = df_english_select.loc[i,j]\n",
    "#        df_result = df_youtube_sent[df_youtube_sent.sentence.str.contains(fr\"(?:\\s|^){string}(?:\\s|$)\", na=True)]\n",
    "#        df_result.sort_values(\"sentence\",key=lambda x:x.str.len(), inplace=True)\n",
    "#        df_select = df_result.head(6)\n",
    "#        df_select.insert(0,\"search_string\",string)\n",
    "#        df_search_result = pd.concat([df_search_result,df_select], axis=0)\n",
    "#df_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_string</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sentence</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trafik kontrol</td>\n",
       "      <td>153.880</td>\n",
       "      <td>157.320</td>\n",
       "      <td>ben de hayatımda ilk kez bir hava trafik kontr...</td>\n",
       "      <td>zLD0TgRGl24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trafik kontrol</td>\n",
       "      <td>1002.804</td>\n",
       "      <td>1007.295</td>\n",
       "      <td>birincisi üniversitelerin hava trafik kontrol ...</td>\n",
       "      <td>zLD0TgRGl24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trafik kontrol</td>\n",
       "      <td>1020.000</td>\n",
       "      <td>1025.660</td>\n",
       "      <td>bu hava trafik kontrol kulelerinin olmazsa olm...</td>\n",
       "      <td>zLD0TgRGl24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trafik kontrol</td>\n",
       "      <td>2496.507</td>\n",
       "      <td>2499.157</td>\n",
       "      <td>hemen yakındaki trafik kontrol noktalarına hab...</td>\n",
       "      <td>OOF8y6PCb90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kontrol paneli</td>\n",
       "      <td>1008.808</td>\n",
       "      <td>1012.660</td>\n",
       "      <td>ömer vay be arda orada kontrol paneli var bak ...</td>\n",
       "      <td>o9KfgVAxFk4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>tost makinesi</td>\n",
       "      <td>1125.760</td>\n",
       "      <td>1127.980</td>\n",
       "      <td>tost makinesi zaten söylememe gerek yok</td>\n",
       "      <td>g9s7UhT22Uc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>tost makinesi</td>\n",
       "      <td>573.187</td>\n",
       "      <td>577.581</td>\n",
       "      <td>tost makinesi ve kettle gibi böyle görseli bir...</td>\n",
       "      <td>GcLoBlWydDw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>tost makinesi</td>\n",
       "      <td>460.971</td>\n",
       "      <td>462.971</td>\n",
       "      <td>tost makinesi</td>\n",
       "      <td>RN3BR75sWJs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>fotokopi makinesi</td>\n",
       "      <td>5419.000</td>\n",
       "      <td>5423.360</td>\n",
       "      <td>adam kırtasiyeci sabahtan akşama kadar fotokop...</td>\n",
       "      <td>Ri8OHAHmTJw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>fotokopi makinesi</td>\n",
       "      <td>5419.000</td>\n",
       "      <td>5423.360</td>\n",
       "      <td>adam kırtasiyeci sabahtan akşama kadar fotokop...</td>\n",
       "      <td>lREyKzqpCjE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>638 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         search_string  start_time  end_time  \\\n",
       "0       trafik kontrol     153.880   157.320   \n",
       "1       trafik kontrol    1002.804  1007.295   \n",
       "2       trafik kontrol    1020.000  1025.660   \n",
       "3       trafik kontrol    2496.507  2499.157   \n",
       "4       kontrol paneli    1008.808  1012.660   \n",
       "..                 ...         ...       ...   \n",
       "633      tost makinesi    1125.760  1127.980   \n",
       "634      tost makinesi     573.187   577.581   \n",
       "635      tost makinesi     460.971   462.971   \n",
       "636  fotokopi makinesi    5419.000  5423.360   \n",
       "637  fotokopi makinesi    5419.000  5423.360   \n",
       "\n",
       "                                              sentence     video_id  \n",
       "0    ben de hayatımda ilk kez bir hava trafik kontr...  zLD0TgRGl24  \n",
       "1    birincisi üniversitelerin hava trafik kontrol ...  zLD0TgRGl24  \n",
       "2    bu hava trafik kontrol kulelerinin olmazsa olm...  zLD0TgRGl24  \n",
       "3    hemen yakındaki trafik kontrol noktalarına hab...  OOF8y6PCb90  \n",
       "4    ömer vay be arda orada kontrol paneli var bak ...  o9KfgVAxFk4  \n",
       "..                                                 ...          ...  \n",
       "633            tost makinesi zaten söylememe gerek yok  g9s7UhT22Uc  \n",
       "634  tost makinesi ve kettle gibi böyle görseli bir...  GcLoBlWydDw  \n",
       "635                                      tost makinesi  RN3BR75sWJs  \n",
       "636  adam kırtasiyeci sabahtan akşama kadar fotokop...  Ri8OHAHmTJw  \n",
       "637  adam kırtasiyeci sabahtan akşama kadar fotokop...  lREyKzqpCjE  \n",
       "\n",
       "[638 rows x 5 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_search_result = word_group_youtube(df_youtube_sentence, search_list, \"sentence\", 6)\n",
    "df_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_group_time_loc(df, search, start_sent, end_sent, sent, sent_video_id):\n",
    "    '''\n",
    "    word_group_time_loc(df_search_result, \"search_string\", \"start_time\", \"end_time\", \"sentence\", \"video_id\")\n",
    "    '''\n",
    "    word_time_loc_list = []\n",
    "    for i in range(len(df)):\n",
    "        word = df.loc[i,f\"{search}\"]\n",
    "        start_time = df.loc[i,f\"{start_sent}\"]\n",
    "        end_time = df.loc[i,f\"{end_sent}\"]\n",
    "        sentence = df.loc[i,f\"{sent}\"]\n",
    "        video_id = df.loc[i,f\"{sent_video_id}\"]\n",
    "        time_length = end_time-start_time\n",
    "        sentence_length = len(sentence)\n",
    "        time_length_ratio = time_length/sentence_length\n",
    "        loc_list = []\n",
    "        for j in re.finditer(fr\"(?:\\s|^){word}(?:\\s|$)\", sentence, re.IGNORECASE|re.UNICODE):\n",
    "            loc_list.append(j)\n",
    "            start = loc_list[0].start()\n",
    "            end = loc_list[0].end()\n",
    "            start_loc = start_time+(start*time_length_ratio)\n",
    "            end_loc = start_time+(end*time_length_ratio)\n",
    "        word_time_loc_list.append([word,start_loc,end_loc,sentence,video_id])\n",
    "    df_word_time_loc = pd.DataFrame(word_time_loc_list, columns=[f\"{search}\",f\"{start_sent}\",f\"{end_sent}\",f\"{sent}\",f\"{sent_video_id}\"])\n",
    "\n",
    "    return df_word_time_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_string</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sentence</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trafik kontrol</td>\n",
       "      <td>155.501714</td>\n",
       "      <td>156.288000</td>\n",
       "      <td>ben de hayatımda ilk kez bir hava trafik kontr...</td>\n",
       "      <td>zLD0TgRGl24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trafik kontrol</td>\n",
       "      <td>1004.756609</td>\n",
       "      <td>1005.798000</td>\n",
       "      <td>birincisi üniversitelerin hava trafik kontrol ...</td>\n",
       "      <td>zLD0TgRGl24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trafik kontrol</td>\n",
       "      <td>1020.471667</td>\n",
       "      <td>1021.549762</td>\n",
       "      <td>bu hava trafik kontrol kulelerinin olmazsa olm...</td>\n",
       "      <td>zLD0TgRGl24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trafik kontrol</td>\n",
       "      <td>2497.243111</td>\n",
       "      <td>2498.028296</td>\n",
       "      <td>hemen yakındaki trafik kontrol noktalarına hab...</td>\n",
       "      <td>OOF8y6PCb90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kontrol paneli</td>\n",
       "      <td>1009.841463</td>\n",
       "      <td>1010.593073</td>\n",
       "      <td>ömer vay be arda orada kontrol paneli var bak ...</td>\n",
       "      <td>o9KfgVAxFk4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>tost makinesi</td>\n",
       "      <td>1125.760000</td>\n",
       "      <td>1126.556923</td>\n",
       "      <td>tost makinesi zaten söylememe gerek yok</td>\n",
       "      <td>g9s7UhT22Uc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>tost makinesi</td>\n",
       "      <td>573.187000</td>\n",
       "      <td>574.326185</td>\n",
       "      <td>tost makinesi ve kettle gibi böyle görseli bir...</td>\n",
       "      <td>GcLoBlWydDw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>tost makinesi</td>\n",
       "      <td>460.971000</td>\n",
       "      <td>462.971000</td>\n",
       "      <td>tost makinesi</td>\n",
       "      <td>RN3BR75sWJs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>fotokopi makinesi</td>\n",
       "      <td>5421.472836</td>\n",
       "      <td>5422.709254</td>\n",
       "      <td>adam kırtasiyeci sabahtan akşama kadar fotokop...</td>\n",
       "      <td>Ri8OHAHmTJw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>fotokopi makinesi</td>\n",
       "      <td>5421.472836</td>\n",
       "      <td>5422.709254</td>\n",
       "      <td>adam kırtasiyeci sabahtan akşama kadar fotokop...</td>\n",
       "      <td>lREyKzqpCjE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>638 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         search_string   start_time     end_time  \\\n",
       "0       trafik kontrol   155.501714   156.288000   \n",
       "1       trafik kontrol  1004.756609  1005.798000   \n",
       "2       trafik kontrol  1020.471667  1021.549762   \n",
       "3       trafik kontrol  2497.243111  2498.028296   \n",
       "4       kontrol paneli  1009.841463  1010.593073   \n",
       "..                 ...          ...          ...   \n",
       "633      tost makinesi  1125.760000  1126.556923   \n",
       "634      tost makinesi   573.187000   574.326185   \n",
       "635      tost makinesi   460.971000   462.971000   \n",
       "636  fotokopi makinesi  5421.472836  5422.709254   \n",
       "637  fotokopi makinesi  5421.472836  5422.709254   \n",
       "\n",
       "                                              sentence     video_id  \n",
       "0    ben de hayatımda ilk kez bir hava trafik kontr...  zLD0TgRGl24  \n",
       "1    birincisi üniversitelerin hava trafik kontrol ...  zLD0TgRGl24  \n",
       "2    bu hava trafik kontrol kulelerinin olmazsa olm...  zLD0TgRGl24  \n",
       "3    hemen yakındaki trafik kontrol noktalarına hab...  OOF8y6PCb90  \n",
       "4    ömer vay be arda orada kontrol paneli var bak ...  o9KfgVAxFk4  \n",
       "..                                                 ...          ...  \n",
       "633            tost makinesi zaten söylememe gerek yok  g9s7UhT22Uc  \n",
       "634  tost makinesi ve kettle gibi böyle görseli bir...  GcLoBlWydDw  \n",
       "635                                      tost makinesi  RN3BR75sWJs  \n",
       "636  adam kırtasiyeci sabahtan akşama kadar fotokop...  Ri8OHAHmTJw  \n",
       "637  adam kırtasiyeci sabahtan akşama kadar fotokop...  lREyKzqpCjE  \n",
       "\n",
       "[638 rows x 5 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_group_time_loc_result = word_group_time_loc(df_search_result, \"search_string\", \"start_time\", \"end_time\", \"sentence\", \"video_id\")\n",
    "df_word_group_time_loc_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_string</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sentence</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trafik kontrol</td>\n",
       "      <td>154.901714</td>\n",
       "      <td>156.888000</td>\n",
       "      <td>ben de hayatımda ilk kez bir hava trafik kontr...</td>\n",
       "      <td>zLD0TgRGl24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trafik kontrol</td>\n",
       "      <td>1004.156609</td>\n",
       "      <td>1006.398000</td>\n",
       "      <td>birincisi üniversitelerin hava trafik kontrol ...</td>\n",
       "      <td>zLD0TgRGl24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trafik kontrol</td>\n",
       "      <td>1019.871667</td>\n",
       "      <td>1022.149762</td>\n",
       "      <td>bu hava trafik kontrol kulelerinin olmazsa olm...</td>\n",
       "      <td>zLD0TgRGl24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trafik kontrol</td>\n",
       "      <td>2496.643111</td>\n",
       "      <td>2498.628296</td>\n",
       "      <td>hemen yakındaki trafik kontrol noktalarına hab...</td>\n",
       "      <td>OOF8y6PCb90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kontrol paneli</td>\n",
       "      <td>1009.241463</td>\n",
       "      <td>1011.193073</td>\n",
       "      <td>ömer vay be arda orada kontrol paneli var bak ...</td>\n",
       "      <td>o9KfgVAxFk4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>tost makinesi</td>\n",
       "      <td>1125.160000</td>\n",
       "      <td>1127.156923</td>\n",
       "      <td>tost makinesi zaten söylememe gerek yok</td>\n",
       "      <td>g9s7UhT22Uc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>tost makinesi</td>\n",
       "      <td>572.587000</td>\n",
       "      <td>574.926185</td>\n",
       "      <td>tost makinesi ve kettle gibi böyle görseli bir...</td>\n",
       "      <td>GcLoBlWydDw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>tost makinesi</td>\n",
       "      <td>460.371000</td>\n",
       "      <td>463.571000</td>\n",
       "      <td>tost makinesi</td>\n",
       "      <td>RN3BR75sWJs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>fotokopi makinesi</td>\n",
       "      <td>5420.872836</td>\n",
       "      <td>5423.309254</td>\n",
       "      <td>adam kırtasiyeci sabahtan akşama kadar fotokop...</td>\n",
       "      <td>Ri8OHAHmTJw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>fotokopi makinesi</td>\n",
       "      <td>5420.872836</td>\n",
       "      <td>5423.309254</td>\n",
       "      <td>adam kırtasiyeci sabahtan akşama kadar fotokop...</td>\n",
       "      <td>lREyKzqpCjE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>638 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         search_string   start_time     end_time  \\\n",
       "0       trafik kontrol   154.901714   156.888000   \n",
       "1       trafik kontrol  1004.156609  1006.398000   \n",
       "2       trafik kontrol  1019.871667  1022.149762   \n",
       "3       trafik kontrol  2496.643111  2498.628296   \n",
       "4       kontrol paneli  1009.241463  1011.193073   \n",
       "..                 ...          ...          ...   \n",
       "633      tost makinesi  1125.160000  1127.156923   \n",
       "634      tost makinesi   572.587000   574.926185   \n",
       "635      tost makinesi   460.371000   463.571000   \n",
       "636  fotokopi makinesi  5420.872836  5423.309254   \n",
       "637  fotokopi makinesi  5420.872836  5423.309254   \n",
       "\n",
       "                                              sentence     video_id  \n",
       "0    ben de hayatımda ilk kez bir hava trafik kontr...  zLD0TgRGl24  \n",
       "1    birincisi üniversitelerin hava trafik kontrol ...  zLD0TgRGl24  \n",
       "2    bu hava trafik kontrol kulelerinin olmazsa olm...  zLD0TgRGl24  \n",
       "3    hemen yakındaki trafik kontrol noktalarına hab...  OOF8y6PCb90  \n",
       "4    ömer vay be arda orada kontrol paneli var bak ...  o9KfgVAxFk4  \n",
       "..                                                 ...          ...  \n",
       "633            tost makinesi zaten söylememe gerek yok  g9s7UhT22Uc  \n",
       "634  tost makinesi ve kettle gibi böyle görseli bir...  GcLoBlWydDw  \n",
       "635                                      tost makinesi  RN3BR75sWJs  \n",
       "636  adam kırtasiyeci sabahtan akşama kadar fotokop...  Ri8OHAHmTJw  \n",
       "637  adam kırtasiyeci sabahtan akşama kadar fotokop...  lREyKzqpCjE  \n",
       "\n",
       "[638 rows x 5 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#time_shift = 0.3\n",
    "df_word_group_time_loc_result.start_time = df_word_group_time_loc_result.start_time.apply(lambda x: (x-time_shift))\n",
    "df_word_group_time_loc_result.end_time = df_word_group_time_loc_result.end_time.apply(lambda x: (x+time_shift))\n",
    "df_word_group_time_loc_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_string</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sentence</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trafik kontrol</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>ben de hayatımda ilk kez bir hava trafik kontr...</td>\n",
       "      <td>zLD0TgRGl24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trafik kontrol</td>\n",
       "      <td>1004</td>\n",
       "      <td>1006</td>\n",
       "      <td>birincisi üniversitelerin hava trafik kontrol ...</td>\n",
       "      <td>zLD0TgRGl24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trafik kontrol</td>\n",
       "      <td>1020</td>\n",
       "      <td>1022</td>\n",
       "      <td>bu hava trafik kontrol kulelerinin olmazsa olm...</td>\n",
       "      <td>zLD0TgRGl24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trafik kontrol</td>\n",
       "      <td>2497</td>\n",
       "      <td>2499</td>\n",
       "      <td>hemen yakındaki trafik kontrol noktalarına hab...</td>\n",
       "      <td>OOF8y6PCb90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kontrol paneli</td>\n",
       "      <td>1009</td>\n",
       "      <td>1011</td>\n",
       "      <td>ömer vay be arda orada kontrol paneli var bak ...</td>\n",
       "      <td>o9KfgVAxFk4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>tost makinesi</td>\n",
       "      <td>1125</td>\n",
       "      <td>1127</td>\n",
       "      <td>tost makinesi zaten söylememe gerek yok</td>\n",
       "      <td>g9s7UhT22Uc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>tost makinesi</td>\n",
       "      <td>573</td>\n",
       "      <td>575</td>\n",
       "      <td>tost makinesi ve kettle gibi böyle görseli bir...</td>\n",
       "      <td>GcLoBlWydDw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>tost makinesi</td>\n",
       "      <td>460</td>\n",
       "      <td>464</td>\n",
       "      <td>tost makinesi</td>\n",
       "      <td>RN3BR75sWJs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>fotokopi makinesi</td>\n",
       "      <td>5421</td>\n",
       "      <td>5423</td>\n",
       "      <td>adam kırtasiyeci sabahtan akşama kadar fotokop...</td>\n",
       "      <td>Ri8OHAHmTJw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>fotokopi makinesi</td>\n",
       "      <td>5421</td>\n",
       "      <td>5423</td>\n",
       "      <td>adam kırtasiyeci sabahtan akşama kadar fotokop...</td>\n",
       "      <td>lREyKzqpCjE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>638 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         search_string  start_time  end_time  \\\n",
       "0       trafik kontrol         155       157   \n",
       "1       trafik kontrol        1004      1006   \n",
       "2       trafik kontrol        1020      1022   \n",
       "3       trafik kontrol        2497      2499   \n",
       "4       kontrol paneli        1009      1011   \n",
       "..                 ...         ...       ...   \n",
       "633      tost makinesi        1125      1127   \n",
       "634      tost makinesi         573       575   \n",
       "635      tost makinesi         460       464   \n",
       "636  fotokopi makinesi        5421      5423   \n",
       "637  fotokopi makinesi        5421      5423   \n",
       "\n",
       "                                              sentence     video_id  \n",
       "0    ben de hayatımda ilk kez bir hava trafik kontr...  zLD0TgRGl24  \n",
       "1    birincisi üniversitelerin hava trafik kontrol ...  zLD0TgRGl24  \n",
       "2    bu hava trafik kontrol kulelerinin olmazsa olm...  zLD0TgRGl24  \n",
       "3    hemen yakındaki trafik kontrol noktalarına hab...  OOF8y6PCb90  \n",
       "4    ömer vay be arda orada kontrol paneli var bak ...  o9KfgVAxFk4  \n",
       "..                                                 ...          ...  \n",
       "633            tost makinesi zaten söylememe gerek yok  g9s7UhT22Uc  \n",
       "634  tost makinesi ve kettle gibi böyle görseli bir...  GcLoBlWydDw  \n",
       "635                                      tost makinesi  RN3BR75sWJs  \n",
       "636  adam kırtasiyeci sabahtan akşama kadar fotokop...  Ri8OHAHmTJw  \n",
       "637  adam kırtasiyeci sabahtan akşama kadar fotokop...  lREyKzqpCjE  \n",
       "\n",
       "[638 rows x 5 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_group_time_loc_result.start_time = df_word_group_time_loc_result.start_time.apply(lambda x: round(x))\n",
    "df_word_group_time_loc_result.end_time = df_word_group_time_loc_result.end_time.apply(lambda x: round(x))\n",
    "df_word_group_time_loc_result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_string</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sentence</th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trafik kontrol</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>ben de hayatımda ilk kez bir hava trafik kontr...</td>\n",
       "      <td>zLD0TgRGl24</td>\n",
       "      <td>https://www.youtube.com/watch?v=zLD0TgRGl24&amp;t=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trafik kontrol</td>\n",
       "      <td>1004</td>\n",
       "      <td>1006</td>\n",
       "      <td>birincisi üniversitelerin hava trafik kontrol ...</td>\n",
       "      <td>zLD0TgRGl24</td>\n",
       "      <td>https://www.youtube.com/watch?v=zLD0TgRGl24&amp;t=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trafik kontrol</td>\n",
       "      <td>1020</td>\n",
       "      <td>1022</td>\n",
       "      <td>bu hava trafik kontrol kulelerinin olmazsa olm...</td>\n",
       "      <td>zLD0TgRGl24</td>\n",
       "      <td>https://www.youtube.com/watch?v=zLD0TgRGl24&amp;t=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trafik kontrol</td>\n",
       "      <td>2497</td>\n",
       "      <td>2499</td>\n",
       "      <td>hemen yakındaki trafik kontrol noktalarına hab...</td>\n",
       "      <td>OOF8y6PCb90</td>\n",
       "      <td>https://www.youtube.com/watch?v=OOF8y6PCb90&amp;t=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kontrol paneli</td>\n",
       "      <td>1009</td>\n",
       "      <td>1011</td>\n",
       "      <td>ömer vay be arda orada kontrol paneli var bak ...</td>\n",
       "      <td>o9KfgVAxFk4</td>\n",
       "      <td>https://www.youtube.com/watch?v=o9KfgVAxFk4&amp;t=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>tost makinesi</td>\n",
       "      <td>1125</td>\n",
       "      <td>1127</td>\n",
       "      <td>tost makinesi zaten söylememe gerek yok</td>\n",
       "      <td>g9s7UhT22Uc</td>\n",
       "      <td>https://www.youtube.com/watch?v=g9s7UhT22Uc&amp;t=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>tost makinesi</td>\n",
       "      <td>573</td>\n",
       "      <td>575</td>\n",
       "      <td>tost makinesi ve kettle gibi böyle görseli bir...</td>\n",
       "      <td>GcLoBlWydDw</td>\n",
       "      <td>https://www.youtube.com/watch?v=GcLoBlWydDw&amp;t=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>tost makinesi</td>\n",
       "      <td>460</td>\n",
       "      <td>464</td>\n",
       "      <td>tost makinesi</td>\n",
       "      <td>RN3BR75sWJs</td>\n",
       "      <td>https://www.youtube.com/watch?v=RN3BR75sWJs&amp;t=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>fotokopi makinesi</td>\n",
       "      <td>5421</td>\n",
       "      <td>5423</td>\n",
       "      <td>adam kırtasiyeci sabahtan akşama kadar fotokop...</td>\n",
       "      <td>Ri8OHAHmTJw</td>\n",
       "      <td>https://www.youtube.com/watch?v=Ri8OHAHmTJw&amp;t=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>fotokopi makinesi</td>\n",
       "      <td>5421</td>\n",
       "      <td>5423</td>\n",
       "      <td>adam kırtasiyeci sabahtan akşama kadar fotokop...</td>\n",
       "      <td>lREyKzqpCjE</td>\n",
       "      <td>https://www.youtube.com/watch?v=lREyKzqpCjE&amp;t=...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>638 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         search_string  start_time  end_time  \\\n",
       "0       trafik kontrol         155       157   \n",
       "1       trafik kontrol        1004      1006   \n",
       "2       trafik kontrol        1020      1022   \n",
       "3       trafik kontrol        2497      2499   \n",
       "4       kontrol paneli        1009      1011   \n",
       "..                 ...         ...       ...   \n",
       "633      tost makinesi        1125      1127   \n",
       "634      tost makinesi         573       575   \n",
       "635      tost makinesi         460       464   \n",
       "636  fotokopi makinesi        5421      5423   \n",
       "637  fotokopi makinesi        5421      5423   \n",
       "\n",
       "                                              sentence     video_id  \\\n",
       "0    ben de hayatımda ilk kez bir hava trafik kontr...  zLD0TgRGl24   \n",
       "1    birincisi üniversitelerin hava trafik kontrol ...  zLD0TgRGl24   \n",
       "2    bu hava trafik kontrol kulelerinin olmazsa olm...  zLD0TgRGl24   \n",
       "3    hemen yakındaki trafik kontrol noktalarına hab...  OOF8y6PCb90   \n",
       "4    ömer vay be arda orada kontrol paneli var bak ...  o9KfgVAxFk4   \n",
       "..                                                 ...          ...   \n",
       "633            tost makinesi zaten söylememe gerek yok  g9s7UhT22Uc   \n",
       "634  tost makinesi ve kettle gibi böyle görseli bir...  GcLoBlWydDw   \n",
       "635                                      tost makinesi  RN3BR75sWJs   \n",
       "636  adam kırtasiyeci sabahtan akşama kadar fotokop...  Ri8OHAHmTJw   \n",
       "637  adam kırtasiyeci sabahtan akşama kadar fotokop...  lREyKzqpCjE   \n",
       "\n",
       "                                             video_url  \n",
       "0    https://www.youtube.com/watch?v=zLD0TgRGl24&t=...  \n",
       "1    https://www.youtube.com/watch?v=zLD0TgRGl24&t=...  \n",
       "2    https://www.youtube.com/watch?v=zLD0TgRGl24&t=...  \n",
       "3    https://www.youtube.com/watch?v=OOF8y6PCb90&t=...  \n",
       "4    https://www.youtube.com/watch?v=o9KfgVAxFk4&t=...  \n",
       "..                                                 ...  \n",
       "633  https://www.youtube.com/watch?v=g9s7UhT22Uc&t=...  \n",
       "634  https://www.youtube.com/watch?v=GcLoBlWydDw&t=...  \n",
       "635  https://www.youtube.com/watch?v=RN3BR75sWJs&t=...  \n",
       "636  https://www.youtube.com/watch?v=Ri8OHAHmTJw&t=...  \n",
       "637  https://www.youtube.com/watch?v=lREyKzqpCjE&t=...  \n",
       "\n",
       "[638 rows x 6 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_group_time_loc_result[\"video_url\"] = \"https://www.youtube.com/watch?v=\"+df_word_group_time_loc_result['video_id'].map(str)+\"&t=\"+df_word_group_time_loc_result['start_time'].map(str)+\"s\"\n",
    "df_word_group_time_loc_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_word_group_time_loc_result.to_excel(\"Turkish_English_2 Gram Hybrid_SV_Youtube_Result.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_group_time_loc_result.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_{sheets.capitalize()}_\\\n",
    "{sample_num}_Youtube_{time_shift}s_Timeshift_Result.xlsx\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Move And Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Turkish_English_2 gram hybrid_6_Youtube_0.6s_Timeshift_Result.xlsx']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file5 = glob.glob(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_*_{sample_num}_Youtube_{time_shift}s_Timeshift_Result.xlsx\")\n",
    "output_file5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in output_file5:\n",
    "    source = y # source directory\n",
    "    destination = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/5-Shared Word File/{lang_folder.capitalize()} {lang_pair.capitalize()}\"\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in output_file5:\n",
    "    try:\n",
    "        os.remove(z)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "651d507d70892fab0fc6529d935cd476f6e2eb1791525b76da6cc8da34bc0503"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
