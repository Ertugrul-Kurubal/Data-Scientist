{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared Word File Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "#import multiprocessing as mp\n",
    "from multiprocessing import Process, Manager, Pool, Queue\n",
    "from itertools import islice\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 16\n"
     ]
    }
   ],
   "source": [
    "nprocs = multiprocessing.cpu_count()\n",
    "print(f\"Number of CPU cores: {nprocs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# language pair\n",
    "lang_folder = \"English\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "lang_pair = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "# adding native word to shared word\n",
    "word_start = 0  # 0  # native word start index\n",
    "word_end = 28  # 28  # native word end index\n",
    "\n",
    "# shared word frequency\n",
    "shared_word_frequency = True  # True, False\n",
    "\n",
    "# prefix suffix file\n",
    "prefix_suffix = False  # True, False  # always must be False in this part\n",
    "native_word = True # True for adding native word\n",
    "etymology_word = True  # True for adding etymology word\n",
    "\n",
    "# adding output file extention\n",
    "if (not prefix_suffix) & etymology_word & native_word:\n",
    "    file_ext = \"1\"\n",
    "elif (not prefix_suffix) & etymology_word & (not native_word):\n",
    "    file_ext = \"2\"\n",
    "elif prefix_suffix & etymology_word & native_word:\n",
    "    file_ext = \"3\"\n",
    "elif prefix_suffix & etymology_word & (not native_word):\n",
    "    file_ext = \"4\"\n",
    "elif prefix_suffix & (not etymology_word) & native_word:\n",
    "    file_ext = \"5\"\n",
    "elif (not prefix_suffix) & (not etymology_word) & native_word:\n",
    "    file_ext = \"6\"\n",
    "else:\n",
    "    file_ext = \"7\"              \n",
    "# 1 => for native word and etymology word without prefix suffix. \n",
    "# 2 => for only etymology word without prefix suffix. \n",
    "# 3 => for native word and etymology word with prefix suffix. prefix_suffix, native_word and etymology_word must be True. \n",
    "# 4 => for only etymology word with prefix suffix.\n",
    "# 5 => for only native word with prefix suffix.\n",
    "# 6 => for only native word without prefix suffix.\n",
    "print(f\"{file_ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/5-Shared Word File/{lang_folder.capitalize()} {lang_pair.capitalize()}\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twogram In Threegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you</td>\n",
       "      <td>102069964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i</td>\n",
       "      <td>94447074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>77481215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>58281119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>50852895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552149</th>\n",
       "      <td>fruitcocktail</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552150</th>\n",
       "      <td>andthesunlightshining</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552151</th>\n",
       "      <td>upravo</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552152</th>\n",
       "      <td>yagawa</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552153</th>\n",
       "      <td>foxtrotoscar</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>552154 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         word  frequency\n",
       "0                         you  102069964\n",
       "1                           i   94447074\n",
       "2                         the   77481215\n",
       "3                          to   58281119\n",
       "4                          is   50852895\n",
       "...                       ...        ...\n",
       "552149          fruitcocktail          6\n",
       "552150  andthesunlightshining          6\n",
       "552151                 upravo          6\n",
       "552152                 yagawa          6\n",
       "552153           foxtrotoscar          6\n",
       "\n",
       "[552154 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.lower().capitalize()}/Deployment/Data/Word/Word_Merge_Preprocess.xlsx\")\n",
    "df_word_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "      <th>twogram</th>\n",
       "      <th>freq_twogram</th>\n",
       "      <th>threegram</th>\n",
       "      <th>freq_threegram</th>\n",
       "      <th>fourgram</th>\n",
       "      <th>freq_fourgram</th>\n",
       "      <th>fivegram</th>\n",
       "      <th>freq_fivegram</th>\n",
       "      <th>sentence</th>\n",
       "      <th>freq_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you</td>\n",
       "      <td>102069964.0</td>\n",
       "      <td>i am</td>\n",
       "      <td>10494331.0</td>\n",
       "      <td>i do not</td>\n",
       "      <td>3520257</td>\n",
       "      <td>you do not have</td>\n",
       "      <td>160426.0</td>\n",
       "      <td>you do not have to</td>\n",
       "      <td>107450.0</td>\n",
       "      <td>of course</td>\n",
       "      <td>266277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i</td>\n",
       "      <td>94447074.0</td>\n",
       "      <td>do not</td>\n",
       "      <td>8972296.0</td>\n",
       "      <td>i am not</td>\n",
       "      <td>1262941</td>\n",
       "      <td>i do not have</td>\n",
       "      <td>158788.0</td>\n",
       "      <td>i do not have a</td>\n",
       "      <td>34568.0</td>\n",
       "      <td>what is it</td>\n",
       "      <td>251203.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>77481215.0</td>\n",
       "      <td>i do</td>\n",
       "      <td>4179914.0</td>\n",
       "      <td>what do you</td>\n",
       "      <td>1120086</td>\n",
       "      <td>do not have to</td>\n",
       "      <td>150328.0</td>\n",
       "      <td>do not have to do</td>\n",
       "      <td>21572.0</td>\n",
       "      <td>stop it</td>\n",
       "      <td>152280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>58281119.0</td>\n",
       "      <td>i will</td>\n",
       "      <td>3706224.0</td>\n",
       "      <td>you do not</td>\n",
       "      <td>1010676</td>\n",
       "      <td>no i do not</td>\n",
       "      <td>105374.0</td>\n",
       "      <td>i do not have to</td>\n",
       "      <td>21499.0</td>\n",
       "      <td>i am</td>\n",
       "      <td>136931.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>50852895.0</td>\n",
       "      <td>do you</td>\n",
       "      <td>3358227.0</td>\n",
       "      <td>do not you</td>\n",
       "      <td>644488</td>\n",
       "      <td>i do not like</td>\n",
       "      <td>99318.0</td>\n",
       "      <td>i do not like it</td>\n",
       "      <td>18564.0</td>\n",
       "      <td>i do</td>\n",
       "      <td>114801.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206638</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i control radiation</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206639</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the antibiotic i</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206640</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my radar screen</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206641</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cup will not</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206642</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stop on no</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206643 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word    frequency twogram  freq_twogram            threegram  \\\n",
       "0       you  102069964.0    i am    10494331.0             i do not   \n",
       "1         i   94447074.0  do not     8972296.0             i am not   \n",
       "2       the   77481215.0    i do     4179914.0          what do you   \n",
       "3        to   58281119.0  i will     3706224.0           you do not   \n",
       "4        is   50852895.0  do you     3358227.0           do not you   \n",
       "...     ...          ...     ...           ...                  ...   \n",
       "206638  NaN          NaN     NaN           NaN  i control radiation   \n",
       "206639  NaN          NaN     NaN           NaN     the antibiotic i   \n",
       "206640  NaN          NaN     NaN           NaN      my radar screen   \n",
       "206641  NaN          NaN     NaN           NaN         cup will not   \n",
       "206642  NaN          NaN     NaN           NaN           stop on no   \n",
       "\n",
       "        freq_threegram         fourgram  freq_fourgram            fivegram  \\\n",
       "0              3520257  you do not have       160426.0  you do not have to   \n",
       "1              1262941    i do not have       158788.0     i do not have a   \n",
       "2              1120086   do not have to       150328.0   do not have to do   \n",
       "3              1010676      no i do not       105374.0    i do not have to   \n",
       "4               644488    i do not like        99318.0    i do not like it   \n",
       "...                ...              ...            ...                 ...   \n",
       "206638               4              NaN            NaN                 NaN   \n",
       "206639               4              NaN            NaN                 NaN   \n",
       "206640               4              NaN            NaN                 NaN   \n",
       "206641               4              NaN            NaN                 NaN   \n",
       "206642               4              NaN            NaN                 NaN   \n",
       "\n",
       "        freq_fivegram    sentence  freq_sentence  \n",
       "0            107450.0   of course       266277.0  \n",
       "1             34568.0  what is it       251203.0  \n",
       "2             21572.0     stop it       152280.0  \n",
       "3             21499.0        i am       136931.0  \n",
       "4             18564.0        i do       114801.0  \n",
       "...               ...         ...            ...  \n",
       "206638            NaN         NaN            NaN  \n",
       "206639            NaN         NaN            NaN  \n",
       "206640            NaN         NaN            NaN  \n",
       "206641            NaN         NaN            NaN  \n",
       "206642            NaN         NaN            NaN  \n",
       "\n",
       "[206643 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shared_file = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/4-Shared Word/{lang_folder.capitalize()} {lang_pair.capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Result_With_Frequency{file_ext}.xlsx\")\n",
    "#df_shared_file = pd.read_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Result_With_Frequency.xlsx\")\n",
    "df_shared_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_result(df,column_list): # df is dataframe, column_list is list value\n",
    "    '''\n",
    "    word_count_bool(df, column_list): df columns word count for word frequency\\n\n",
    "    df is dataframe, column_list is list value\\n\n",
    "    word_count_bool(df, [\"word\",\"twogram\"]):\n",
    "    '''\n",
    "    list_all = []\n",
    "    for i in df.loc[:,[x for x in column_list]].columns:\n",
    "        var_list = df[f\"{i}\"].dropna().tolist()\n",
    "        for j in var_list:\n",
    "            list_all.append(j)\n",
    "    text = \" \".join(list_all)\n",
    "    word_list = re.findall(r\"\\w+\",text, re.UNICODE)\n",
    "    df_word_list = pd.DataFrame(word_list, columns=[\"word\"])\n",
    "    #df_word_list.rename(columns={0:\"word\"}, inplace=True)\n",
    "    df_word_count = pd.DataFrame(df_word_list.value_counts())\n",
    "    df_word_count.reset_index(inplace=True)\n",
    "    df_word_count.rename(columns={0:\"word_count\"}, inplace=True)\n",
    "    \n",
    "    return  df_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_in_wordgroup(df, list_column, target_column):\n",
    "\n",
    "    '''word_in_wordgroup(df, \"word\", \"twogram\"):\n",
    "       df is dataframe, list_column and target_column are \n",
    "       dataframe column string name. list_column convert list\n",
    "       values that are in target column.\n",
    "    '''\n",
    "    \n",
    "    df_select = df[[f\"{target_column}\"]].dropna()\n",
    "    df_word_result = pd.DataFrame()\n",
    "    for i in df[f\"{list_column}\"].dropna():\n",
    "        try:\n",
    "            #word_in_twogram = df_select[df_select[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)].head(10)  # Option\n",
    "            word_in_word_cluster = df_select[df_select[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)].head(100) \n",
    "        except:\n",
    "            pass        \n",
    "        word_in_word_cluster.insert(0,f\"{list_column}\",i)\n",
    "        df_word_result = pd.concat([df_word_result,word_in_word_cluster], axis=0)\n",
    "    df_word_result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_word_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_shared_count = word_count_result(df_shared_file,[\"threegram\"])\n",
    "#df_shared_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78359"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shared_file[\"twogram\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram</th>\n",
       "      <th>threegram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i am</td>\n",
       "      <td>i am not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i am</td>\n",
       "      <td>i am a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i am</td>\n",
       "      <td>no i am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am</td>\n",
       "      <td>what i am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am</td>\n",
       "      <td>i am the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334913</th>\n",
       "      <td>champion puzzle</td>\n",
       "      <td>a champion puzzle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334914</th>\n",
       "      <td>quality material</td>\n",
       "      <td>was quality material</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334915</th>\n",
       "      <td>quality mask</td>\n",
       "      <td>a quality mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334916</th>\n",
       "      <td>quality index</td>\n",
       "      <td>quality index is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334917</th>\n",
       "      <td>classical department</td>\n",
       "      <td>the classical department</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>334918 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     twogram                 threegram\n",
       "0                       i am                  i am not\n",
       "1                       i am                    i am a\n",
       "2                       i am                   no i am\n",
       "3                       i am                 what i am\n",
       "4                       i am                  i am the\n",
       "...                      ...                       ...\n",
       "334913       champion puzzle         a champion puzzle\n",
       "334914      quality material      was quality material\n",
       "334915          quality mask            a quality mask\n",
       "334916         quality index          quality index is\n",
       "334917  classical department  the classical department\n",
       "\n",
       "[334918 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_two_in_three = word_in_wordgroup(df_shared_file, \"twogram\", \"threegram\")\n",
    "df_two_in_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60870"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_two_in_three[\"twogram\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram</th>\n",
       "      <th>freq_twogram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i am</td>\n",
       "      <td>10494331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>do not</td>\n",
       "      <td>8972296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i do</td>\n",
       "      <td>4179914.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i will</td>\n",
       "      <td>3706224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>do you</td>\n",
       "      <td>3358227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206638</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206639</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206640</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206641</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206642</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206643 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       twogram  freq_twogram\n",
       "0         i am    10494331.0\n",
       "1       do not     8972296.0\n",
       "2         i do     4179914.0\n",
       "3       i will     3706224.0\n",
       "4       do you     3358227.0\n",
       "...        ...           ...\n",
       "206638     NaN           NaN\n",
       "206639     NaN           NaN\n",
       "206640     NaN           NaN\n",
       "206641     NaN           NaN\n",
       "206642     NaN           NaN\n",
       "\n",
       "[206643 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shared_select_twogram = df_shared_file.loc[:,[\"twogram\",\"freq_twogram\"]]\n",
    "df_shared_select_twogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_shared_twogram = set(df_shared_select_twogram[\"twogram\"])\n",
    "set_two_three = set(df_two_in_three[\"twogram\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>your screen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hologram is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>action august</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>realism do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>corner depressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60865</th>\n",
       "      <td>social plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60866</th>\n",
       "      <td>bouquet the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60867</th>\n",
       "      <td>cafe we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60868</th>\n",
       "      <td>training baby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60869</th>\n",
       "      <td>unit hit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60870 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                twogram\n",
       "0           your screen\n",
       "1           hologram is\n",
       "2         action august\n",
       "3            realism do\n",
       "4      corner depressed\n",
       "...                 ...\n",
       "60865       social plan\n",
       "60866       bouquet the\n",
       "60867           cafe we\n",
       "60868     training baby\n",
       "60869          unit hit\n",
       "\n",
       "[60870 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twogram_in_threegram = pd.DataFrame(set_two_three, columns=[\"twogram\"])  # columns=[\"twogram_in_threegram\"]\n",
    "df_twogram_in_threegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram_in_threegram</th>\n",
       "      <th>freq_two_in_three</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i am</td>\n",
       "      <td>10494331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>do not</td>\n",
       "      <td>8972296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i do</td>\n",
       "      <td>4179914.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i will</td>\n",
       "      <td>3706224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>do you</td>\n",
       "      <td>3358227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60865</th>\n",
       "      <td>lift music</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60866</th>\n",
       "      <td>counter no</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60867</th>\n",
       "      <td>system design</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60868</th>\n",
       "      <td>have champion</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60869</th>\n",
       "      <td>frequency active</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60870 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      twogram_in_threegram  freq_two_in_three\n",
       "0                     i am         10494331.0\n",
       "1                   do not          8972296.0\n",
       "2                     i do          4179914.0\n",
       "3                   i will          3706224.0\n",
       "4                   do you          3358227.0\n",
       "...                    ...                ...\n",
       "60865           lift music                4.0\n",
       "60866           counter no                4.0\n",
       "60867        system design                4.0\n",
       "60868        have champion                4.0\n",
       "60869     frequency active                4.0\n",
       "\n",
       "[60870 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twogram_in_threegram_freq = pd.merge(df_twogram_in_threegram, df_shared_select_twogram, how=\"left\", on=\"twogram\")\n",
    "df_twogram_in_threegram_freq.sort_values(by=\"freq_twogram\", ascending=False, inplace=True)\n",
    "df_twogram_in_threegram_freq.rename(columns={\"twogram\":\"twogram_in_threegram\",\"freq_twogram\":\"freq_two_in_three\"}, inplace=True)\n",
    "df_twogram_in_threegram_freq.reset_index(drop=True, inplace=True)\n",
    "df_twogram_in_threegram_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anonymous sponsor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>diet chips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>complete protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>university hall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17485</th>\n",
       "      <td>subsidy to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17486</th>\n",
       "      <td>shot type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17487</th>\n",
       "      <td>captain post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17488</th>\n",
       "      <td>it initiative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17489</th>\n",
       "      <td>miniature control</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17490 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 twogram\n",
       "0                    NaN\n",
       "1      anonymous sponsor\n",
       "2             diet chips\n",
       "3       complete protein\n",
       "4        university hall\n",
       "...                  ...\n",
       "17485         subsidy to\n",
       "17486          shot type\n",
       "17487       captain post\n",
       "17488      it initiative\n",
       "17489  miniature control\n",
       "\n",
       "[17490 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twogram_diff = pd.DataFrame(set_shared_twogram.difference(set_two_three), columns=[\"twogram\"])\n",
    "df_twogram_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram</th>\n",
       "      <th>freq_twogram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>media group</td>\n",
       "      <td>4604.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hello sheriff</td>\n",
       "      <td>501.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hello mark</td>\n",
       "      <td>457.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hello princess</td>\n",
       "      <td>433.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hello general</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145768</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145769</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145770</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145771</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145772</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145773 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               twogram  freq_twogram\n",
       "0          media group        4604.0\n",
       "1        hello sheriff         501.0\n",
       "2           hello mark         457.0\n",
       "3       hello princess         433.0\n",
       "4        hello general         398.0\n",
       "...                ...           ...\n",
       "145768             NaN           NaN\n",
       "145769             NaN           NaN\n",
       "145770             NaN           NaN\n",
       "145771             NaN           NaN\n",
       "145772             NaN           NaN\n",
       "\n",
       "[145773 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twogram_diff_freq = pd.merge(df_twogram_diff, df_shared_select_twogram, how=\"left\", on=\"twogram\")\n",
    "df_twogram_diff_freq.sort_values(by=\"freq_twogram\", ascending=False, inplace=True)\n",
    "df_twogram_diff_freq.reset_index(drop=True, inplace=True)\n",
    "df_twogram_diff_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shared_file[\"twogram\"] = df_twogram_diff_freq[\"twogram\"]\n",
    "df_shared_file[\"freq_twogram\"] = df_twogram_diff_freq[\"freq_twogram\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "      <th>twogram</th>\n",
       "      <th>freq_twogram</th>\n",
       "      <th>threegram</th>\n",
       "      <th>freq_threegram</th>\n",
       "      <th>fourgram</th>\n",
       "      <th>freq_fourgram</th>\n",
       "      <th>fivegram</th>\n",
       "      <th>freq_fivegram</th>\n",
       "      <th>sentence</th>\n",
       "      <th>freq_sentence</th>\n",
       "      <th>twogram_in_threegram</th>\n",
       "      <th>freq_two_in_three</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you</td>\n",
       "      <td>102069964.0</td>\n",
       "      <td>media group</td>\n",
       "      <td>4604.0</td>\n",
       "      <td>i do not</td>\n",
       "      <td>3520257</td>\n",
       "      <td>you do not have</td>\n",
       "      <td>160426.0</td>\n",
       "      <td>you do not have to</td>\n",
       "      <td>107450.0</td>\n",
       "      <td>of course</td>\n",
       "      <td>266277.0</td>\n",
       "      <td>i am</td>\n",
       "      <td>10494331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i</td>\n",
       "      <td>94447074.0</td>\n",
       "      <td>hello sheriff</td>\n",
       "      <td>501.0</td>\n",
       "      <td>i am not</td>\n",
       "      <td>1262941</td>\n",
       "      <td>i do not have</td>\n",
       "      <td>158788.0</td>\n",
       "      <td>i do not have a</td>\n",
       "      <td>34568.0</td>\n",
       "      <td>what is it</td>\n",
       "      <td>251203.0</td>\n",
       "      <td>do not</td>\n",
       "      <td>8972296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>77481215.0</td>\n",
       "      <td>hello mark</td>\n",
       "      <td>457.0</td>\n",
       "      <td>what do you</td>\n",
       "      <td>1120086</td>\n",
       "      <td>do not have to</td>\n",
       "      <td>150328.0</td>\n",
       "      <td>do not have to do</td>\n",
       "      <td>21572.0</td>\n",
       "      <td>stop it</td>\n",
       "      <td>152280.0</td>\n",
       "      <td>i do</td>\n",
       "      <td>4179914.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>58281119.0</td>\n",
       "      <td>hello princess</td>\n",
       "      <td>433.0</td>\n",
       "      <td>you do not</td>\n",
       "      <td>1010676</td>\n",
       "      <td>no i do not</td>\n",
       "      <td>105374.0</td>\n",
       "      <td>i do not have to</td>\n",
       "      <td>21499.0</td>\n",
       "      <td>i am</td>\n",
       "      <td>136931.0</td>\n",
       "      <td>i will</td>\n",
       "      <td>3706224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>50852895.0</td>\n",
       "      <td>hello general</td>\n",
       "      <td>398.0</td>\n",
       "      <td>do not you</td>\n",
       "      <td>644488</td>\n",
       "      <td>i do not like</td>\n",
       "      <td>99318.0</td>\n",
       "      <td>i do not like it</td>\n",
       "      <td>18564.0</td>\n",
       "      <td>i do</td>\n",
       "      <td>114801.0</td>\n",
       "      <td>do you</td>\n",
       "      <td>3358227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206638</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i control radiation</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206639</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the antibiotic i</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206640</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my radar screen</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206641</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cup will not</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206642</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stop on no</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206643 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word    frequency         twogram  freq_twogram            threegram  \\\n",
       "0       you  102069964.0     media group        4604.0             i do not   \n",
       "1         i   94447074.0   hello sheriff         501.0             i am not   \n",
       "2       the   77481215.0      hello mark         457.0          what do you   \n",
       "3        to   58281119.0  hello princess         433.0           you do not   \n",
       "4        is   50852895.0   hello general         398.0           do not you   \n",
       "...     ...          ...             ...           ...                  ...   \n",
       "206638  NaN          NaN             NaN           NaN  i control radiation   \n",
       "206639  NaN          NaN             NaN           NaN     the antibiotic i   \n",
       "206640  NaN          NaN             NaN           NaN      my radar screen   \n",
       "206641  NaN          NaN             NaN           NaN         cup will not   \n",
       "206642  NaN          NaN             NaN           NaN           stop on no   \n",
       "\n",
       "        freq_threegram         fourgram  freq_fourgram            fivegram  \\\n",
       "0              3520257  you do not have       160426.0  you do not have to   \n",
       "1              1262941    i do not have       158788.0     i do not have a   \n",
       "2              1120086   do not have to       150328.0   do not have to do   \n",
       "3              1010676      no i do not       105374.0    i do not have to   \n",
       "4               644488    i do not like        99318.0    i do not like it   \n",
       "...                ...              ...            ...                 ...   \n",
       "206638               4              NaN            NaN                 NaN   \n",
       "206639               4              NaN            NaN                 NaN   \n",
       "206640               4              NaN            NaN                 NaN   \n",
       "206641               4              NaN            NaN                 NaN   \n",
       "206642               4              NaN            NaN                 NaN   \n",
       "\n",
       "        freq_fivegram    sentence  freq_sentence twogram_in_threegram  \\\n",
       "0            107450.0   of course       266277.0                 i am   \n",
       "1             34568.0  what is it       251203.0               do not   \n",
       "2             21572.0     stop it       152280.0                 i do   \n",
       "3             21499.0        i am       136931.0               i will   \n",
       "4             18564.0        i do       114801.0               do you   \n",
       "...               ...         ...            ...                  ...   \n",
       "206638            NaN         NaN            NaN                  NaN   \n",
       "206639            NaN         NaN            NaN                  NaN   \n",
       "206640            NaN         NaN            NaN                  NaN   \n",
       "206641            NaN         NaN            NaN                  NaN   \n",
       "206642            NaN         NaN            NaN                  NaN   \n",
       "\n",
       "        freq_two_in_three  \n",
       "0              10494331.0  \n",
       "1               8972296.0  \n",
       "2               4179914.0  \n",
       "3               3706224.0  \n",
       "4               3358227.0  \n",
       "...                   ...  \n",
       "206638                NaN  \n",
       "206639                NaN  \n",
       "206640                NaN  \n",
       "206641                NaN  \n",
       "206642                NaN  \n",
       "\n",
       "[206643 rows x 14 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shared_twogram_process = pd.concat([df_shared_file,df_twogram_in_threegram_freq], axis=1)\n",
    "df_shared_twogram_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shared_twogram_process.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Result_With_Frequency{file_ext}2.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concat Result With Comma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_twogram = word_in_wordgroup(df_shared_twogram_process, \"word\", \"twogram\")\n",
    "df_word_order_threegram = word_in_wordgroup(df_shared_twogram_process, \"word\", \"threegram\") \n",
    "df_word_order_fourgram = word_in_wordgroup(df_shared_twogram_process, \"word\", \"fourgram\") \n",
    "df_word_order_fivegram = word_in_wordgroup(df_shared_twogram_process, \"word\", \"fivegram\")\n",
    "df_word_order_sentence = word_in_wordgroup(df_shared_twogram_process, \"word\", \"sentence\")\n",
    "df_word_order_twogram_threegram = word_in_wordgroup(df_shared_twogram_process, \"word\", \"twogram_in_threegram\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_join_twogram = df_word_order_twogram.groupby([\"word\"])[\"twogram\"].apply(\", \".join).reset_index()   # df_word_order_11.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].transform(lambda x: ','.join(x))\n",
    "df_word_order_join_threegram = df_word_order_threegram.groupby([\"word\"])[\"threegram\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_fourgram = df_word_order_fourgram.groupby([\"word\"])[\"fourgram\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_fivegram = df_word_order_fivegram.groupby([\"word\"])[\"fivegram\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_sentence = df_word_order_sentence.groupby([\"word\"])[\"sentence\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_twogram_threegram = df_word_order_twogram_threegram.groupby([\"word\"])[\"twogram_in_threegram\"].apply(\", \".join).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df_word_order_join_twogram,df_word_order_join_threegram,df_word_order_join_fourgram,df_word_order_join_fivegram,df_word_order_join_sentence,df_word_order_join_twogram_threegram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>twogram</th>\n",
       "      <th>threegram</th>\n",
       "      <th>fourgram</th>\n",
       "      <th>fivegram</th>\n",
       "      <th>sentence</th>\n",
       "      <th>twogram_in_threegram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>agent a, a terrorism, solo a, a tribune, mummy...</td>\n",
       "      <td>i am a, i have a, this is a, you have a, it wa...</td>\n",
       "      <td>i am not a, do not have a, do you have a, this...</td>\n",
       "      <td>i do not have a, you do not have a, we do not ...</td>\n",
       "      <td>a what, not a chance, what a surprise, i am a ...</td>\n",
       "      <td>have a, is a, was a, for a, in a, not a, like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abacus</td>\n",
       "      <td>your abacus, abacus and, abacus of, my abacus</td>\n",
       "      <td>like the abacus, abacus to the, and the abacus...</td>\n",
       "      <td>i like the abacus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>and the abacus, my abacus</td>\n",
       "      <td>the abacus, abacus to, abacus is, abacus you, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abnormal</td>\n",
       "      <td>on abnormal, this abnormal, for abnormal, you ...</td>\n",
       "      <td>i am abnormal, in the abnormal, am i abnormal,...</td>\n",
       "      <td>contact in the abnormal, and you have abnormal...</td>\n",
       "      <td>we have on the abnormal, the reaction to the a...</td>\n",
       "      <td>abnormal psychology, i am abnormal, am i abnor...</td>\n",
       "      <td>the abnormal, no abnormal, abnormal psychology...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>absorb</td>\n",
       "      <td>i absorb, absorb shock</td>\n",
       "      <td>to absorb the, will absorb the, and absorb it,...</td>\n",
       "      <td>it and absorb it, will absorb the radiation, t...</td>\n",
       "      <td>that will absorb the radiation, the ocean will...</td>\n",
       "      <td>absorb it, to absorb, i absorb, absorb this in...</td>\n",
       "      <td>to absorb, absorb the, absorb it, will absorb,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>absurd</td>\n",
       "      <td>absurd it, absurd you, what absurd, you absurd...</td>\n",
       "      <td>this is absurd, that is absurd, it is absurd, ...</td>\n",
       "      <td>absurd is not it, absurd your position is, you...</td>\n",
       "      <td>is it not absurd to, absurd name for a cricket...</td>\n",
       "      <td>this is absurd, that is absurd, it is absurd, ...</td>\n",
       "      <td>is absurd, absurd to, the absurd, this absurd,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>provoke</td>\n",
       "      <td>NaN</td>\n",
       "      <td>do not provoke, not provoke me, to provoke me,...</td>\n",
       "      <td>do not provoke me, i do not provoke, do not yo...</td>\n",
       "      <td>you do do not provoke, do not you provoke me, ...</td>\n",
       "      <td>do not provoke me, i do not provoke, do not pr...</td>\n",
       "      <td>to provoke, not provoke, provoke me, you provo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>quadrillion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a quadrillion electron</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a quadrillion</td>\n",
       "      <td>a quadrillion, quadrillion electron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>retouch</td>\n",
       "      <td>NaN</td>\n",
       "      <td>do not retouch, will retouch it, to retouch it...</td>\n",
       "      <td>we do not retouch, we will retouch it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>retouch it, not retouch, will retouch, to retouch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>sympathizer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>me a sympathizer, a communist sympathizer, is ...</td>\n",
       "      <td>am a communist sympathizer, brother was a symp...</td>\n",
       "      <td>i am a communist sympathizer, your brother was...</td>\n",
       "      <td>communist sympathizer, a sympathizer, i am a c...</td>\n",
       "      <td>a sympathizer, communist sympathizer, sympathi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>unisex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a unisex toilet, you have unisex, it was unise...</td>\n",
       "      <td>me it was unisex, this is a unisex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a unisex, a unisex toilet</td>\n",
       "      <td>a unisex, unisex toilet, have unisex, was unis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1700 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word                                            twogram  \\\n",
       "0               a  agent a, a terrorism, solo a, a tribune, mummy...   \n",
       "1          abacus      your abacus, abacus and, abacus of, my abacus   \n",
       "2        abnormal  on abnormal, this abnormal, for abnormal, you ...   \n",
       "3          absorb                             i absorb, absorb shock   \n",
       "4          absurd  absurd it, absurd you, what absurd, you absurd...   \n",
       "...           ...                                                ...   \n",
       "1695      provoke                                                NaN   \n",
       "1696  quadrillion                                                NaN   \n",
       "1697      retouch                                                NaN   \n",
       "1698  sympathizer                                                NaN   \n",
       "1699       unisex                                                NaN   \n",
       "\n",
       "                                              threegram  \\\n",
       "0     i am a, i have a, this is a, you have a, it wa...   \n",
       "1     like the abacus, abacus to the, and the abacus...   \n",
       "2     i am abnormal, in the abnormal, am i abnormal,...   \n",
       "3     to absorb the, will absorb the, and absorb it,...   \n",
       "4     this is absurd, that is absurd, it is absurd, ...   \n",
       "...                                                 ...   \n",
       "1695  do not provoke, not provoke me, to provoke me,...   \n",
       "1696                             a quadrillion electron   \n",
       "1697  do not retouch, will retouch it, to retouch it...   \n",
       "1698  me a sympathizer, a communist sympathizer, is ...   \n",
       "1699  a unisex toilet, you have unisex, it was unise...   \n",
       "\n",
       "                                               fourgram  \\\n",
       "0     i am not a, do not have a, do you have a, this...   \n",
       "1                                     i like the abacus   \n",
       "2     contact in the abnormal, and you have abnormal...   \n",
       "3     it and absorb it, will absorb the radiation, t...   \n",
       "4     absurd is not it, absurd your position is, you...   \n",
       "...                                                 ...   \n",
       "1695  do not provoke me, i do not provoke, do not yo...   \n",
       "1696                                                NaN   \n",
       "1697              we do not retouch, we will retouch it   \n",
       "1698  am a communist sympathizer, brother was a symp...   \n",
       "1699                 me it was unisex, this is a unisex   \n",
       "\n",
       "                                               fivegram  \\\n",
       "0     i do not have a, you do not have a, we do not ...   \n",
       "1                                                   NaN   \n",
       "2     we have on the abnormal, the reaction to the a...   \n",
       "3     that will absorb the radiation, the ocean will...   \n",
       "4     is it not absurd to, absurd name for a cricket...   \n",
       "...                                                 ...   \n",
       "1695  you do do not provoke, do not you provoke me, ...   \n",
       "1696                                                NaN   \n",
       "1697                                                NaN   \n",
       "1698  i am a communist sympathizer, your brother was...   \n",
       "1699                                                NaN   \n",
       "\n",
       "                                               sentence  \\\n",
       "0     a what, not a chance, what a surprise, i am a ...   \n",
       "1                             and the abacus, my abacus   \n",
       "2     abnormal psychology, i am abnormal, am i abnor...   \n",
       "3     absorb it, to absorb, i absorb, absorb this in...   \n",
       "4     this is absurd, that is absurd, it is absurd, ...   \n",
       "...                                                 ...   \n",
       "1695  do not provoke me, i do not provoke, do not pr...   \n",
       "1696                                      a quadrillion   \n",
       "1697                                                NaN   \n",
       "1698  communist sympathizer, a sympathizer, i am a c...   \n",
       "1699                          a unisex, a unisex toilet   \n",
       "\n",
       "                                   twogram_in_threegram  \n",
       "0     have a, is a, was a, for a, in a, not a, like ...  \n",
       "1     the abacus, abacus to, abacus is, abacus you, ...  \n",
       "2     the abnormal, no abnormal, abnormal psychology...  \n",
       "3     to absorb, absorb the, absorb it, will absorb,...  \n",
       "4     is absurd, absurd to, the absurd, this absurd,...  \n",
       "...                                                 ...  \n",
       "1695  to provoke, not provoke, provoke me, you provo...  \n",
       "1696                a quadrillion, quadrillion electron  \n",
       "1697  retouch it, not retouch, will retouch, to retouch  \n",
       "1698  a sympathizer, communist sympathizer, sympathi...  \n",
       "1699  a unisex, unisex toilet, have unisex, was unis...  \n",
       "\n",
       "[1700 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_order_join_all = reduce(lambda  left,right: pd.merge(left,right, on=['word'], how='outer'), dfs)  # left,right make left to right merge\n",
    "#df_word_order_join_all = reduce(lambda  right,left: pd.merge(left,right, on=['word'], how='outer'), dfs)  # right,left make right to left merge\n",
    "df_word_order_join_all  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "      <th>twogram</th>\n",
       "      <th>threegram</th>\n",
       "      <th>fourgram</th>\n",
       "      <th>fivegram</th>\n",
       "      <th>sentence</th>\n",
       "      <th>twogram_in_threegram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you</td>\n",
       "      <td>102069964</td>\n",
       "      <td>you korean, specific you, cypher you, you comm...</td>\n",
       "      <td>what do you, you do not, do not you, you have ...</td>\n",
       "      <td>you do not have, do you have a, no you do not,...</td>\n",
       "      <td>you do not have to, you do not have a, you do ...</td>\n",
       "      <td>and you, do you, you do, no you do not, you do...</td>\n",
       "      <td>do you, you have, you do, not you, you will, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i</td>\n",
       "      <td>94447074</td>\n",
       "      <td>anonymous i, i absorb, i contract, i wow, dies...</td>\n",
       "      <td>i do not, i am not, i am a, i have to, i will ...</td>\n",
       "      <td>i do not have, no i do not, i do not like, i a...</td>\n",
       "      <td>i do not have a, i do not have to, i do not li...</td>\n",
       "      <td>i am, i do, i will, i do not, i am not, no i d...</td>\n",
       "      <td>i am, i do, i will, i have, i was, and i, what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>77481215</td>\n",
       "      <td>the idealist, fantastic the, sophisticated the...</td>\n",
       "      <td>this is the, i am the, out of the, it was the,...</td>\n",
       "      <td>i am in the, i am not the, this is not the, do...</td>\n",
       "      <td>i do not have the, i do not like the, i am not...</td>\n",
       "      <td>what the, the what, the police, the baby, the ...</td>\n",
       "      <td>in the, to the, on the, of the, what the, for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>58281119</td>\n",
       "      <td>to booster, to princess, to formula, to capaci...</td>\n",
       "      <td>i have to, you have to, we have to, not have t...</td>\n",
       "      <td>do not have to, you will have to, do i have to...</td>\n",
       "      <td>you do not have to, do not have to do, i do no...</td>\n",
       "      <td>i have to, you do not have to, you have to, to...</td>\n",
       "      <td>have to, to the, to me, to do, to you, you to,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>50852895</td>\n",
       "      <td>is simultaneous, is feminine, is bourgeois, tu...</td>\n",
       "      <td>what is it, this is not, this is a, this is th...</td>\n",
       "      <td>this is not a, is that what you, this is not t...</td>\n",
       "      <td>you have to do is, is not that what you, is th...</td>\n",
       "      <td>what is it, what is this, what is that, it is,...</td>\n",
       "      <td>this is, is not, is it, what is, is that, it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2299</th>\n",
       "      <td>camp</td>\n",
       "      <td>6</td>\n",
       "      <td>captain camp, camp zombie, camp doctor, camp e...</td>\n",
       "      <td>in the camp, to the camp, we will camp, in thi...</td>\n",
       "      <td>this is base camp, me to the camp, the camp wa...</td>\n",
       "      <td>this for a band camp, this is a training camp,...</td>\n",
       "      <td>the camp, base camp, what camp, a camp, in the...</td>\n",
       "      <td>the camp, to camp, base camp, this camp, camp ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>session</td>\n",
       "      <td>6</td>\n",
       "      <td>practice session, detector session, session a,...</td>\n",
       "      <td>is in session, the session is, have a session,...</td>\n",
       "      <td>a group therapy session, congress is in sessio...</td>\n",
       "      <td>the meeting is in session, in a group therapy ...</td>\n",
       "      <td>i am in session, school is in session, this is...</td>\n",
       "      <td>in session, a session, the session, this sessi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2301</th>\n",
       "      <td>captain</td>\n",
       "      <td>6</td>\n",
       "      <td>captain axis, captain camp, control captain, c...</td>\n",
       "      <td>this is captain, i am captain, is the captain,...</td>\n",
       "      <td>this is the captain, i am the captain, this is...</td>\n",
       "      <td>i am the captain of, captain of the football t...</td>\n",
       "      <td>this is the captain, the captain, no captain, ...</td>\n",
       "      <td>the captain, you captain, captain i, is captai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2302</th>\n",
       "      <td>have</td>\n",
       "      <td>6</td>\n",
       "      <td>have name, have depressed, have tank, caps hav...</td>\n",
       "      <td>do not have, i have to, you have to, i have a,...</td>\n",
       "      <td>you do not have, i do not have, do not have to...</td>\n",
       "      <td>you do not have to, i do not have a, do not ha...</td>\n",
       "      <td>i have, have you, i have to, you do not have t...</td>\n",
       "      <td>i have, you have, have to, we have, have a, no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2303</th>\n",
       "      <td>point</td>\n",
       "      <td>6</td>\n",
       "      <td>point bar, million point, out point, point cap...</td>\n",
       "      <td>not the point, the point is, to the point, the...</td>\n",
       "      <td>what is the point, you have a point, is not th...</td>\n",
       "      <td>that is not the point, what is the point of, i...</td>\n",
       "      <td>the point is, no point, your point, what is th...</td>\n",
       "      <td>the point, a point, your point, point is, poin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2304 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  frequency                                            twogram  \\\n",
       "0         you  102069964  you korean, specific you, cypher you, you comm...   \n",
       "1           i   94447074  anonymous i, i absorb, i contract, i wow, dies...   \n",
       "2         the   77481215  the idealist, fantastic the, sophisticated the...   \n",
       "3          to   58281119  to booster, to princess, to formula, to capaci...   \n",
       "4          is   50852895  is simultaneous, is feminine, is bourgeois, tu...   \n",
       "...       ...        ...                                                ...   \n",
       "2299     camp          6  captain camp, camp zombie, camp doctor, camp e...   \n",
       "2300  session          6  practice session, detector session, session a,...   \n",
       "2301  captain          6  captain axis, captain camp, control captain, c...   \n",
       "2302     have          6  have name, have depressed, have tank, caps hav...   \n",
       "2303    point          6  point bar, million point, out point, point cap...   \n",
       "\n",
       "                                              threegram  \\\n",
       "0     what do you, you do not, do not you, you have ...   \n",
       "1     i do not, i am not, i am a, i have to, i will ...   \n",
       "2     this is the, i am the, out of the, it was the,...   \n",
       "3     i have to, you have to, we have to, not have t...   \n",
       "4     what is it, this is not, this is a, this is th...   \n",
       "...                                                 ...   \n",
       "2299  in the camp, to the camp, we will camp, in thi...   \n",
       "2300  is in session, the session is, have a session,...   \n",
       "2301  this is captain, i am captain, is the captain,...   \n",
       "2302  do not have, i have to, you have to, i have a,...   \n",
       "2303  not the point, the point is, to the point, the...   \n",
       "\n",
       "                                               fourgram  \\\n",
       "0     you do not have, do you have a, no you do not,...   \n",
       "1     i do not have, no i do not, i do not like, i a...   \n",
       "2     i am in the, i am not the, this is not the, do...   \n",
       "3     do not have to, you will have to, do i have to...   \n",
       "4     this is not a, is that what you, this is not t...   \n",
       "...                                                 ...   \n",
       "2299  this is base camp, me to the camp, the camp wa...   \n",
       "2300  a group therapy session, congress is in sessio...   \n",
       "2301  this is the captain, i am the captain, this is...   \n",
       "2302  you do not have, i do not have, do not have to...   \n",
       "2303  what is the point, you have a point, is not th...   \n",
       "\n",
       "                                               fivegram  \\\n",
       "0     you do not have to, you do not have a, you do ...   \n",
       "1     i do not have a, i do not have to, i do not li...   \n",
       "2     i do not have the, i do not like the, i am not...   \n",
       "3     you do not have to, do not have to do, i do no...   \n",
       "4     you have to do is, is not that what you, is th...   \n",
       "...                                                 ...   \n",
       "2299  this for a band camp, this is a training camp,...   \n",
       "2300  the meeting is in session, in a group therapy ...   \n",
       "2301  i am the captain of, captain of the football t...   \n",
       "2302  you do not have to, i do not have a, do not ha...   \n",
       "2303  that is not the point, what is the point of, i...   \n",
       "\n",
       "                                               sentence  \\\n",
       "0     and you, do you, you do, no you do not, you do...   \n",
       "1     i am, i do, i will, i do not, i am not, no i d...   \n",
       "2     what the, the what, the police, the baby, the ...   \n",
       "3     i have to, you do not have to, you have to, to...   \n",
       "4     what is it, what is this, what is that, it is,...   \n",
       "...                                                 ...   \n",
       "2299  the camp, base camp, what camp, a camp, in the...   \n",
       "2300  i am in session, school is in session, this is...   \n",
       "2301  this is the captain, the captain, no captain, ...   \n",
       "2302  i have, have you, i have to, you do not have t...   \n",
       "2303  the point is, no point, your point, what is th...   \n",
       "\n",
       "                                   twogram_in_threegram  \n",
       "0     do you, you have, you do, not you, you will, f...  \n",
       "1     i am, i do, i will, i have, i was, and i, what...  \n",
       "2     in the, to the, on the, of the, what the, for ...  \n",
       "3     have to, to the, to me, to do, to you, you to,...  \n",
       "4     this is, is not, is it, what is, is that, it i...  \n",
       "...                                                 ...  \n",
       "2299  the camp, to camp, base camp, this camp, camp ...  \n",
       "2300  in session, a session, the session, this sessi...  \n",
       "2301  the captain, you captain, captain i, is captai...  \n",
       "2302  i have, you have, have to, we have, have a, no...  \n",
       "2303  the point, a point, your point, point is, poin...  \n",
       "\n",
       "[2304 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option For Word Frequency\n",
    "if shared_word_frequency:\n",
    "    df_word_order_join_all = pd.merge(df_word_order_join_all,df_word_all, how=\"inner\", on=\"word\")\n",
    "    df_word_order_join_all.drop_duplicates(inplace=True)\n",
    "    df_word_order_join_all = df_word_order_join_all.loc[:,[\"word\",\"frequency\",\"twogram\",\"threegram\",\"fourgram\",\"fivegram\",\"sentence\",\"twogram_in_threegram\"]]\n",
    "    df_word_order_join_all.sort_values(by=\"frequency\", inplace=True, ascending=False)\n",
    "    df_word_order_join_all.reset_index(drop=True, inplace=True)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "df_word_order_join_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_join_all.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Join_Result_Without_Frequency{file_ext}2.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Move And Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['English_Turkish_Shared_Result_With_Frequency12.xlsx',\n",
       " 'English_Turkish_Shared_Join_Result_Without_Frequency12.xlsx']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file = glob.glob(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared*{file_ext}2.xlsx\")\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in output_file:\n",
    "    source = k # source directory\n",
    "    destination = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/5-Shared Word File/{lang_folder.capitalize()} {lang_pair.capitalize()}\"\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in output_file:\n",
    "    try:\n",
    "        os.remove(i)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prefix Suffix Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "lang_pair = \"Italian\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "# adding native word to shared word\n",
    "word_start = 0  # 0  # native word start index\n",
    "word_end = 28  # 28  # native word end index\n",
    "\n",
    "# word sample\n",
    "word_sample = True  # True, False\n",
    "word_sample_num = 20\n",
    "\n",
    "# shared word frequency\n",
    "shared_word_frequency = True  # True, False\n",
    "\n",
    "# prefix suffix file\n",
    "prefix_suffix = True  # True, False  # always must be True in this part\n",
    "native_word = False # True for adding native word\n",
    "etymology_word = True  # True for adding etymology word\n",
    "\n",
    "# adding output file extention\n",
    "if (not prefix_suffix) & etymology_word & native_word:\n",
    "    file_ext = \"1\"\n",
    "elif (not prefix_suffix) & etymology_word & (not native_word):\n",
    "    file_ext = \"2\"\n",
    "elif prefix_suffix & etymology_word & native_word:\n",
    "    file_ext = \"3\"\n",
    "elif prefix_suffix & etymology_word & (not native_word):\n",
    "    file_ext = \"4\"\n",
    "elif prefix_suffix & (not etymology_word) & native_word:\n",
    "    file_ext = \"5\"\n",
    "elif (not prefix_suffix) & (not etymology_word) & native_word:\n",
    "    file_ext = \"6\"\n",
    "else:\n",
    "    file_ext = \"7\"              \n",
    "# 1 => for native word and etymology word without prefix suffix. \n",
    "# 2 => for only etymology word without prefix suffix. \n",
    "# 3 => for native word and etymology word with prefix suffix. prefix_suffix, native_word and etymology_word must be True. \n",
    "# 4 => for only etymology word with prefix suffix.\n",
    "# 5 => for only native word with prefix suffix.\n",
    "# 6 => for only native word without prefix suffix.\n",
    "print(f\"{file_ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_in_wordgroup(df, source_column, target_column):\n",
    "\n",
    "    '''word_in_wordgroup(df, \"word\", \"twogram\"):\n",
    "       df is dataframe, source_column and target_column are \n",
    "       dataframe column string name. source_column convert list\n",
    "       values that are in target column.\n",
    "    '''\n",
    "    \n",
    "    df_select = df[[f\"{target_column}\"]].dropna()\n",
    "    df_word_result = pd.DataFrame()\n",
    "    for i in df[f\"{source_column}\"].dropna():\n",
    "        try:\n",
    "            if word_sample:\n",
    "                word_in_word_cluster = df_select[df_select[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)].head(word_sample_num)  # Option\n",
    "            else:\n",
    "                word_in_word_cluster = df_select[df_select[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)] \n",
    "        except:\n",
    "            pass        \n",
    "        word_in_word_cluster.insert(0,f\"{source_column}\",i)\n",
    "        df_word_result = pd.concat([df_word_result,word_in_word_cluster], axis=0)\n",
    "    df_word_result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_word_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.lower().capitalize()}/Deployment/Data/Word/Word_Merge_Preprocess.xlsx\")\n",
    "df_word_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_prefix_suffix = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_{word_end}_Word_Prefix_Suffix_Custom_Result_Manuel.xlsx\")\n",
    "df_word_prefix_suffix = df_word_prefix_suffix[[\"search_word\",\"word\"]]\n",
    "df_word_prefix_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ety_prefix_suffix = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Word_Prefix_Suffix_Custom_Result.xlsx\")\n",
    "df_ety_prefix_suffix = df_ety_prefix_suffix[[\"search_word\",\"word\"]]\n",
    "df_ety_prefix_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file_ext == \"3\":\n",
    "    df_all_word = pd.concat([df_word_prefix_suffix,df_ety_prefix_suffix],axis=0)\n",
    "    df_all_word.drop_duplicates(inplace=True)\n",
    "    df_all_word.reset_index(drop=True, inplace=True)\n",
    "elif file_ext == \"4\":\n",
    "    df_all_word = df_ety_prefix_suffix\n",
    "    df_all_word.drop_duplicates(inplace=True)\n",
    "    df_all_word.reset_index(drop=True, inplace=True)\n",
    "elif file_ext == \"5\":\n",
    "    df_all_word = df_word_prefix_suffix\n",
    "    df_all_word.drop_duplicates(inplace=True)\n",
    "    df_all_word.reset_index(drop=True, inplace=True)\n",
    "else:\n",
    "    pass\n",
    "    \n",
    "df_all_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_word.search_word.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_word.word.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shared_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/4-Shared Word/{lang_folder.capitalize()} {lang_pair.capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Result_With_Frequency{file_ext}.xlsx\")\n",
    "#df_shared_all = pd.read_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Result_With_Frequency.xlsx\")\n",
    "df_shared_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_twogram = word_in_wordgroup(df_shared_all, \"word\", \"twogram\")\n",
    "df_word_order_threegram = word_in_wordgroup(df_shared_all, \"word\", \"threegram\") \n",
    "df_word_order_fourgram = word_in_wordgroup(df_shared_all, \"word\", \"fourgram\") \n",
    "df_word_order_fivegram = word_in_wordgroup(df_shared_all, \"word\", \"fivegram\")\n",
    "df_word_order_sentence = word_in_wordgroup(df_shared_all, \"word\", \"sentence\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_twogram = pd.merge(df_word_order_twogram,df_all_word, how=\"inner\", on=\"word\")\n",
    "df_word_order_threegram = pd.merge(df_word_order_threegram,df_all_word, how=\"inner\", on=\"word\")\n",
    "df_word_order_fourgram = pd.merge(df_word_order_fourgram,df_all_word, how=\"inner\", on=\"word\")\n",
    "df_word_order_fivegram = pd.merge(df_word_order_fivegram,df_all_word, how=\"inner\", on=\"word\")\n",
    "df_word_order_sentence = pd.merge(df_word_order_sentence,df_all_word, how=\"inner\", on=\"word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_join_twogram = df_word_order_twogram.groupby([\"search_word\"])[\"twogram\"].apply(\", \".join).reset_index()   # df_word_order_11.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].transform(lambda x: ','.join(x))\n",
    "df_word_order_join_threegram = df_word_order_threegram.groupby([\"search_word\"])[\"threegram\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_fourgram = df_word_order_fourgram.groupby([\"search_word\"])[\"fourgram\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_fivegram = df_word_order_fivegram.groupby([\"search_word\"])[\"fivegram\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_sentence = df_word_order_sentence.groupby([\"search_word\"])[\"sentence\"].apply(\", \".join).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df_word_order_join_twogram,df_word_order_join_threegram,df_word_order_join_fourgram,df_word_order_join_fivegram,df_word_order_join_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_join_all = reduce(lambda  left,right: pd.merge(left,right, on=['search_word'], how='outer'), dfs)  # left,right make left to right merge\n",
    "#df_word_order_join_all = reduce(lambda  right,left: pd.merge(left,right, on=['word'], how='outer'), dfs)  # right,left make right to left merge\n",
    "df_word_order_join_all.rename(columns={\"search_word\":\"word\"}, inplace=True)\n",
    "df_word_order_join_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option For Word Frequency\n",
    "if shared_word_frequency:\n",
    "    df_word_order_join_all = pd.merge(df_word_order_join_all,df_word_all, how=\"left\", on=\"word\")\n",
    "    df_word_order_join_all.drop_duplicates(inplace=True)\n",
    "    df_word_order_join_all = df_word_order_join_all.loc[:,[\"word\",\"frequency\",\"twogram\",\"threegram\",\"fourgram\",\"fivegram\",\"sentence\"]]\n",
    "    df_word_order_join_all.sort_values(by=\"frequency\", inplace=True, ascending=False)\n",
    "    df_word_order_join_all.reset_index(drop=True, inplace=True)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "df_word_order_join_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_join_all.word.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_join_all.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Join_Result_Without_Frequency{file_ext}3.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Move And Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file2 = glob.glob(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared*{file_ext}3.xlsx\")\n",
    "output_file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in output_file2:\n",
    "    source = l # source directory\n",
    "    destination = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/5-Shared Word File/{lang_folder.capitalize()} {lang_pair.capitalize()}\"\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in output_file2:\n",
    "    try:\n",
    "        os.remove(j)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prefix Suffix Shared File Word Result Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## language pair (same previous part parameter)\n",
    "#lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "#lang_pair = \"French\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "# word sample\n",
    "word_sample_num = 20\n",
    "\n",
    "print(f\"{file_ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_strip_func(x):\n",
    "    try:\n",
    "        var_low = x.lower()\n",
    "        var_out = var_low.strip()\n",
    "    except:\n",
    "        var_out = x\n",
    "    return var_out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shared_process_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/5-Shared Word File/{lang_folder.capitalize()} {lang_pair.capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Join_Result_Without_Frequency{file_ext}3.xlsx\")\n",
    "df_shared_process_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.lower().capitalize()}/Deployment/Data/Word/Word_Merge_Preprocess.xlsx\")\n",
    "df_word_all = df_word_all.loc[:,[\"word\",\"frequency\"]]\n",
    "df_word_all[\"word\"] = df_word_all[\"word\"].apply(lambda x: lower_strip_func(x))\n",
    "df_word_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twogram_all = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Twogram_Merge.csv\")\n",
    "df_twogram_all = df_twogram_all.loc[:,[\"twogram\",\"frequency\"]]\n",
    "df_twogram_all[\"twogram\"] = df_twogram_all[\"twogram\"].apply(lambda x: lower_strip_func(x))\n",
    "df_twogram_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_threegram_all = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Threegram_Merge.csv\")\n",
    "df_threegram_all = df_threegram_all.loc[:,[\"threegram\",\"frequency\"]]\n",
    "df_threegram_all[\"threegram\"] = df_threegram_all[\"threegram\"].apply(lambda x: lower_strip_func(x))\n",
    "df_threegram_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fourgram_all = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Fourgram_Merge.csv\")\n",
    "df_fourgram_all = df_fourgram_all.loc[:,[\"fourgram\",\"frequency\"]]\n",
    "df_fourgram_all[\"fourgram\"] = df_fourgram_all[\"fourgram\"].apply(lambda x: lower_strip_func(x))\n",
    "df_fourgram_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fivegram_all = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Fivegram_Merge.csv\")\n",
    "df_fivegram_all = df_fivegram_all.loc[:,[\"fivegram\",\"frequency\"]]\n",
    "df_fivegram_all[\"fivegram\"] = df_fivegram_all[\"fivegram\"].apply(lambda x: lower_strip_func(x))\n",
    "df_fivegram_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentence_all = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/Sentence/Merge/Sentence_Merge.csv\")\n",
    "df_sentence_all = df_sentence_all.loc[:,[\"sentence\",\"frequency\"]]\n",
    "df_sentence_all[\"sentence\"] = df_sentence_all[\"sentence\"].apply(lambda x: lower_strip_func(x))\n",
    "df_sentence_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_shared_process_all)):\n",
    "    # column result\n",
    "    try:\n",
    "        # column result\n",
    "        df_two_var = pd.DataFrame(df_shared_process_all.loc[i,\"twogram\"].split(\", \"), columns=[\"twogram\"])\n",
    "        # merge with all\n",
    "        df_two_var_merge = pd.merge(df_two_var, df_twogram_all, how=\"left\", on=\"twogram\")\n",
    "        df_two_var_merge.sort_values(by=\"frequency\", ascending=False, inplace=True)\n",
    "        df_two_var_merge_select = df_two_var_merge.head(word_sample_num)\n",
    "        # to list value\n",
    "        df_two_var_list = df_two_var_merge_select[\"twogram\"].to_list()\n",
    "        # list join\n",
    "        df_two_var_list_join = \", \".join(df_two_var_list)\n",
    "        # change value\n",
    "        df_shared_process_all.loc[i,\"twogram\"] = df_two_var_list_join\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        # column result\n",
    "        df_three_var = pd.DataFrame(df_shared_process_all.loc[i,\"threegram\"].split(\", \"), columns=[\"threegram\"])\n",
    "        # merge with all\n",
    "        df_three_var_merge = pd.merge(df_three_var, df_threegram_all, how=\"left\", on=\"threegram\")\n",
    "        df_three_var_merge.sort_values(by=\"frequency\", ascending=False, inplace=True)\n",
    "        df_three_var_merge_select = df_three_var_merge.head(word_sample_num)\n",
    "        # to list value\n",
    "        df_three_var_list = df_three_var_merge_select[\"threegram\"].to_list()\n",
    "        # list join\n",
    "        df_three_var_list_join = \", \".join(df_three_var_list)\n",
    "        # change value\n",
    "        df_shared_process_all.loc[i,\"threegram\"] = df_three_var_list_join\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        # column result\n",
    "        df_four_var = pd.DataFrame(df_shared_process_all.loc[i,\"fourgram\"].split(\", \"), columns=[\"fourgram\"])\n",
    "        # merge with all\n",
    "        df_four_var_merge = pd.merge(df_four_var, df_fourgram_all, how=\"left\", on=\"fourgram\")\n",
    "        df_four_var_merge.sort_values(by=\"frequency\", ascending=False, inplace=True)\n",
    "        df_four_var_merge_select = df_four_var_merge.head(word_sample_num)\n",
    "        # to list value\n",
    "        df_four_var_list = df_four_var_merge_select[\"fourgram\"].to_list()\n",
    "        # list join\n",
    "        df_four_var_list_join = \", \".join(df_four_var_list)\n",
    "        # change value\n",
    "        df_shared_process_all.loc[i,\"fourgram\"] = df_four_var_list_join\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        # column result\n",
    "        df_five_var = pd.DataFrame(df_shared_process_all.loc[i,\"fivegram\"].split(\", \"), columns=[\"fivegram\"])\n",
    "        # merge with all\n",
    "        df_five_var_merge = pd.merge(df_five_var, df_fivegram_all, how=\"left\", on=\"fivegram\")\n",
    "        df_five_var_merge.sort_values(by=\"frequency\", ascending=False, inplace=True)\n",
    "        df_five_var_merge_select = df_five_var_merge.head(word_sample_num)\n",
    "        # to list value\n",
    "        df_five_var_list = df_five_var_merge_select[\"fivegram\"].to_list()\n",
    "        # list join\n",
    "        df_five_var_list_join = \", \".join(df_five_var_list)\n",
    "        # change value\n",
    "        df_shared_process_all.loc[i,\"fivegram\"] = df_five_var_list_join\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        # column result\n",
    "        df_sentence_var = pd.DataFrame(df_shared_process_all.loc[i,\"sentence\"].split(\", \"), columns=[\"sentence\"])\n",
    "        # merge with all\n",
    "        df_sentence_var_merge = pd.merge(df_sentence_var, df_sentence_all, how=\"left\", on=\"sentence\")\n",
    "        df_sentence_var_merge.sort_values(by=\"frequency\", ascending=False, inplace=True)\n",
    "        df_sentence_var_merge_select = df_sentence_var_merge.head(word_sample_num)\n",
    "        # to list value\n",
    "        df_sentence_var_list = df_sentence_var_merge_select[\"sentence\"].to_list()\n",
    "        # list join\n",
    "        df_sentence_var_list_join = \", \".join(df_sentence_var_list)\n",
    "        # change value\n",
    "        df_shared_process_all.loc[i,\"sentence\"] = df_sentence_var_list_join\n",
    "    except:\n",
    "        pass      \n",
    "\n",
    "df_shared_process_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_shared_process_all.sort_values(by=\"frequency\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shared_process_all.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Join_Select_Result_Without_Frequency{file_ext}4.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Move And Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file3 = glob.glob(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared*_Select_*{file_ext}4.xlsx\")\n",
    "output_file3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in output_file3:\n",
    "    source = l # source directory\n",
    "    destination = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/5-Shared Word File/{lang_folder.capitalize()} {lang_pair.capitalize()}\"\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in output_file3:\n",
    "    try:\n",
    "        os.remove(j)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Count Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "lang_pair = \"English\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/5-Shared Word File/{lang_folder.capitalize()} {lang_pair.capitalize()}\").mkdir(parents=True, exist_ok=True)\n",
    "Path(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/Deploy Result Manuel\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_result(df,column_list): # df is dataframe, column_list is list value\n",
    "    '''\n",
    "    word_count_bool(df, column_list): df columns word count for word frequency\\n\n",
    "    df is dataframe, column_list is list value\\n\n",
    "    word_count_bool(df, [\"word\",\"twogram\"]):\n",
    "    '''\n",
    "    list_all = []\n",
    "    for i in df.loc[:,[x for x in column_list]].columns:\n",
    "        var_list = df[f\"{i}\"].dropna().tolist()\n",
    "        for j in var_list:\n",
    "            list_all.append(j)\n",
    "    text = \" \".join(list_all)\n",
    "    word_list = re.findall(r\"\\w+\",text, re.UNICODE)\n",
    "    df_word_list = pd.DataFrame(word_list, columns=[\"word\"])\n",
    "    #df_word_list.rename(columns={0:\"word\"}, inplace=True)\n",
    "    df_word_count = pd.DataFrame(df_word_list.value_counts())\n",
    "    df_word_count.reset_index(inplace=True)\n",
    "    df_word_count.rename(columns={0:\"word_count\"}, inplace=True)\n",
    "    \n",
    "    return  df_word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hybrid Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybrid = pd.read_excel(\"Turkish English manual selected 2 gram hybrids 3.xlsx\", sheet_name=\"2 gram hybrid\")\n",
    "df_hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybrid_count = word_count_result(df_hybrid, [\"twogram_pair1\",\"twogram_pair2\",\"twogram_pair3\",\"twogram_pair4\"])\n",
    "df_hybrid_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybrid_count_merge = pd.merge(df_hybrid,df_hybrid_count,how=\"left\",on=\"word\")\n",
    "df_hybrid_count_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybrid_count_merge2 = pd.merge(df_hybrid,df_hybrid_count,how=\"outer\",on=\"word\")\n",
    "df_hybrid_count_merge2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(f\"{lang_folder}_{lang_pair}_Hybrid_Word_Count.xlsx\", engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybrid_count_merge.to_excel(writer, sheet_name='28_Hybrid_Word_Count', index=False)\n",
    "df_hybrid_count_merge2.to_excel(writer, sheet_name='All_Hybrid_Word_Count', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = pd.read_excel(\"Turkish English manual selected 2 gram hybrids 3.xlsx\", sheet_name=\"2 gram target\")\n",
    "df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_count = word_count_result(df_target, [\"twogram_1\",\"twogram_2\",\"twogram_3\",\"twogram_4\"])\n",
    "df_target_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_count_merge = pd.merge(df_target,df_target_count,how=\"left\",on=\"word\")\n",
    "df_target_count_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_count_merge2 = pd.merge(df_target,df_target_count,how=\"outer\",on=\"word\")\n",
    "df_target_count_merge2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer2 = pd.ExcelWriter(f\"{lang_folder}_{lang_pair}_Target_Word_Count.xlsx\", engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_count_merge.to_excel(writer2, sheet_name='28_Target_Word_Count', index=False)\n",
    "df_target_count_merge2.to_excel(writer2, sheet_name='All_Target_Word_Count', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer2.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All Target Hybrid Word Count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybrid_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_word = pd.concat([df_target_count, df_hybrid_count], axis=0)\n",
    "df_all_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_word.groupby(\"word\")[[\"word_count\"]].sum().reset_index(inplace=True)\n",
    "df_all_word.sort_values(by=\"word_count\", ascending=False, inplace=True)\n",
    "df_all_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_word.to_excel(f\"{lang_folder}_{lang_pair}_Target_Hybrid_Word_Count.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Move And Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file4 = glob.glob(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_*_Word_Count.xlsx\")\n",
    "output_file4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in output_file4:\n",
    "    source = o # source directory\n",
    "    destination = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/5-Shared Word File/{lang_folder.capitalize()} {lang_pair.capitalize()}\"\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in output_file4:\n",
    "    try:\n",
    "        os.remove(p)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Prefix Suffix Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shared_word = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shared_word_count = word_count_result(df_shared_word, [\"twogram_1\",\"twogram_2\",\"twogram_3\",\"twogram_4\"])\n",
    "df_shared_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Youtube Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "lang_pair = \"English\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "# parameter\n",
    "sheets = \"2 gram hybrid\"  # 2 gram target, 2 gram hybrid\n",
    "time_shift = 0.6\n",
    "sample_num = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sentence</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:02:51.948</td>\n",
       "      <td>00:02:58.829</td>\n",
       "      <td>özgür bunlar normalde kamyon daha büyük araçla...</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:03:00.956</td>\n",
       "      <td>00:03:04.236</td>\n",
       "      <td>burcu arka tarafı bağlamak kolay olmayacak</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:03:13.434</td>\n",
       "      <td>00:03:16.327</td>\n",
       "      <td>özgür arabaya yarım tur attıracağım</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:03:17.235</td>\n",
       "      <td>00:03:21.338</td>\n",
       "      <td>burcu biraz daha devam et devam et tamam oldu</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:03:27.806</td>\n",
       "      <td>00:03:33.383</td>\n",
       "      <td>burcu şimdilik iki tekere takacağız ama kar ka...</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036932</th>\n",
       "      <td>00:07:51.970</td>\n",
       "      <td>00:07:52.470</td>\n",
       "      <td>umarız ki bu büyük ve güçlü teknoloji yanlış e...</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036933</th>\n",
       "      <td>00:07:52.470</td>\n",
       "      <td>00:08:02.304</td>\n",
       "      <td>daha faydalı ve özgün kurumlarda herkesin eşit...</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036934</th>\n",
       "      <td>00:08:02.498</td>\n",
       "      <td>00:08:04.178</td>\n",
       "      <td>i zlediğiniz için teşekkürler</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036935</th>\n",
       "      <td>00:08:04.178</td>\n",
       "      <td>00:08:08.089</td>\n",
       "      <td>yararlandığım kaynakları açıklamada link olara...</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036936</th>\n",
       "      <td>00:08:08.089</td>\n",
       "      <td>00:08:11.770</td>\n",
       "      <td>i leri düzey okuma ve araştırma yapmak isteyen...</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3036937 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           start_time      end_time  \\\n",
       "0        00:02:51.948  00:02:58.829   \n",
       "1        00:03:00.956  00:03:04.236   \n",
       "2        00:03:13.434  00:03:16.327   \n",
       "3        00:03:17.235  00:03:21.338   \n",
       "4        00:03:27.806  00:03:33.383   \n",
       "...               ...           ...   \n",
       "3036932  00:07:51.970  00:07:52.470   \n",
       "3036933  00:07:52.470  00:08:02.304   \n",
       "3036934  00:08:02.498  00:08:04.178   \n",
       "3036935  00:08:04.178  00:08:08.089   \n",
       "3036936  00:08:08.089  00:08:11.770   \n",
       "\n",
       "                                                  sentence     video_id  \n",
       "0        özgür bunlar normalde kamyon daha büyük araçla...  8V9tq1pe8eI  \n",
       "1               burcu arka tarafı bağlamak kolay olmayacak  8V9tq1pe8eI  \n",
       "2                      özgür arabaya yarım tur attıracağım  8V9tq1pe8eI  \n",
       "3            burcu biraz daha devam et devam et tamam oldu  8V9tq1pe8eI  \n",
       "4        burcu şimdilik iki tekere takacağız ama kar ka...  8V9tq1pe8eI  \n",
       "...                                                    ...          ...  \n",
       "3036932  umarız ki bu büyük ve güçlü teknoloji yanlış e...  YFFJ5FyZj4Q  \n",
       "3036933  daha faydalı ve özgün kurumlarda herkesin eşit...  YFFJ5FyZj4Q  \n",
       "3036934                      i zlediğiniz için teşekkürler  YFFJ5FyZj4Q  \n",
       "3036935  yararlandığım kaynakları açıklamada link olara...  YFFJ5FyZj4Q  \n",
       "3036936  i leri düzey okuma ve araştırma yapmak isteyen...  YFFJ5FyZj4Q  \n",
       "\n",
       "[3036937 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_youtube_sentence = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Youtube/Result/{lang_folder.capitalize()}/Sentence Clean Merge/Clean_Youtube_Sentence_Merge_Result.csv\")\n",
    "df_youtube_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_youtube_sentence['start_time'] = pd.to_timedelta(df_youtube_sentence['start_time']) # data type converted timedelta for second \n",
    "df_youtube_sentence['end_time'] = pd.to_timedelta(df_youtube_sentence['end_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sentence</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171.948</td>\n",
       "      <td>178.829</td>\n",
       "      <td>özgür bunlar normalde kamyon daha büyük araçla...</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180.956</td>\n",
       "      <td>184.236</td>\n",
       "      <td>burcu arka tarafı bağlamak kolay olmayacak</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>193.434</td>\n",
       "      <td>196.327</td>\n",
       "      <td>özgür arabaya yarım tur attıracağım</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>197.235</td>\n",
       "      <td>201.338</td>\n",
       "      <td>burcu biraz daha devam et devam et tamam oldu</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>207.806</td>\n",
       "      <td>213.383</td>\n",
       "      <td>burcu şimdilik iki tekere takacağız ama kar ka...</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036932</th>\n",
       "      <td>471.970</td>\n",
       "      <td>472.470</td>\n",
       "      <td>umarız ki bu büyük ve güçlü teknoloji yanlış e...</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036933</th>\n",
       "      <td>472.470</td>\n",
       "      <td>482.304</td>\n",
       "      <td>daha faydalı ve özgün kurumlarda herkesin eşit...</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036934</th>\n",
       "      <td>482.498</td>\n",
       "      <td>484.178</td>\n",
       "      <td>i zlediğiniz için teşekkürler</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036935</th>\n",
       "      <td>484.178</td>\n",
       "      <td>488.089</td>\n",
       "      <td>yararlandığım kaynakları açıklamada link olara...</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036936</th>\n",
       "      <td>488.089</td>\n",
       "      <td>491.770</td>\n",
       "      <td>i leri düzey okuma ve araştırma yapmak isteyen...</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3036937 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         start_time  end_time  \\\n",
       "0           171.948   178.829   \n",
       "1           180.956   184.236   \n",
       "2           193.434   196.327   \n",
       "3           197.235   201.338   \n",
       "4           207.806   213.383   \n",
       "...             ...       ...   \n",
       "3036932     471.970   472.470   \n",
       "3036933     472.470   482.304   \n",
       "3036934     482.498   484.178   \n",
       "3036935     484.178   488.089   \n",
       "3036936     488.089   491.770   \n",
       "\n",
       "                                                  sentence     video_id  \n",
       "0        özgür bunlar normalde kamyon daha büyük araçla...  8V9tq1pe8eI  \n",
       "1               burcu arka tarafı bağlamak kolay olmayacak  8V9tq1pe8eI  \n",
       "2                      özgür arabaya yarım tur attıracağım  8V9tq1pe8eI  \n",
       "3            burcu biraz daha devam et devam et tamam oldu  8V9tq1pe8eI  \n",
       "4        burcu şimdilik iki tekere takacağız ama kar ka...  8V9tq1pe8eI  \n",
       "...                                                    ...          ...  \n",
       "3036932  umarız ki bu büyük ve güçlü teknoloji yanlış e...  YFFJ5FyZj4Q  \n",
       "3036933  daha faydalı ve özgün kurumlarda herkesin eşit...  YFFJ5FyZj4Q  \n",
       "3036934                      i zlediğiniz için teşekkürler  YFFJ5FyZj4Q  \n",
       "3036935  yararlandığım kaynakları açıklamada link olara...  YFFJ5FyZj4Q  \n",
       "3036936  i leri düzey okuma ve araştırma yapmak isteyen...  YFFJ5FyZj4Q  \n",
       "\n",
       "[3036937 rows x 4 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_youtube_sentence['start_time'] = df_youtube_sentence['start_time'].apply(lambda x: x.total_seconds()) # convert seconds\n",
    "df_youtube_sentence['end_time'] = df_youtube_sentence['end_time'].apply(lambda x: x.total_seconds())\n",
    "df_youtube_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_word_group_select = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/Deploy Result Manuel/\\\n",
    "#{lang_folder.capitalize()} {lang_pair.capitalize()} Manual Selected 2 Gram Hybrids.xlsx\", sheet_name= f\"{sheets}\")\n",
    "#df_word_group_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>twogram_pair1</th>\n",
       "      <th>twogram_pair2</th>\n",
       "      <th>twogram_pair3</th>\n",
       "      <th>twogram_pair4</th>\n",
       "      <th>twogram_pair5</th>\n",
       "      <th>twogram_pair6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kontrol</td>\n",
       "      <td>trafik kontrol</td>\n",
       "      <td>kontrol paneli</td>\n",
       "      <td>sistem kontrolü</td>\n",
       "      <td>trafik kontrolü</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doktor</td>\n",
       "      <td>doktor raporu</td>\n",
       "      <td>doktorun numarası</td>\n",
       "      <td>doktorun telefonu</td>\n",
       "      <td>doktorun ofisine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>polis</td>\n",
       "      <td>polis şefi</td>\n",
       "      <td>trafik polisi</td>\n",
       "      <td>sivil polis</td>\n",
       "      <td>polis raporu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dolar</td>\n",
       "      <td>milyon dolar</td>\n",
       "      <td>milyon dolarlık</td>\n",
       "      <td>milyonlarca dolar</td>\n",
       "      <td>amerikan doları</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>komik</td>\n",
       "      <td>komik film</td>\n",
       "      <td>komik videoları</td>\n",
       "      <td>komik tipler</td>\n",
       "      <td>komik karakter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>alarm</td>\n",
       "      <td>genel alarm</td>\n",
       "      <td>alarm sistemi</td>\n",
       "      <td>alarm şifresi</td>\n",
       "      <td>kriz alarmı</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>motor</td>\n",
       "      <td>jet motoru</td>\n",
       "      <td>motorlar stop</td>\n",
       "      <td>motor kontrol</td>\n",
       "      <td>turbo motor</td>\n",
       "      <td>elektrik motorları</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>otobüs</td>\n",
       "      <td>okul otobüsü</td>\n",
       "      <td>takım otobüse</td>\n",
       "      <td>otobüs terminali</td>\n",
       "      <td>turist otobüsü</td>\n",
       "      <td>tur otobüsü</td>\n",
       "      <td>otobüs turu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>manyak</td>\n",
       "      <td>psikopat manyak</td>\n",
       "      <td>manyak film</td>\n",
       "      <td>manyak numara</td>\n",
       "      <td>manyak parti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>makine</td>\n",
       "      <td>fotoğraf makinesi</td>\n",
       "      <td>kahve makinesi</td>\n",
       "      <td>tost makinesi</td>\n",
       "      <td>fotokopi makinesi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word      twogram_pair1        twogram_pair2       twogram_pair3  \\\n",
       "0   kontrol     trafik kontrol       kontrol paneli     sistem kontrolü   \n",
       "1    doktor      doktor raporu    doktorun numarası   doktorun telefonu   \n",
       "2     polis         polis şefi        trafik polisi         sivil polis   \n",
       "3     dolar       milyon dolar      milyon dolarlık   milyonlarca dolar   \n",
       "4     komik         komik film      komik videoları        komik tipler   \n",
       "..      ...                ...                  ...                 ...   \n",
       "71    alarm        genel alarm        alarm sistemi       alarm şifresi   \n",
       "72    motor         jet motoru        motorlar stop       motor kontrol   \n",
       "73   otobüs       okul otobüsü        takım otobüse    otobüs terminali   \n",
       "74   manyak    psikopat manyak          manyak film       manyak numara   \n",
       "75   makine  fotoğraf makinesi       kahve makinesi       tost makinesi   \n",
       "\n",
       "         twogram_pair4        twogram_pair5 twogram_pair6  \n",
       "0      trafik kontrolü                  NaN           NaN  \n",
       "1     doktorun ofisine                  NaN           NaN  \n",
       "2         polis raporu                  NaN           NaN  \n",
       "3      amerikan doları                  NaN           NaN  \n",
       "4       komik karakter                  NaN           NaN  \n",
       "..                 ...                  ...           ...  \n",
       "71         kriz alarmı                  NaN           NaN  \n",
       "72         turbo motor   elektrik motorları           NaN  \n",
       "73      turist otobüsü          tur otobüsü   otobüs turu  \n",
       "74        manyak parti                  NaN           NaN  \n",
       "75   fotokopi makinesi                  NaN           NaN  \n",
       "\n",
       "[76 rows x 7 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp\n",
    "df_word_group_select = pd.read_excel(\"Turkish English manual selected 2 gram hybrids.xlsx\", sheet_name=\"2 gram SV\")\n",
    "df_word_group_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_group_select.loc[74,\"twogram_pair5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be real number, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-2588e2916b99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ali\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: must be real number, not str"
     ]
    }
   ],
   "source": [
    "math.isnan(\"ali\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trafik kontrol',\n",
       " 'kontrol paneli',\n",
       " 'sistem kontrolü',\n",
       " 'trafik kontrolü',\n",
       " 'doktor raporu',\n",
       " 'doktorun numarası',\n",
       " 'doktorun telefonu',\n",
       " 'doktorun ofisine',\n",
       " 'polis şefi',\n",
       " 'trafik polisi',\n",
       " 'sivil polis',\n",
       " 'polis raporu',\n",
       " 'milyon dolar',\n",
       " 'milyon dolarlık',\n",
       " 'milyonlarca dolar',\n",
       " 'amerikan doları',\n",
       " 'komik film',\n",
       " 'komik videoları',\n",
       " 'komik tipler',\n",
       " 'komik karakter',\n",
       " 'telefon numarası',\n",
       " 'telefon kartı',\n",
       " 'telefonun şarjı',\n",
       " 'doktorun telefonu',\n",
       " 'tüp bebek',\n",
       " 'bebek penguenler',\n",
       " 'bebek pudrası',\n",
       " 'süper bebek',\n",
       " 'dans partisi',\n",
       " 'dans okuluna',\n",
       " 'diskoda dans',\n",
       " 'modern dans',\n",
       " '',\n",
       " 'milyon dolar',\n",
       " 'milyon dolarlık',\n",
       " 'milyon kilometre',\n",
       " 'milyon ton',\n",
       " 'takım kaptanı',\n",
       " 'kaptan pilot',\n",
       " 'kaptan amerika',\n",
       " 'kaptan barı',\n",
       " 'sistemler normal',\n",
       " 'normal kahve',\n",
       " 'fonksiyonlar normal',\n",
       " 'testleri normal',\n",
       " 'şans küpü',\n",
       " 'şanslı numara',\n",
       " 'şans faktörü',\n",
       " 'şans perisi',\n",
       " 'kahve makinesi',\n",
       " 'kahve servisi',\n",
       " 'kafeinsiz kahve',\n",
       " 'kremalı kahve',\n",
       " 'narkotik ajanı',\n",
       " 'şef ajan',\n",
       " 'süper ajan',\n",
       " 'siber ajan',\n",
       " 'şifreli mesaj',\n",
       " 'video mesajı',\n",
       " 'telefon mesajları',\n",
       " 'mesaj panosu',\n",
       " 'telefon numarası',\n",
       " 'plaka numarası',\n",
       " 'rozet numarası',\n",
       " 'kart numarası',\n",
       " 'kovboy filmi',\n",
       " 'aksiyon filmi',\n",
       " 'sinema filmi',\n",
       " 'film karakteri',\n",
       " 'komedi filmi',\n",
       " 'pijama partisi',\n",
       " 'sürpriz parti',\n",
       " 'dans partisi',\n",
       " 'parti lideri',\n",
       " 'futbol takımı',\n",
       " 'takım kaptanı',\n",
       " 'beyzbol takımı',\n",
       " 'okul takımı',\n",
       " 'süper star',\n",
       " 'süper kupa',\n",
       " 'süper market',\n",
       " 'süper model',\n",
       " 'enstrümantal müzik',\n",
       " 'klasik müzik',\n",
       " 'pop müzik',\n",
       " 'müzik festivali',\n",
       " 'okul otobüsü',\n",
       " 'okul projesi',\n",
       " 'okul takımı',\n",
       " 'okul üniforması',\n",
       " 'polis şefi',\n",
       " 'orkestra şefi',\n",
       " 'personel şefi',\n",
       " 'büro şefi',\n",
       " 'karavan parkı',\n",
       " 'park metre',\n",
       " 'park personeli',\n",
       " 'paralel park',\n",
       " 'karantina planı',\n",
       " 'finansal planlar',\n",
       " 'planlama ofisi',\n",
       " 'stratejik planlama',\n",
       " 'grup lideri',\n",
       " 'grup terapisi',\n",
       " 'grup şeması',\n",
       " 'park metre',\n",
       " 'milyonlarca metre',\n",
       " 'metre küp',\n",
       " 'kilo metre',\n",
       " 'fizik profesörü',\n",
       " 'psikoloji profesörü',\n",
       " 'matematik profesörü',\n",
       " 'arkeoloji profesörü',\n",
       " 'test pozitif',\n",
       " 'alkol testi',\n",
       " 'test negatif',\n",
       " 'alerji testi',\n",
       " 'fiziksel test',\n",
       " 'sürpriz parti',\n",
       " 'çikolata sürprizi',\n",
       " 'sürpriz bebek',\n",
       " 'sürpriz atak',\n",
       " 'atom bombası',\n",
       " 'nükleer bomba',\n",
       " 'bomba aktif',\n",
       " 'gaz bombası',\n",
       " 'avukatlık bürosu',\n",
       " 'avukatlar ofisi',\n",
       " 'firmanın avukatı',\n",
       " 'avukatın numarası',\n",
       " 'bazı notlar',\n",
       " 'kredi notu',\n",
       " 'şifreli not',\n",
       " 'laboratuvar notları',\n",
       " 'rafine şeker',\n",
       " 'küp şeker',\n",
       " 'şekerli kahve',\n",
       " 'şekerli krema',\n",
       " 'ekstra şekerli',\n",
       " 'balistik raporu',\n",
       " 'polis raporu',\n",
       " 'otopsi raporu',\n",
       " 'doktor raporu',\n",
       " 'fotoğraf makinesi',\n",
       " 'fotoğraf albümü',\n",
       " 'grup fotoğrafı',\n",
       " 'fotoğraf stüdyosu',\n",
       " 'prenses kostümü',\n",
       " 'japon prensesin',\n",
       " 'balonun prensesi',\n",
       " 'prenses kalesi',\n",
       " 'negatif enerji',\n",
       " 'pozitif enerji',\n",
       " 'enerji santralı',\n",
       " 'nükleer enerji',\n",
       " 'elektrik enerjisi',\n",
       " 'spor kanalı',\n",
       " 'takım sproru',\n",
       " 'spor akademisine',\n",
       " 'profesyonel sporcu',\n",
       " 'spor programı',\n",
       " 'psikolojik problemler',\n",
       " 'kilo problemi',\n",
       " 'vize problemi',\n",
       " 'matematik problemi',\n",
       " 'banka kredisi',\n",
       " 'banka çeki',\n",
       " 'telefonla bankacılığı',\n",
       " 'banka kartı',\n",
       " 'kilo problemi',\n",
       " 'kilo somon',\n",
       " 'kilo şeker',\n",
       " 'tren istasyonu',\n",
       " 'tren rayı',\n",
       " 'ekspres tren',\n",
       " 'metro treni',\n",
       " 'elektrik santrali',\n",
       " 'elektrik sistemi',\n",
       " 'statik elektrik',\n",
       " 'elektrik kablosu',\n",
       " 'taksi limuzin',\n",
       " 'taksinin bagajı',\n",
       " 'taksinin markası',\n",
       " 'taksi numarası',\n",
       " 'televizyon programı',\n",
       " 'kablolu televizyon',\n",
       " 'televizyon stüdyosu',\n",
       " 'teknik servis',\n",
       " 'teknik detaylar',\n",
       " 'teknik direktör',\n",
       " 'teknik ekipman',\n",
       " 'kredi kartı',\n",
       " 'banka kredisi',\n",
       " 'kredi limiti',\n",
       " 'okul kredisi',\n",
       " 'plaza otel',\n",
       " 'otel telefonu',\n",
       " 'otelin barı',\n",
       " 'lüks otel',\n",
       " 'genel sekreter',\n",
       " 'genel anestezi',\n",
       " 'genel karantina',\n",
       " 'genel kültür',\n",
       " 'onur madalyası',\n",
       " 'onur listesi',\n",
       " 'onur rozeti',\n",
       " 'gaz maskesi',\n",
       " 'biber gazı',\n",
       " 'gaz bombası',\n",
       " 'karbondioksit gazı',\n",
       " 'sosyalist parti',\n",
       " 'sosyal psikoloji',\n",
       " 'sosyal medya',\n",
       " 'sosyal aktivite',\n",
       " 'futbol takımı',\n",
       " 'futbol maçı',\n",
       " 'profesyonel futbol',\n",
       " 'futbol antrenmanı',\n",
       " 'futbol ligi',\n",
       " 'profesyonel futbol',\n",
       " 'profesyonel lig',\n",
       " 'profesyonel basketbol',\n",
       " 'profesyonel boks',\n",
       " 'entelektüel tipler',\n",
       " 'psikopat tipi',\n",
       " 'polis tipli',\n",
       " 'komik tipi',\n",
       " 'filmde rol',\n",
       " 'doktor rolü',\n",
       " 'rol model',\n",
       " 'aktif rol',\n",
       " 'teknik servis',\n",
       " 'servis asansörü',\n",
       " 'kahve servisi',\n",
       " 'okul servisi',\n",
       " 'nükleer bomba',\n",
       " 'nükleer enerji',\n",
       " 'nükleer santral',\n",
       " 'nükleer fizik',\n",
       " 'fiziksel temas',\n",
       " 'fiziksel test',\n",
       " 'fiziksel aktivite',\n",
       " 'fiziksel form',\n",
       " 'radyo sinyali',\n",
       " 'telefon sinyali',\n",
       " 'radar sinyali',\n",
       " 'orijinal sinyal',\n",
       " 'sezon finali',\n",
       " 'beyzbol sezonu',\n",
       " 'hokey sezonu',\n",
       " 'sezon şampiyonu',\n",
       " 'senatörün kampanyası',\n",
       " 'senatörün asistanı',\n",
       " 'senatörün planı',\n",
       " 'romantik restoran',\n",
       " 'romantik komedi',\n",
       " 'romantik atmosfer',\n",
       " 'romantik müzik',\n",
       " 'boks maçı',\n",
       " 'futbol maçı',\n",
       " 'final maçı',\n",
       " 'şampiyonluk maçı',\n",
       " 'doktora tezi',\n",
       " 'akdemik doktora',\n",
       " 'doktora komitesi',\n",
       " 'fizik doktorası',\n",
       " 'elektrik şoku',\n",
       " 'şok terapisi',\n",
       " 'alerjik şoka',\n",
       " 'şok video',\n",
       " 'video ünitesi',\n",
       " 'video filmi',\n",
       " 'video klip',\n",
       " 'video konferans',\n",
       " 'kredi kartı',\n",
       " 'telefon kartı',\n",
       " 'kart numarası',\n",
       " 'banka kartı',\n",
       " 'posta kartı',\n",
       " 'vampir filmi',\n",
       " 'vampir rolüne',\n",
       " 'mutant vampir',\n",
       " 'vampir antijeni',\n",
       " 'trafik polisi',\n",
       " 'trafik kontrolü',\n",
       " 'trafik lambası',\n",
       " 'trafik raporu',\n",
       " 'genel alarm',\n",
       " 'alarm sistemi',\n",
       " 'alarm şifresi',\n",
       " 'kriz alarmı',\n",
       " 'jet motoru',\n",
       " 'motorlar stop',\n",
       " 'motor kontrol',\n",
       " 'turbo motor',\n",
       " 'elektrik motorları',\n",
       " 'okul otobüsü',\n",
       " 'takım otobüse',\n",
       " 'otobüs terminali',\n",
       " 'turist otobüsü',\n",
       " 'tur otobüsü',\n",
       " 'otobüs turu',\n",
       " 'psikopat manyak',\n",
       " 'manyak film',\n",
       " 'manyak numara',\n",
       " 'manyak parti',\n",
       " 'fotoğraf makinesi',\n",
       " 'kahve makinesi',\n",
       " 'tost makinesi',\n",
       " 'fotokopi makinesi']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_list = []\n",
    "for i in range(len(df_word_group_select)):\n",
    "    for j in df_word_group_select.columns[1:]:\n",
    "        string = df_word_group_select.loc[i,j]\n",
    "        \n",
    "        if pd.isnull(string) == False and string != 'nan':\n",
    "            search_list.append(string.strip())\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        #search_list.append(string.strip())\n",
    "        #search_list = [x for x in search_list if np.isnan(x) == False]\n",
    "search_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_group_youtube(df, search_list, target_column, sample_num): \n",
    "    df_search_result = pd.DataFrame()\n",
    "    for j in search_list:\n",
    "        try:\n",
    "            df_select = df[df[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){j}(?:\\s|$)\", na=True)].sample(sample_num)\n",
    "        except:\n",
    "            df_select = df[df[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){j}(?:\\s|$)\", na=True)].head(sample_num)\n",
    "        #df_result = df[df[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){j}(?:\\s|$)\", na=True)]  # sentence length part\n",
    "        #df_result.sort_values(f\"{target_column}\",key=lambda x:x.str.len(), inplace=True)\n",
    "        #df_select = df_result.head(sample_num)\n",
    "        df_select.insert(0,\"search_string\",j)\n",
    "        df_search_result = pd.concat([df_search_result,df_select], axis=0)\n",
    "    df_search_result.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return df_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_search_result = pd.DataFrame()\n",
    "#for i in range(len(df_english_select)):\n",
    "#    for j in df_english_select.columns[1:]:\n",
    "#        string = df_english_select.loc[i,j]\n",
    "#        df_result = df_youtube_sent[df_youtube_sent.sentence.str.contains(fr\"(?:\\s|^){string}(?:\\s|$)\", na=True)]\n",
    "#        df_result.sort_values(\"sentence\",key=lambda x:x.str.len(), inplace=True)\n",
    "#        df_select = df_result.head(6)\n",
    "#        df_select.insert(0,\"search_string\",string)\n",
    "#        df_search_result = pd.concat([df_search_result,df_select], axis=0)\n",
    "#df_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_string</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sentence</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>7303.594</td>\n",
       "      <td>7306.376</td>\n",
       "      <td>tanıdığım çok iyi bir doktor var</td>\n",
       "      <td>6ip1mqRyI5M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>3657.882</td>\n",
       "      <td>3662.884</td>\n",
       "      <td>hocam yani biz eski kuşak bir doktor bekliyord...</td>\n",
       "      <td>BWSxerD3LDc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>32.980</td>\n",
       "      <td>35.840</td>\n",
       "      <td>havaalanında bir doktor bir çocuğu mu kurtarmı...</td>\n",
       "      <td>yLJbfglM_tY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>2895.962</td>\n",
       "      <td>2897.712</td>\n",
       "      <td>sonra bir doktor bulduk</td>\n",
       "      <td>GJyk2ANh7mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>812.656</td>\n",
       "      <td>822.328</td>\n",
       "      <td>descendants of the sun kısaca birleşmiş millet...</td>\n",
       "      <td>dSrXG27FnBY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>bebek gibi</td>\n",
       "      <td>1080.799</td>\n",
       "      <td>1085.049</td>\n",
       "      <td>ya onlar bana bu güne kadar bebek gibi baktı b...</td>\n",
       "      <td>KHMNiXYbdaU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>bebek gibi</td>\n",
       "      <td>3681.081</td>\n",
       "      <td>3683.858</td>\n",
       "      <td>aradım vallahi hedoş bebek gibi bakıyormuş gay...</td>\n",
       "      <td>metH403loSY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>bebek gibi</td>\n",
       "      <td>3616.153</td>\n",
       "      <td>3617.830</td>\n",
       "      <td>çişin var diye bebek gibi zırladın iki saat lan</td>\n",
       "      <td>riiIV32FEuM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>dans gibi</td>\n",
       "      <td>36.000</td>\n",
       "      <td>43.080</td>\n",
       "      <td>bu nedenle performansım bir dans gibi değil da...</td>\n",
       "      <td>JOGsTT3hDRo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>dans gibi</td>\n",
       "      <td>104.587</td>\n",
       "      <td>112.883</td>\n",
       "      <td>peki sen gerçek anlamda böyle beden eğitimi gi...</td>\n",
       "      <td>4aN0e5dOzh0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    search_string  start_time  end_time  \\\n",
       "0      bir doktor    7303.594  7306.376   \n",
       "1      bir doktor    3657.882  3662.884   \n",
       "2      bir doktor      32.980    35.840   \n",
       "3      bir doktor    2895.962  2897.712   \n",
       "4      bir doktor     812.656   822.328   \n",
       "..            ...         ...       ...   \n",
       "436    bebek gibi    1080.799  1085.049   \n",
       "437    bebek gibi    3681.081  3683.858   \n",
       "438    bebek gibi    3616.153  3617.830   \n",
       "439     dans gibi      36.000    43.080   \n",
       "440     dans gibi     104.587   112.883   \n",
       "\n",
       "                                              sentence     video_id  \n",
       "0                     tanıdığım çok iyi bir doktor var  6ip1mqRyI5M  \n",
       "1    hocam yani biz eski kuşak bir doktor bekliyord...  BWSxerD3LDc  \n",
       "2    havaalanında bir doktor bir çocuğu mu kurtarmı...  yLJbfglM_tY  \n",
       "3                              sonra bir doktor bulduk  GJyk2ANh7mg  \n",
       "4    descendants of the sun kısaca birleşmiş millet...  dSrXG27FnBY  \n",
       "..                                                 ...          ...  \n",
       "436  ya onlar bana bu güne kadar bebek gibi baktı b...  KHMNiXYbdaU  \n",
       "437  aradım vallahi hedoş bebek gibi bakıyormuş gay...  metH403loSY  \n",
       "438    çişin var diye bebek gibi zırladın iki saat lan  riiIV32FEuM  \n",
       "439  bu nedenle performansım bir dans gibi değil da...  JOGsTT3hDRo  \n",
       "440  peki sen gerçek anlamda böyle beden eğitimi gi...  4aN0e5dOzh0  \n",
       "\n",
       "[441 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_search_result = word_group_youtube(df_youtube_sentence, search_list, \"sentence\", 6)\n",
    "df_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_group_time_loc(df, search, start_sent, end_sent, sent, sent_video_id):\n",
    "    word_time_loc_list = []\n",
    "    for i in range(len(df)):\n",
    "        word = df.loc[i,f\"{search}\"]\n",
    "        start_time = df.loc[i,f\"{start_sent}\"]\n",
    "        end_time = df.loc[i,f\"{end_sent}\"]\n",
    "        sentence = df.loc[i,f\"{sent}\"]\n",
    "        video_id = df.loc[i,f\"{sent_video_id}\"]\n",
    "        time_length = end_time-start_time\n",
    "        sentence_length = len(sentence)\n",
    "        time_length_ratio = time_length/sentence_length\n",
    "        loc_list = []\n",
    "        for j in re.finditer(fr\"(?:\\s|^){word}(?:\\s|$)\", sentence, re.IGNORECASE|re.UNICODE):\n",
    "            loc_list.append(j)\n",
    "            start = loc_list[0].start()\n",
    "            end = loc_list[0].end()\n",
    "            start_loc = start_time+(start*time_length_ratio)\n",
    "            end_loc = start_time+(end*time_length_ratio)\n",
    "        word_time_loc_list.append([word,start_loc,end_loc,sentence,video_id])\n",
    "    df_word_time_loc = pd.DataFrame(word_time_loc_list, columns=[f\"{search}\",f\"{start_sent}\",f\"{end_sent}\",f\"{sent}\",f\"{sent_video_id}\"])\n",
    "\n",
    "    return df_word_time_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_string</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sentence</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>7305.071937</td>\n",
       "      <td>7306.115188</td>\n",
       "      <td>tanıdığım çok iyi bir doktor var</td>\n",
       "      <td>6ip1mqRyI5M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>3659.595014</td>\n",
       "      <td>3660.417260</td>\n",
       "      <td>hocam yani biz eski kuşak bir doktor bekliyord...</td>\n",
       "      <td>BWSxerD3LDc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>33.666400</td>\n",
       "      <td>34.352800</td>\n",
       "      <td>havaalanında bir doktor bir çocuğu mu kurtarmı...</td>\n",
       "      <td>yLJbfglM_tY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>2896.342435</td>\n",
       "      <td>2897.255478</td>\n",
       "      <td>sonra bir doktor bulduk</td>\n",
       "      <td>GJyk2ANh7mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>818.893739</td>\n",
       "      <td>819.734783</td>\n",
       "      <td>descendants of the sun kısaca birleşmiş millet...</td>\n",
       "      <td>dSrXG27FnBY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>bebek gibi</td>\n",
       "      <td>1081.994312</td>\n",
       "      <td>1082.525562</td>\n",
       "      <td>ya onlar bana bu güne kadar bebek gibi baktı b...</td>\n",
       "      <td>KHMNiXYbdaU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>bebek gibi</td>\n",
       "      <td>3682.149077</td>\n",
       "      <td>3682.789923</td>\n",
       "      <td>aradım vallahi hedoş bebek gibi bakıyormuş gay...</td>\n",
       "      <td>metH403loSY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>bebek gibi</td>\n",
       "      <td>3616.652532</td>\n",
       "      <td>3617.080702</td>\n",
       "      <td>çişin var diye bebek gibi zırladın iki saat lan</td>\n",
       "      <td>riiIV32FEuM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>dans gibi</td>\n",
       "      <td>38.331220</td>\n",
       "      <td>39.280976</td>\n",
       "      <td>bu nedenle performansım bir dans gibi değil da...</td>\n",
       "      <td>JOGsTT3hDRo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>dans gibi</td>\n",
       "      <td>108.453097</td>\n",
       "      <td>109.339078</td>\n",
       "      <td>peki sen gerçek anlamda böyle beden eğitimi gi...</td>\n",
       "      <td>4aN0e5dOzh0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    search_string   start_time     end_time  \\\n",
       "0      bir doktor  7305.071937  7306.115188   \n",
       "1      bir doktor  3659.595014  3660.417260   \n",
       "2      bir doktor    33.666400    34.352800   \n",
       "3      bir doktor  2896.342435  2897.255478   \n",
       "4      bir doktor   818.893739   819.734783   \n",
       "..            ...          ...          ...   \n",
       "436    bebek gibi  1081.994312  1082.525562   \n",
       "437    bebek gibi  3682.149077  3682.789923   \n",
       "438    bebek gibi  3616.652532  3617.080702   \n",
       "439     dans gibi    38.331220    39.280976   \n",
       "440     dans gibi   108.453097   109.339078   \n",
       "\n",
       "                                              sentence     video_id  \n",
       "0                     tanıdığım çok iyi bir doktor var  6ip1mqRyI5M  \n",
       "1    hocam yani biz eski kuşak bir doktor bekliyord...  BWSxerD3LDc  \n",
       "2    havaalanında bir doktor bir çocuğu mu kurtarmı...  yLJbfglM_tY  \n",
       "3                              sonra bir doktor bulduk  GJyk2ANh7mg  \n",
       "4    descendants of the sun kısaca birleşmiş millet...  dSrXG27FnBY  \n",
       "..                                                 ...          ...  \n",
       "436  ya onlar bana bu güne kadar bebek gibi baktı b...  KHMNiXYbdaU  \n",
       "437  aradım vallahi hedoş bebek gibi bakıyormuş gay...  metH403loSY  \n",
       "438    çişin var diye bebek gibi zırladın iki saat lan  riiIV32FEuM  \n",
       "439  bu nedenle performansım bir dans gibi değil da...  JOGsTT3hDRo  \n",
       "440  peki sen gerçek anlamda böyle beden eğitimi gi...  4aN0e5dOzh0  \n",
       "\n",
       "[441 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_group_time_loc_result = word_group_time_loc(df_search_result, \"search_string\", \"start_time\", \"end_time\", \"sentence\", \"video_id\")\n",
    "df_word_group_time_loc_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_string</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sentence</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>7304.471937</td>\n",
       "      <td>7306.715188</td>\n",
       "      <td>tanıdığım çok iyi bir doktor var</td>\n",
       "      <td>6ip1mqRyI5M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>3658.995014</td>\n",
       "      <td>3661.017260</td>\n",
       "      <td>hocam yani biz eski kuşak bir doktor bekliyord...</td>\n",
       "      <td>BWSxerD3LDc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>33.066400</td>\n",
       "      <td>34.952800</td>\n",
       "      <td>havaalanında bir doktor bir çocuğu mu kurtarmı...</td>\n",
       "      <td>yLJbfglM_tY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>2895.742435</td>\n",
       "      <td>2897.855478</td>\n",
       "      <td>sonra bir doktor bulduk</td>\n",
       "      <td>GJyk2ANh7mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>818.293739</td>\n",
       "      <td>820.334783</td>\n",
       "      <td>descendants of the sun kısaca birleşmiş millet...</td>\n",
       "      <td>dSrXG27FnBY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>bebek gibi</td>\n",
       "      <td>1081.394313</td>\n",
       "      <td>1083.125562</td>\n",
       "      <td>ya onlar bana bu güne kadar bebek gibi baktı b...</td>\n",
       "      <td>KHMNiXYbdaU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>bebek gibi</td>\n",
       "      <td>3681.549077</td>\n",
       "      <td>3683.389923</td>\n",
       "      <td>aradım vallahi hedoş bebek gibi bakıyormuş gay...</td>\n",
       "      <td>metH403loSY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>bebek gibi</td>\n",
       "      <td>3616.052532</td>\n",
       "      <td>3617.680702</td>\n",
       "      <td>çişin var diye bebek gibi zırladın iki saat lan</td>\n",
       "      <td>riiIV32FEuM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>dans gibi</td>\n",
       "      <td>37.731220</td>\n",
       "      <td>39.880976</td>\n",
       "      <td>bu nedenle performansım bir dans gibi değil da...</td>\n",
       "      <td>JOGsTT3hDRo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>dans gibi</td>\n",
       "      <td>107.853097</td>\n",
       "      <td>109.939078</td>\n",
       "      <td>peki sen gerçek anlamda böyle beden eğitimi gi...</td>\n",
       "      <td>4aN0e5dOzh0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    search_string   start_time     end_time  \\\n",
       "0      bir doktor  7304.471937  7306.715188   \n",
       "1      bir doktor  3658.995014  3661.017260   \n",
       "2      bir doktor    33.066400    34.952800   \n",
       "3      bir doktor  2895.742435  2897.855478   \n",
       "4      bir doktor   818.293739   820.334783   \n",
       "..            ...          ...          ...   \n",
       "436    bebek gibi  1081.394313  1083.125562   \n",
       "437    bebek gibi  3681.549077  3683.389923   \n",
       "438    bebek gibi  3616.052532  3617.680702   \n",
       "439     dans gibi    37.731220    39.880976   \n",
       "440     dans gibi   107.853097   109.939078   \n",
       "\n",
       "                                              sentence     video_id  \n",
       "0                     tanıdığım çok iyi bir doktor var  6ip1mqRyI5M  \n",
       "1    hocam yani biz eski kuşak bir doktor bekliyord...  BWSxerD3LDc  \n",
       "2    havaalanında bir doktor bir çocuğu mu kurtarmı...  yLJbfglM_tY  \n",
       "3                              sonra bir doktor bulduk  GJyk2ANh7mg  \n",
       "4    descendants of the sun kısaca birleşmiş millet...  dSrXG27FnBY  \n",
       "..                                                 ...          ...  \n",
       "436  ya onlar bana bu güne kadar bebek gibi baktı b...  KHMNiXYbdaU  \n",
       "437  aradım vallahi hedoş bebek gibi bakıyormuş gay...  metH403loSY  \n",
       "438    çişin var diye bebek gibi zırladın iki saat lan  riiIV32FEuM  \n",
       "439  bu nedenle performansım bir dans gibi değil da...  JOGsTT3hDRo  \n",
       "440  peki sen gerçek anlamda böyle beden eğitimi gi...  4aN0e5dOzh0  \n",
       "\n",
       "[441 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#time_shift = 0.3\n",
    "df_word_group_time_loc_result.start_time = df_word_group_time_loc_result.start_time.apply(lambda x: (x-time_shift))\n",
    "df_word_group_time_loc_result.end_time = df_word_group_time_loc_result.end_time.apply(lambda x: (x+time_shift))\n",
    "df_word_group_time_loc_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_string</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sentence</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>7304</td>\n",
       "      <td>7307</td>\n",
       "      <td>tanıdığım çok iyi bir doktor var</td>\n",
       "      <td>6ip1mqRyI5M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>3659</td>\n",
       "      <td>3661</td>\n",
       "      <td>hocam yani biz eski kuşak bir doktor bekliyord...</td>\n",
       "      <td>BWSxerD3LDc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>havaalanında bir doktor bir çocuğu mu kurtarmı...</td>\n",
       "      <td>yLJbfglM_tY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>2896</td>\n",
       "      <td>2898</td>\n",
       "      <td>sonra bir doktor bulduk</td>\n",
       "      <td>GJyk2ANh7mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>818</td>\n",
       "      <td>820</td>\n",
       "      <td>descendants of the sun kısaca birleşmiş millet...</td>\n",
       "      <td>dSrXG27FnBY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>bebek gibi</td>\n",
       "      <td>1081</td>\n",
       "      <td>1083</td>\n",
       "      <td>ya onlar bana bu güne kadar bebek gibi baktı b...</td>\n",
       "      <td>KHMNiXYbdaU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>bebek gibi</td>\n",
       "      <td>3682</td>\n",
       "      <td>3683</td>\n",
       "      <td>aradım vallahi hedoş bebek gibi bakıyormuş gay...</td>\n",
       "      <td>metH403loSY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>bebek gibi</td>\n",
       "      <td>3616</td>\n",
       "      <td>3618</td>\n",
       "      <td>çişin var diye bebek gibi zırladın iki saat lan</td>\n",
       "      <td>riiIV32FEuM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>dans gibi</td>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "      <td>bu nedenle performansım bir dans gibi değil da...</td>\n",
       "      <td>JOGsTT3hDRo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>dans gibi</td>\n",
       "      <td>108</td>\n",
       "      <td>110</td>\n",
       "      <td>peki sen gerçek anlamda böyle beden eğitimi gi...</td>\n",
       "      <td>4aN0e5dOzh0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    search_string  start_time  end_time  \\\n",
       "0      bir doktor        7304      7307   \n",
       "1      bir doktor        3659      3661   \n",
       "2      bir doktor          33        35   \n",
       "3      bir doktor        2896      2898   \n",
       "4      bir doktor         818       820   \n",
       "..            ...         ...       ...   \n",
       "436    bebek gibi        1081      1083   \n",
       "437    bebek gibi        3682      3683   \n",
       "438    bebek gibi        3616      3618   \n",
       "439     dans gibi          38        40   \n",
       "440     dans gibi         108       110   \n",
       "\n",
       "                                              sentence     video_id  \n",
       "0                     tanıdığım çok iyi bir doktor var  6ip1mqRyI5M  \n",
       "1    hocam yani biz eski kuşak bir doktor bekliyord...  BWSxerD3LDc  \n",
       "2    havaalanında bir doktor bir çocuğu mu kurtarmı...  yLJbfglM_tY  \n",
       "3                              sonra bir doktor bulduk  GJyk2ANh7mg  \n",
       "4    descendants of the sun kısaca birleşmiş millet...  dSrXG27FnBY  \n",
       "..                                                 ...          ...  \n",
       "436  ya onlar bana bu güne kadar bebek gibi baktı b...  KHMNiXYbdaU  \n",
       "437  aradım vallahi hedoş bebek gibi bakıyormuş gay...  metH403loSY  \n",
       "438    çişin var diye bebek gibi zırladın iki saat lan  riiIV32FEuM  \n",
       "439  bu nedenle performansım bir dans gibi değil da...  JOGsTT3hDRo  \n",
       "440  peki sen gerçek anlamda böyle beden eğitimi gi...  4aN0e5dOzh0  \n",
       "\n",
       "[441 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_group_time_loc_result.start_time = df_word_group_time_loc_result.start_time.apply(lambda x: round(x))\n",
    "df_word_group_time_loc_result.end_time = df_word_group_time_loc_result.end_time.apply(lambda x: round(x))\n",
    "df_word_group_time_loc_result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_string</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sentence</th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>7304</td>\n",
       "      <td>7307</td>\n",
       "      <td>tanıdığım çok iyi bir doktor var</td>\n",
       "      <td>6ip1mqRyI5M</td>\n",
       "      <td>https://www.youtube.com/watch?v=6ip1mqRyI5M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>3659</td>\n",
       "      <td>3661</td>\n",
       "      <td>hocam yani biz eski kuşak bir doktor bekliyord...</td>\n",
       "      <td>BWSxerD3LDc</td>\n",
       "      <td>https://www.youtube.com/watch?v=BWSxerD3LDc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>havaalanında bir doktor bir çocuğu mu kurtarmı...</td>\n",
       "      <td>yLJbfglM_tY</td>\n",
       "      <td>https://www.youtube.com/watch?v=yLJbfglM_tY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>2896</td>\n",
       "      <td>2898</td>\n",
       "      <td>sonra bir doktor bulduk</td>\n",
       "      <td>GJyk2ANh7mg</td>\n",
       "      <td>https://www.youtube.com/watch?v=GJyk2ANh7mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>818</td>\n",
       "      <td>820</td>\n",
       "      <td>descendants of the sun kısaca birleşmiş millet...</td>\n",
       "      <td>dSrXG27FnBY</td>\n",
       "      <td>https://www.youtube.com/watch?v=dSrXG27FnBY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>bebek gibi</td>\n",
       "      <td>1081</td>\n",
       "      <td>1083</td>\n",
       "      <td>ya onlar bana bu güne kadar bebek gibi baktı b...</td>\n",
       "      <td>KHMNiXYbdaU</td>\n",
       "      <td>https://www.youtube.com/watch?v=KHMNiXYbdaU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>bebek gibi</td>\n",
       "      <td>3682</td>\n",
       "      <td>3683</td>\n",
       "      <td>aradım vallahi hedoş bebek gibi bakıyormuş gay...</td>\n",
       "      <td>metH403loSY</td>\n",
       "      <td>https://www.youtube.com/watch?v=metH403loSY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>bebek gibi</td>\n",
       "      <td>3616</td>\n",
       "      <td>3618</td>\n",
       "      <td>çişin var diye bebek gibi zırladın iki saat lan</td>\n",
       "      <td>riiIV32FEuM</td>\n",
       "      <td>https://www.youtube.com/watch?v=riiIV32FEuM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>dans gibi</td>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "      <td>bu nedenle performansım bir dans gibi değil da...</td>\n",
       "      <td>JOGsTT3hDRo</td>\n",
       "      <td>https://www.youtube.com/watch?v=JOGsTT3hDRo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>dans gibi</td>\n",
       "      <td>108</td>\n",
       "      <td>110</td>\n",
       "      <td>peki sen gerçek anlamda böyle beden eğitimi gi...</td>\n",
       "      <td>4aN0e5dOzh0</td>\n",
       "      <td>https://www.youtube.com/watch?v=4aN0e5dOzh0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    search_string  start_time  end_time  \\\n",
       "0      bir doktor        7304      7307   \n",
       "1      bir doktor        3659      3661   \n",
       "2      bir doktor          33        35   \n",
       "3      bir doktor        2896      2898   \n",
       "4      bir doktor         818       820   \n",
       "..            ...         ...       ...   \n",
       "436    bebek gibi        1081      1083   \n",
       "437    bebek gibi        3682      3683   \n",
       "438    bebek gibi        3616      3618   \n",
       "439     dans gibi          38        40   \n",
       "440     dans gibi         108       110   \n",
       "\n",
       "                                              sentence     video_id  \\\n",
       "0                     tanıdığım çok iyi bir doktor var  6ip1mqRyI5M   \n",
       "1    hocam yani biz eski kuşak bir doktor bekliyord...  BWSxerD3LDc   \n",
       "2    havaalanında bir doktor bir çocuğu mu kurtarmı...  yLJbfglM_tY   \n",
       "3                              sonra bir doktor bulduk  GJyk2ANh7mg   \n",
       "4    descendants of the sun kısaca birleşmiş millet...  dSrXG27FnBY   \n",
       "..                                                 ...          ...   \n",
       "436  ya onlar bana bu güne kadar bebek gibi baktı b...  KHMNiXYbdaU   \n",
       "437  aradım vallahi hedoş bebek gibi bakıyormuş gay...  metH403loSY   \n",
       "438    çişin var diye bebek gibi zırladın iki saat lan  riiIV32FEuM   \n",
       "439  bu nedenle performansım bir dans gibi değil da...  JOGsTT3hDRo   \n",
       "440  peki sen gerçek anlamda böyle beden eğitimi gi...  4aN0e5dOzh0   \n",
       "\n",
       "                                       video_url  \n",
       "0    https://www.youtube.com/watch?v=6ip1mqRyI5M  \n",
       "1    https://www.youtube.com/watch?v=BWSxerD3LDc  \n",
       "2    https://www.youtube.com/watch?v=yLJbfglM_tY  \n",
       "3    https://www.youtube.com/watch?v=GJyk2ANh7mg  \n",
       "4    https://www.youtube.com/watch?v=dSrXG27FnBY  \n",
       "..                                           ...  \n",
       "436  https://www.youtube.com/watch?v=KHMNiXYbdaU  \n",
       "437  https://www.youtube.com/watch?v=metH403loSY  \n",
       "438  https://www.youtube.com/watch?v=riiIV32FEuM  \n",
       "439  https://www.youtube.com/watch?v=JOGsTT3hDRo  \n",
       "440  https://www.youtube.com/watch?v=4aN0e5dOzh0  \n",
       "\n",
       "[441 rows x 6 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_group_time_loc_result[\"video_url\"] = \"https://www.youtube.com/watch?v=\"+df_word_group_time_loc_result['video_id'].map(str)\n",
    "df_word_group_time_loc_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_group_time_loc_result.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_{sheets.capitalize()}_\\\n",
    "{sample_num}_Youtube_{time_shift}s_Timeshift_Result.xlsx\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Move And Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Turkish_English_2 gram hybrid_6_Youtube_0.6s_Timeshift_Result.xlsx',\n",
       " 'Turkish_English_2 gram target_6_Youtube_0.6s_Timeshift_Result.xlsx']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file5 = glob.glob(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_*_{sample_num}_Youtube_{time_shift}s_Timeshift_Result.xlsx\")\n",
    "output_file5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in output_file5:\n",
    "    source = y # source directory\n",
    "    destination = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/5-Shared Word File/{lang_folder.capitalize()} {lang_pair.capitalize()}\"\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in output_file5:\n",
    "    try:\n",
    "        os.remove(z)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "651d507d70892fab0fc6529d935cd476f6e2eb1791525b76da6cc8da34bc0503"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
